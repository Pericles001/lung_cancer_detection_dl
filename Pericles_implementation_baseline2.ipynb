{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9803146,"sourceType":"datasetVersion","datasetId":6008457}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/iabh1shekbasu/LungCancerDetectionEnsemble/blob/main/Probability_Extraction_and_Analysis.ipynb\n\n)\n","metadata":{"id":"lfzxkoFg4ePS"}},{"cell_type":"markdown","source":"## Connecting Google Drive","metadata":{"id":"rAhpqH6d3j81"}},{"cell_type":"code","source":"!pip cache purge\n# !!pip install numpy==1.22.4 pandas==1.5.3 scipy==1.8.1\n# !pip cache purge\n# !pip install scipy==1.7.3\n# !pip install --force-reinstall --no-deps scipy==1.14.1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T22:33:45.914798Z","iopub.execute_input":"2024-12-04T22:33:45.915138Z","iopub.status.idle":"2024-12-04T22:33:47.531670Z","shell.execute_reply.started":"2024-12-04T22:33:45.915107Z","shell.execute_reply":"2024-12-04T22:33:47.530828Z"}},"outputs":[{"name":"stdout","text":"Files removed: 8\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install --force-reinstall --no-cache-dir scipy==1.14.1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T22:33:50.749687Z","iopub.execute_input":"2024-12-04T22:33:50.750041Z","iopub.status.idle":"2024-12-04T22:34:11.051689Z","shell.execute_reply.started":"2024-12-04T22:33:50.750009Z","shell.execute_reply":"2024-12-04T22:34:11.050787Z"}},"outputs":[{"name":"stdout","text":"Collecting scipy==1.14.1\n  Downloading scipy-1.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting numpy<2.3,>=1.23.5 (from scipy==1.14.1)\n  Downloading numpy-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m224.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading scipy-1.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 MB\u001b[0m \u001b[31m279.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading numpy-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m281.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: numpy, scipy\n  Attempting uninstall: numpy\n    Found existing installation: numpy 1.26.4\n    Uninstalling numpy-1.26.4:\n      Successfully uninstalled numpy-1.26.4\n  Attempting uninstall: scipy\n    Found existing installation: scipy 1.14.1\n    Uninstalling scipy-1.14.1:\n      Successfully uninstalled scipy-1.14.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 24.10.1 requires cubinlinker, which is not installed.\ncudf 24.10.1 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 24.10.1 requires libcudf==24.10.*, which is not installed.\ncudf 24.10.1 requires ptxcompiler, which is not installed.\ncuml 24.10.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncuml 24.10.0 requires cuvs==24.10.*, which is not installed.\ncuml 24.10.0 requires nvidia-cublas, which is not installed.\ncuml 24.10.0 requires nvidia-cufft, which is not installed.\ncuml 24.10.0 requires nvidia-curand, which is not installed.\ncuml 24.10.0 requires nvidia-cusolver, which is not installed.\ncuml 24.10.0 requires nvidia-cusparse, which is not installed.\ndask-cudf 24.10.1 requires cupy-cuda11x>=12.0.0, which is not installed.\npylibcudf 24.10.1 requires libcudf==24.10.*, which is not installed.\npylibraft 24.10.0 requires nvidia-cublas, which is not installed.\npylibraft 24.10.0 requires nvidia-curand, which is not installed.\npylibraft 24.10.0 requires nvidia-cusolver, which is not installed.\npylibraft 24.10.0 requires nvidia-cusparse, which is not installed.\nucxx 0.40.0 requires libucxx==0.40.*, which is not installed.\napache-beam 2.46.0 requires cloudpickle~=2.2.1, but you have cloudpickle 3.1.0 which is incompatible.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 2.1.3 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 17.0.0 which is incompatible.\ncatboost 1.2.7 requires numpy<2.0,>=1.16.0, but you have numpy 2.1.3 which is incompatible.\ncudf 24.10.1 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.6.2.post1 which is incompatible.\ncudf 24.10.1 requires pandas<2.2.3dev0,>=2.0, but you have pandas 2.2.3 which is incompatible.\ndask-cudf 24.10.1 requires pandas<2.2.3dev0,>=2.0, but you have pandas 2.2.3 which is incompatible.\ngensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.1.3 which is incompatible.\ngensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.14.1 which is incompatible.\nibis-framework 7.1.0 requires numpy<2,>=1, but you have numpy 2.1.3 which is incompatible.\nibis-framework 7.1.0 requires pyarrow<15,>=2, but you have pyarrow 17.0.0 which is incompatible.\nlibpysal 4.9.2 requires packaging>=22, but you have packaging 21.3 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmatplotlib 3.7.5 requires numpy<2,>=1.20, but you have numpy 2.1.3 which is incompatible.\nmlxtend 0.23.3 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\nnumba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.1.3 which is incompatible.\nplotnine 0.14.3 requires matplotlib>=3.8.0, but you have matplotlib 3.7.5 which is incompatible.\npylibcudf 24.10.1 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.6.2.post1 which is incompatible.\nrmm 24.10.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.6.2.post1 which is incompatible.\ntensorflow 2.16.1 requires numpy<2.0.0,>=1.23.5; python_version <= \"3.11\", but you have numpy 2.1.3 which is incompatible.\ntensorflow-transform 0.14.0 requires numpy<2,>=1.16, but you have numpy 2.1.3 which is incompatible.\nthinc 8.3.2 requires numpy<2.1.0,>=2.0.0; python_version >= \"3.9\", but you have numpy 2.1.3 which is incompatible.\nxarray 2024.11.0 requires packaging>=23.2, but you have packaging 21.3 which is incompatible.\nydata-profiling 4.12.0 requires scipy<1.14,>=1.4.1, but you have scipy 1.14.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed numpy-2.1.3 scipy-1.14.1\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!pip uninstall scikit-plot -y\n!pip install scikit-plot","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T22:34:11.053478Z","iopub.execute_input":"2024-12-04T22:34:11.053794Z","iopub.status.idle":"2024-12-04T22:34:24.401216Z","shell.execute_reply.started":"2024-12-04T22:34:11.053764Z","shell.execute_reply":"2024-12-04T22:34:24.400340Z"}},"outputs":[{"name":"stdout","text":"Found existing installation: scikit-plot 0.3.7\nUninstalling scikit-plot-0.3.7:\n  Successfully uninstalled scikit-plot-0.3.7\nCollecting scikit-plot\n  Downloading scikit_plot-0.3.7-py3-none-any.whl.metadata (7.1 kB)\nRequirement already satisfied: matplotlib>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from scikit-plot) (3.7.5)\nRequirement already satisfied: scikit-learn>=0.18 in /opt/conda/lib/python3.10/site-packages (from scikit-plot) (1.2.2)\nRequirement already satisfied: scipy>=0.9 in /opt/conda/lib/python3.10/site-packages (from scikit-plot) (1.14.1)\nRequirement already satisfied: joblib>=0.10 in /opt/conda/lib/python3.10/site-packages (from scikit-plot) (1.4.2)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=1.4.0->scikit-plot) (1.2.1)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=1.4.0->scikit-plot) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=1.4.0->scikit-plot) (4.53.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=1.4.0->scikit-plot) (1.4.5)\nCollecting numpy<2,>=1.20 (from matplotlib>=1.4.0->scikit-plot)\n  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=1.4.0->scikit-plot) (21.3)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=1.4.0->scikit-plot) (10.3.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=1.4.0->scikit-plot) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=1.4.0->scikit-plot) (2.9.0.post0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.18->scikit-plot) (3.5.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=1.4.0->scikit-plot) (1.16.0)\nDownloading scikit_plot-0.3.7-py3-none-any.whl (33 kB)\nDownloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m79.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: numpy, scikit-plot\n  Attempting uninstall: numpy\n    Found existing installation: numpy 2.1.3\n    Uninstalling numpy-2.1.3:\n      Successfully uninstalled numpy-2.1.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 24.10.1 requires cubinlinker, which is not installed.\ncudf 24.10.1 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 24.10.1 requires libcudf==24.10.*, which is not installed.\ncudf 24.10.1 requires ptxcompiler, which is not installed.\ncuml 24.10.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncuml 24.10.0 requires cuvs==24.10.*, which is not installed.\ncuml 24.10.0 requires nvidia-cublas, which is not installed.\ncuml 24.10.0 requires nvidia-cufft, which is not installed.\ncuml 24.10.0 requires nvidia-curand, which is not installed.\ncuml 24.10.0 requires nvidia-cusolver, which is not installed.\ncuml 24.10.0 requires nvidia-cusparse, which is not installed.\ndask-cudf 24.10.1 requires cupy-cuda11x>=12.0.0, which is not installed.\npylibcudf 24.10.1 requires libcudf==24.10.*, which is not installed.\npylibraft 24.10.0 requires nvidia-cublas, which is not installed.\npylibraft 24.10.0 requires nvidia-curand, which is not installed.\npylibraft 24.10.0 requires nvidia-cusolver, which is not installed.\npylibraft 24.10.0 requires nvidia-cusparse, which is not installed.\nucxx 0.40.0 requires libucxx==0.40.*, which is not installed.\napache-beam 2.46.0 requires cloudpickle~=2.2.1, but you have cloudpickle 3.1.0 which is incompatible.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 17.0.0 which is incompatible.\nblis 1.0.1 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\ncesium 0.12.3 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ncudf 24.10.1 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.6.2.post1 which is incompatible.\ncudf 24.10.1 requires pandas<2.2.3dev0,>=2.0, but you have pandas 2.2.3 which is incompatible.\ndask-cudf 24.10.1 requires pandas<2.2.3dev0,>=2.0, but you have pandas 2.2.3 which is incompatible.\ngensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.14.1 which is incompatible.\nibis-framework 7.1.0 requires pyarrow<15,>=2, but you have pyarrow 17.0.0 which is incompatible.\nlibpysal 4.9.2 requires packaging>=22, but you have packaging 21.3 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmlxtend 0.23.3 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\nplotnine 0.14.3 requires matplotlib>=3.8.0, but you have matplotlib 3.7.5 which is incompatible.\npylibcudf 24.10.1 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.6.2.post1 which is incompatible.\nrmm 24.10.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.6.2.post1 which is incompatible.\nthinc 8.3.2 requires numpy<2.1.0,>=2.0.0; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\nxarray 2024.11.0 requires packaging>=23.2, but you have packaging 21.3 which is incompatible.\nydata-profiling 4.12.0 requires scipy<1.14,>=1.4.1, but you have scipy 1.14.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed numpy-1.26.4 scikit-plot-0.3.7\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# !pip uninstall scikit-plot -y\n!pip install scikit-plot","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T22:34:30.538295Z","iopub.execute_input":"2024-12-04T22:34:30.539041Z","iopub.status.idle":"2024-12-04T22:34:38.772991Z","shell.execute_reply.started":"2024-12-04T22:34:30.539003Z","shell.execute_reply":"2024-12-04T22:34:38.772148Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: scikit-plot in /opt/conda/lib/python3.10/site-packages (0.3.7)\nRequirement already satisfied: matplotlib>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from scikit-plot) (3.7.5)\nRequirement already satisfied: scikit-learn>=0.18 in /opt/conda/lib/python3.10/site-packages (from scikit-plot) (1.2.2)\nRequirement already satisfied: scipy>=0.9 in /opt/conda/lib/python3.10/site-packages (from scikit-plot) (1.14.1)\nRequirement already satisfied: joblib>=0.10 in /opt/conda/lib/python3.10/site-packages (from scikit-plot) (1.4.2)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=1.4.0->scikit-plot) (1.2.1)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=1.4.0->scikit-plot) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=1.4.0->scikit-plot) (4.53.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=1.4.0->scikit-plot) (1.4.5)\nRequirement already satisfied: numpy<2,>=1.20 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=1.4.0->scikit-plot) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=1.4.0->scikit-plot) (21.3)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=1.4.0->scikit-plot) (10.3.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=1.4.0->scikit-plot) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=1.4.0->scikit-plot) (2.9.0.post0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.18->scikit-plot) (3.5.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=1.4.0->scikit-plot) (1.16.0)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# pip install scipy==1.6.3\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.metrics import *\nimport matplotlib.pyplot as plt\nimport math,os,argparse\n# from scikitplot.estimators import plot_feature_importances\n# from scikitplot.metrics import plot_confusion_matrix, plot_roc\nfrom sklearn.metrics import roc_curve,auc\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import label_binarize","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T22:34:46.893740Z","iopub.execute_input":"2024-12-04T22:34:46.894201Z","iopub.status.idle":"2024-12-04T22:34:46.899410Z","shell.execute_reply.started":"2024-12-04T22:34:46.894170Z","shell.execute_reply":"2024-12-04T22:34:46.898497Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# !mkdir /content/drive","metadata":{"id":"jHg6TA_x_GBG","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# from google.colab import drive\n\n# drive.mount('/content/drive')\n# https://drive.google.com/drive/folders/1pk4XWbn5PVPS4OQmj3GhBHq5fd0QAYZk?usp=drive_link","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5VJCY8ut_j8I","outputId":"5e15b818-52f9-493d-c953-a0ab78a8d5c3","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# !google-drive-ocamlfuse\n\n# !ls '/kaggle/input/ensemble-learning-on-lidc-dataset/data'\n# List contents of the data directory\ndata_dir = \"/kaggle/input/ensemble-learning-on-lidc-dataset/data\"\nprint(\"Contents of data directory:\")\n!ls \"{data_dir}\"","metadata":{"id":"dgsT6mC3tQF-","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e6a8de35-2e21-4382-a15d-020d181f70e2","trusted":true,"execution":{"iopub.status.busy":"2024-12-04T22:34:50.909448Z","iopub.execute_input":"2024-12-04T22:34:50.910139Z","iopub.status.idle":"2024-12-04T22:34:51.935251Z","shell.execute_reply.started":"2024-12-04T22:34:50.910103Z","shell.execute_reply":"2024-12-04T22:34:51.934397Z"}},"outputs":[{"name":"stdout","text":"Contents of data directory:\ndensenet169.h5\t       resnet152_test.csv  train\ndensenet169_test.csv   test\t\t   train_labels.csv\ndensenet169_train.csv  test_labels.csv\t   val\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# !xdg-settings set default-web-browser w3m.desktop # to set default browser\n\n# %cd /content\n\n# !mkdir drive\n\n# %cd drive\n\n# !mkdir MyDrive\n\n# %cd ..\n\n# %cd ..\n\n# !google-drive-ocamlfuse /content/drive/MyDrive","metadata":{"id":"MBozFjkZgUG2","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Importing Libraries\n\n\n\nThis section imports necessary libraries required for the entire notebook. It includes deep learning libraries such as PyTorch, data manipulation libraries like NumPy, and visualization libraries such as matplotlib.","metadata":{"id":"20b1c6af"}},{"cell_type":"code","source":"import time\n\nimport os\n\nimport copy\n\nimport numpy as np\n\nimport matplotlib.pyplot as plt\n\nfrom sklearn.metrics import roc_auc_score\n\nimport torch\n\nimport torch.nn as nn\n\nimport torch.optim as optim\n\nfrom torch.optim import lr_scheduler\n\nimport torchvision\n\nfrom torchvision import datasets, models, transforms\n\nfrom torch.utils.data import WeightedRandomSampler, DataLoader\n# Set device for training (GPU or CPU)\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","metadata":{"id":"5fyYNJJ-wXVL","trusted":true,"execution":{"iopub.status.busy":"2024-12-04T22:34:58.520946Z","iopub.execute_input":"2024-12-04T22:34:58.521315Z","iopub.status.idle":"2024-12-04T22:35:03.374323Z","shell.execute_reply.started":"2024-12-04T22:34:58.521283Z","shell.execute_reply":"2024-12-04T22:35:03.373415Z"}},"outputs":[{"name":"stdout","text":"cuda:0\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"## Data Preprocessing\n\n\n\nThis section defines the transformations to be applied to the input data for training and evaluation purposes. It includes normalization, resizing, and augmentation strategies.","metadata":{"id":"e2ea2095"}},{"cell_type":"code","source":"mean = np.array([0.5, 0.5, 0.5])\n\nstd = np.array([0.5, 0.5, 0.5])","metadata":{"id":"phwkI5VowXcW","trusted":true,"execution":{"iopub.status.busy":"2024-12-04T22:37:55.821847Z","iopub.execute_input":"2024-12-04T22:37:55.822426Z","iopub.status.idle":"2024-12-04T22:37:55.829495Z","shell.execute_reply.started":"2024-12-04T22:37:55.822393Z","shell.execute_reply":"2024-12-04T22:37:55.827120Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"data_transforms = {\n    'train': transforms.Compose([\n        transforms.Resize(256),\n        transforms.RandomPerspective(distortion_scale=0.3, p=0.5),\n        transforms.ColorJitter(brightness=0.2),\n        transforms.RandomRotation(degrees=25),\n        transforms.RandomHorizontalFlip(p=0.25),\n        transforms.RandAugment(num_ops=4),\n        transforms.Resize((256, 256)),  # Ensure consistent output size\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n    ]),\n    'val': transforms.Compose([\n        transforms.Resize((256, 256)),\n        transforms.ToTensor()\n    ]),\n    'test': transforms.Compose([\n        transforms.Resize((256, 256)),\n        transforms.ToTensor()\n    ]),\n}\n","metadata":{"id":"9oGdFrDawXeu","trusted":true,"execution":{"iopub.status.busy":"2024-12-04T22:52:48.099327Z","iopub.execute_input":"2024-12-04T22:52:48.099729Z","iopub.status.idle":"2024-12-04T22:52:48.108494Z","shell.execute_reply.started":"2024-12-04T22:52:48.099693Z","shell.execute_reply":"2024-12-04T22:52:48.107595Z"}},"outputs":[],"execution_count":28},{"cell_type":"markdown","source":"## Data Directory Setup\n\n\n\nThis sets the path to the directory where the dataset is stored. It's essential for the notebook to access the training and testing data.","metadata":{"id":"6c021840"}},{"cell_type":"code","source":"# Load datasets and create dataloaders for training, validation, and testing \nimage_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val', 'test']}\ndataloaders = {x: DataLoader(image_datasets[x], batch_size=16, shuffle=True, num_workers=2) for x in ['train', 'val', 'test']}\ndataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val', 'test']}\nclass_names = image_datasets['train'].classes\nnum_classes = len(class_names)\n\nprint(\"Classes:\", class_names)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T22:52:50.225203Z","iopub.execute_input":"2024-12-04T22:52:50.225863Z","iopub.status.idle":"2024-12-04T22:52:58.520419Z","shell.execute_reply.started":"2024-12-04T22:52:50.225829Z","shell.execute_reply":"2024-12-04T22:52:58.519548Z"}},"outputs":[{"name":"stdout","text":"Classes: ['benign', 'malignant']\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"# # data_dir = \"/content/drive/MyDrive/Ensemble Learning on LIDC Dataset/data\"  # Set the directory for the data\n\n# # image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n\n# #                                           data_transforms[x])\n\n# #                   for x in [ 'test', 'train', 'val']}\n\n# # dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=16,\n\n# #                                              shuffle=True, num_workers=2)\n\n# #               for x in ['train', 'val','test']}\n\n# # dataset_sizes = {x: len(image_datasets[x]) for x in ['test', 'train', 'val']}\n\n# # class_names = image_datasets['train'].classes\n\n# # num_classes = len(class_names)\n\n# # device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\n# # print(class_names)\n\n# # Set the path to the data directory\n\n# data_dir = \"/kaggle/input/ensemble-learning-on-lidc-dataset/data\"\n\n\n\n# # Verify the contents of the data directory\n\n# print(\"Contents of data directory:\")\n\n# !ls \"{data_dir}\"\n\n\n\n# # Load the datasets\n\n# data_transforms = {\n\n#     'train': transforms.Compose([\n\n#         transforms.Resize((256, 256)),\n\n#         transforms.ToTensor(),\n\n#         transforms.Normalize(mean, std),\n\n#     ]),\n\n#     'val': transforms.Compose([\n\n#         transforms.Resize((256, 256)),\n\n#         transforms.ToTensor(),\n\n#         transforms.Normalize(mean, std),\n\n#     ]),\n\n#     'test': transforms.Compose([\n\n#         transforms.Resize((256, 256)),\n\n#         transforms.ToTensor(),\n\n#         transforms.Normalize(mean, std),\n\n#     ]),\n\n# }\n\n\n\n# # Define the datasets and dataloaders\n\n# image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x])\n\n#                   for x in ['train', 'val', 'test']}\n\n# dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=16,\n\n#                                              shuffle=True, num_workers=2)\n\n#                for x in ['train', 'val', 'test']}\n\n# dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val', 'test']}\n\n# class_names = image_datasets['train'].classes\n\n# num_classes = len(class_names)\n\n# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\n\n\n# # Display the class names\n\n# print(\"Classes:\", class_names)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0TxSDbhXwXhD","outputId":"e8293fb3-6a4c-4be8-88d5-237411dcc66b","trusted":true,"execution":{"iopub.status.busy":"2024-12-04T22:52:58.522189Z","iopub.execute_input":"2024-12-04T22:52:58.522837Z","iopub.status.idle":"2024-12-04T22:52:58.528315Z","shell.execute_reply.started":"2024-12-04T22:52:58.522795Z","shell.execute_reply":"2024-12-04T22:52:58.527384Z"}},"outputs":[],"execution_count":30},{"cell_type":"markdown","source":"## Visualization Function\n\n\n\nHere we define a function to visualize images in the dataset. It will help in understanding the data and debugging the data loaders.","metadata":{"id":"97b79c30"}},{"cell_type":"code","source":"def imshow(inp, title):\n\n    \"\"\"Imshow for Tensor.\"\"\"\n\n    inp = inp.numpy().transpose((1, 2, 0))\n\n    inp = std * inp + mean\n\n    inp = np.clip(inp, 0, 1)\n\n    plt.imshow(inp)\n\n    plt.title(title)\n\n    plt.show()","metadata":{"id":"t957VPeRwXjx","trusted":true,"execution":{"iopub.status.busy":"2024-12-04T22:52:58.529429Z","iopub.execute_input":"2024-12-04T22:52:58.529690Z","iopub.status.idle":"2024-12-04T22:52:58.545061Z","shell.execute_reply.started":"2024-12-04T22:52:58.529665Z","shell.execute_reply":"2024-12-04T22:52:58.544442Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"# Get a batch of testing data\n\ninputs, classes = next(iter(dataloaders['test']))\n\n# Make a grid from batch\n\nout = torchvision.utils.make_grid(inputs)\n\nimshow(out, title=[class_names[x] for x in classes])","metadata":{"id":"S3t4wxmKwXmK","colab":{"base_uri":"https://localhost:8080/","height":207},"outputId":"a483b3e9-79ae-438d-91b5-fd30a88d1688","trusted":true,"execution":{"iopub.status.busy":"2024-12-04T22:52:58.547095Z","iopub.execute_input":"2024-12-04T22:52:58.547795Z","iopub.status.idle":"2024-12-04T22:52:59.474365Z","shell.execute_reply.started":"2024-12-04T22:52:58.547768Z","shell.execute_reply":"2024-12-04T22:52:59.473484Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAABOIAAAC+CAYAAACYhaDZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOy9eZh0V1ktvmqeq6u/OYEQIKAyKRgIQYhM0eiNepEojpBwvRhjEiQRLuBPJQElgPoQJJCLXk1uEC6DA3pFIkZBFKNiiIrJBYIQQkK+sYeaq7qrzu+Pftbudd7e1UklXwaadz3P93T3qXP2+O5d37vOet+dSZIkgcPhcDgcDofD4XA4HA6Hw+F4QJF9qBvgcDgcDofD4XA4HA6Hw+FwfDPAiTiHw+FwOBwOh8PhcDgcDofjQYATcQ6Hw+FwOBwOh8PhcDgcDseDACfiHA6Hw+FwOBwOh8PhcDgcjgcBTsQ5HA6Hw+FwOBwOh8PhcDgcDwKciHM4HA6Hw+FwOBwOh8PhcDgeBDgR53A4HA6Hw+FwOBwOh8PhcDwIcCLO4XA4HA6Hw+FwOBwOh8PheBDgRJzD4XA4HA6Hw+FwOBwOh8PxIGAuIu68885DJpNBJpPBk5/85G3vvfbaa5HJZPAv//Iv96uB9xWZTAaXXXbZQ1L3fcV5552Her3+kNT9yU9+EplMBp/85CcfkvrvKx796EfjB37gBx6Sui+77DJkMpmHpO77ittvvx2ZTAa/+Zu/+ZDU/7znPQ/Pe97zHpK67yt8L5sfvpfND9/L5oPvZfPD97L54XvZ/PC9bD74XjY/fC+bH76XzQ/fy+bDN+te9qpXvSrwY/OusbkVcXv27MF73/tevOUtb0ldf/SjH/0NtyndX/CL4L6AxvqNtindX5x33nn3eZHcn/H+Rsb9WVv3Z7y/UXF/15bvZfPB97L54XvZ/PC9bH74XjYffC+bH76XzQ/fy+aH72Xzwfey+eF72fzwvWwDL33pS/He974XZ5xxxtzl5ed9oFar4ad/+qfnrujBxmAwQD4/d/e+afHd3/3dGAwGKBaLD3VTvmHwy7/8y3jd6173UDfjGwof//jHH+omfMPB97L54HvZ/PC9bH74XjY/fC+bD76XzQ/fy+aH72Xzw/ey+eB72fzwvWx+PFR72amnnopTTz0VN9xwAz772c/O9eyO3UXK5fJD3YRvKGSzWR+zOZHP5/2LeE74l/D88HU5H3wvmx++l80P38vmh6/L+eB72fzwvWx++F42P3xdzgffy+aH72Xz4xtxL3vAD2vo9/s4//zzsXv3bjSbTbzsZS/D8vLylvs+9rGP4YwzzkCtVkOj0cDZZ5+NW265JXUP49vvuusuvOhFL0K9XsfevXvx6le/GpPJJHVvLH7/k5/8JJ7+9KejXC7jlFNOwXve855oDHYmk8FFF12Ej3zkI3jyk5+MUqmEJz3pSbj++uuPz6DcA7785S/jrLPOQq1Ww4knnog3vvGNSJIkdc90OsWVV16JJz3pSSiXy9i/fz/OP//8LWPL+Pa///u/x2mnnYZyuYzHPvaxuO6661L3zYrff9e73oXHPvaxqFQqOO200/B3f/d3W2Kw+eyHPvQh/Pqv/zoe+chHolwu44UvfCG+9KUvHdexmYWPf/zjeOpTn4pyuYwnPvGJ+OM//uMt96ysrOBVr3oVTjrpJJRKJTzucY/DW9/6Vkyn03CPxrf/zu/8Dk455RSUSiU84xnPwGc+85lUeTHbGQwGeOUrX4k9e/ag0Wjgh37oh3DXXXdtsUc++6UvfQnnnXceWq0WFhYW8PKXvxz9fv/4Ds4MvP3tb8fJJ5+MSqWC5z73ufiP//iPLfd8/vOfx4/8yI9g165dKJfLePrTn44/+7M/S91DOfenP/1pXHrppdi7dy9qtRp++Id/GEeOHEndG4vf/+pXv4of+qEfQq1Ww759+3DJJZfgL//yL7fY4/Oe9zw8+clPxq233ornP//5qFareMQjHoG3ve1tx21MtoPvZfPD97L54XvZ/PC9bD74XjY/fC+bH76XzQ/fy+aD72Xzw/ey+eF72fzwveze4QGnWi+66CK0Wi1cdtll+MIXvoCrr74aX/3qV8PCAoD3vve9OPfcc3HWWWfhrW99K/r9Pq6++mo85znPwc0334xHP/rRobzJZIKzzjoLz3zmM/Gbv/mbuOGGG/Bbv/VbOOWUU3DBBRfMbMfNN9+M7/u+78MJJ5yAyy+/HJPJBG984xuxd+/e6P1///d/jz/+4z/Gz//8z6PRaOC3f/u3cc455+COO+7A7t27j+sYKSaTCb7v+74Pp59+Ot72trfh+uuvxxve8Aasr6/jjW98Y7jv/PPPx7XXXouXv/zleOUrX4mvfOUruOqqq3DzzTfj05/+NAqFQrj3S1/6En7kR34EP/MzP4Nzzz0Xv//7v4/zzjsPp556Kp70pCfNbMvVV1+Niy66CGeccQYuueQS3H777XjRi16ExcVFPPKRj9xy/1ve8hZks1m8+tWvxurqKt72trfhp37qp/BP//RPx3eQDG677Tb82I/9GH7u534O5557Lq655hr86I/+KK6//np8z/d8D4CNL+vnPve5uOuuu3D++efjUY96FP7hH/4Br3/963H33XfjyiuvTJX5/ve/H51OB+effz4ymQze9ra34cUvfjG+/OUvp8bW4rzzzsOHPvQhvPSlL8Xpp5+Ov/3bv8XZZ5898/6XvOQleMxjHoMrrrgCn/3sZ/G//tf/wr59+/DWt771uIzNLFx33XXodDq48MILMRwO8Y53vAMveMEL8LnPfQ779+8HANxyyy149rOfjUc84hF43eteh1qthg996EN40YtehD/6oz/CD//wD6fKvPjii7G4uIg3vOENuP3223HllVfioosuwgc/+MGZ7ej1enjBC16Au+++G7/wC7+AAwcO4P3vfz8+8YlPRO9fXl7G933f9+HFL34xXvKSl+AP//AP8drXvhZPecpT8P3f//3Hb4Ai8L1sPvheNj98L5sfvpfND9/L5oPvZfPD97L54XvZ/PC9bD74XjY/fC+bH76XzYFkDpx77rnJySeffK/uveaaaxIAyamnnpqMx+Nw/W1ve1sCIPnTP/3TJEmSpNPpJK1WK3nFK16Rev7gwYPJwsJC6vq5556bAEje+MY3pu592tOelpx66qmpawCSN7zhDeHvH/zBH0yq1Wpy1113hWu33XZbks/nEzsMAJJisZh86UtfCtf+7d/+LQGQvPOd77xX/b8vYP8uvvjicG06nSZnn312UiwWkyNHjiRJkiR/93d/lwBI3ve+96Wev/7667dcP/nkkxMAyac+9alw7fDhw0mpVEp+8Rd/MVz7xCc+kQBIPvGJTyRJkiSj0SjZvXt38oxnPCNZW1sL91177bUJgOS5z33ulmef8IQnJKPRKFx/xzvekQBIPve5z92/gdkG7N8f/dEfhWurq6vJCSeckDztaU8L1970pjcltVot+eIXv5h6/nWve12Sy+WSO+64I0mSJPnKV76SAEh2796dLC0thfv+9E//NAGQ/N//+3/DtTe84Q0p27npppsSAMmrXvWqVB3nnXfeFnvks//tv/231L0//MM/nOzevfs+jMS9A/tXqVSSO++8M1z/p3/6pwRAcskll4RrL3zhC5OnPOUpyXA4DNem02nyXd/1XcnjH//4cI1r/cwzz0ym02m4fskllyS5XC5ZWVkJ15773OembOe3fuu3EgDJRz7ykXBtMBgk3/Zt35ayRz4LILnuuuvCtdFolBw4cCA555xz7vug3AN8L5sfvpfND9/L5oPvZfPD97L54XvZ/PC9bD74XjY/fC+bH76XzQ/fy+bDN/tedu655ya1Wu1e3Us84KGpP/uzP5tidy+44ALk83n8xV/8BQDgr/7qr7CysoKf+ImfwNGjR8O/XC6HZz7zmVHW8ud+7udSf59xxhn48pe/PLMNk8kEN9xwA170ohfhxBNPDNcf97jHzWQ4zzzzTJxyyinh72//9m9Hs9nctp7jhYsuuij8TgnzeDzGDTfcAAD48Ic/jIWFBXzP93xPasxOPfVU1Ov1LWP2xCc+MXWSx969e/Gt3/qt2/blX/7lX3Ds2DG84hWvSMWo/9RP/RQWFxejz7z85S9PxWezzgd6zE488cQUc055+s0334yDBw8C2BizM844A4uLi6kxO/PMMzGZTPCpT30qVeaP/diPpfp5b/pCWfnP//zPp65ffPHFM5+J2fKxY8fQbre36/L9xote9CI84hGPCH+fdtppeOYznxnW5dLSEv7mb/4GL3nJS9DpdMJ4HTt2DGeddRZuu+023HXXXakyf/ZnfzYloz7jjDMwmUzw1a9+dWY7rr/+ejziEY/AD/3QD4Vr5XIZr3jFK6L31+v11GExxWIRp5122oOyLn0vmx++l80H38vmh+9l88P3svnhe9l88L1sfvheNj98L5sfvpfNB9/L5ofvZfceD3ho6uMf//jU3/V6HSeccAJuv/12ABuSTwB4wQteEH2+2Wym/i6Xy1ukvouLi9GcAMThw4cxGAzwuMc9bstnsWsA8KhHPWrLtXuq53ggm83isY99bOrat3zLtwBAasxWV1exb9++aBmHDx9O/X1f+kLDtuOTz+dTMu7t6uEm80CP2eMe97gtcfQ6ZgcOHMBtt92Gf//3f58pE7+nMbs3ffnqV7+KbDaLxzzmMVvaNwvb1WNt/3jCrktgY8w+9KEPAdiQmidJgl/5lV/Br/zKr0TLOHz4cGqjva9jdsopp2yZv1lj9shHPnLLvYuLi/j3f//3mXUcL/heNh98L5sfvpfND9/L5ofvZfPB97L54XvZ/PC9bH74XjYffC+bH76XzQ/fy+49HvLjOJjE8L3vfS8OHDiw5XN7Ykgul3tQ2jWrnsQktHwoMJ1OsW/fPrzvfe+Lfm43ggerLw/3Mfue7/ke/I//8T+in3NTJb7Zx4zr8tWvfjXOOuus6D12I3sw+vJwHS/A97L7At/L5ofvZfPB97L54XvZ/PC9bH74XjYffC+bH76XzQ/fy+aH72XzwfeyTTzgRNxtt92G5z//+eHvbreLu+++G//lv/wXAAjS3H379uHMM898QNqwb98+lMvl6OkqD9aJK/cW0+kUX/7yl1OL9otf/CIAhLcEp5xyCm644QY8+9nPRqVSeUDacfLJJwPYGB+dv/X1ddx+++349m//9gek3vsCMuvKYsfGrNvtPmA2BmyM2XQ6xVe+8pXU24CHm40Bm28JFV/84hfDePGNWaFQeMDH7NZbb90yfw/XMfO97N7D97L54XvZ/PC9bH74XjYffC+bH76XzQ/fy+aH72Xzwfey+eF72fzwveze4wHPEfc7v/M7WFtbC39fffXVWF9fD3HzZ511FprNJt785jen7iPs0bT3BblcDmeeeSY+8pGP4Otf/3q4/qUvfQkf+9jH7nf5xxtXXXVV+D1JElx11VUoFAp44QtfCGDjFJTJZII3velNW55dX1/HysrK/W7D05/+dOzevRu/+7u/i/X19XD9fe973wMuA54XX//61/Enf/In4e92u43rrrsOT33qU8MbsJe85CW48cYb8Zd/+Zdbnl9ZWUn18b6CrP673/3u1PV3vvOd97vs442PfOQjqfj7f/7nf8Y//dM/hXW5b98+PO95z8N73vMe3H333VuePx7rEtgYs7vuuit1XPVwOMTv/u7vHpfyjyd8L5sfvpfNB9/L5ofvZfPD97L54XvZfPC9bH74XjY/fC+bH76XzQffy+aH72X3Hg+4Im48HuOFL3whXvKSl+ALX/gC3v3ud+M5z3lOSJzXbDZx9dVX46UvfSm+8zu/Ez/+4z+OvXv34o477sBHP/pRPPvZz05tGvcVl112GT7+8Y/j2c9+Ni644AJMJhNcddVVePKTn4x//dd/vd/lEzzu+ZprrsF555039/PlchnXX389zj33XDzzmc/Exz72MXz0ox/FL/3SLwU58HOf+1ycf/75uOKKK/Cv//qv+N7v/V4UCgXcdttt+PCHP4x3vOMd+JEf+ZH71Y9isYjLLrsMF198MV7wghfgJS95CW6//XZce+210Xjr+4PzzjsP//t//2985StfmZkbYDt8y7d8C37mZ34Gn/nMZ7B//378/u//Pg4dOoRrrrkm3POa17wGf/Znf4Yf+IEfCMdq93o9fO5zn8Mf/uEf4vbbb8eePXvuVz9OPfVUnHPOObjyyitx7NixcLQ035wczzHjODGnw7x43OMeh+c85zm44IILMBqNcOWVV2L37t0pWfW73vUuPOc5z8FTnvIUvOIVr8BjH/tYHDp0CDfeeCPuvPNO/Nu//dv97sf555+Pq666Cj/xEz+BX/iFX8AJJ5yA973vfSiXywCO35jdfvvteMxjHoNzzz0X11577X0qw/ey+eB72aPnft73svnhe9n88L1sPvhe9ui5n/e9bH74XjY/fC+bD76XPXru530vmx/fbHvZ/cEDTsRdddVVeN/73odf/dVfxdraGn7iJ34Cv/3bv53q/E/+5E/ixBNPxFve8hb8xm/8BkajER7xiEfgjDPOwMtf/vLj0o5TTz0VH/vYx/DqV78av/Irv4KTTjoJb3zjG/H//t//w+c///njUgewIYsGgBNOOOE+PZ/L5XD99dfjggsuwGte8xo0Gg284Q1vwK/+6q+m7vuf//N/4tRTT8V73vMe/NIv/VJIcPnTP/3TePazn32/+wFsnKyTJAl+67d+C69+9avxHd/xHfizP/szvPKVrwxGfDzQ7XZRqVTQarXu0/OPf/zj8c53vhOvec1r8IUvfAGPecxj8MEPfjAVd16tVvG3f/u3ePOb34wPf/jDuO6669BsNvEt3/ItuPzyy7GwsHBc+nLdddfhwIED+D//5//gT/7kT3DmmWfigx/8IL71W7/1uI5Zr9fbNkHnPeFlL3sZstksrrzyShw+fBinnXYarrrqqpTdPvGJT8S//Mu/4PLLL8e1116LY8eOYd++fXja0562xR7vK+r1Ov7mb/4GF198Md7xjnegXq/jZS97Gb7ru74L55xzznEbs/u7LgHfy+aF72Xzw/ey+eF72fzwvWw++F42P3wvmx++l80P38vmg+9l88P3svnxzbaX3S8kc+Dcc89NTjrppOTIkSPJ8vLyPI8+bPFf/+t/TR73uMcdt/J+9Ed/NHnGM55x3Mp7uGEymSS7du1K/vt//+/Hrcx9+/Ylr371q49beQ833HzzzQmA5A/+4A+OS3m33HJLAiD58z//8+NS3sMRb3/72xMAyZ133nlcynvXu96V1Gq15ODBg8elvIcjfC+bD76XzQ/fy+aH72Xzw/ey+eB72fzwvWx++F42P3wvmw++l80P38vmx/Hey7rdbnLkyJHkx3/8x5NarTbXs3PniPva176GvXv34jnPec7x4gIfNAwGg9Tft912G/7iL/4Cz3ve845L+UmS4JOf/CR+7dd+7biU91BjOBxuOSnkuuuuw9LS0nEbs1tuuQWDwQCvfe1rj0t5DzWsjQHAlVdeiWw2i+/+7u8+LnV84hOfwLOe9SycffbZx6W8hxp2zIbDId7znvfg8Y9/fOro6vuDT3ziE3jlK1+J/fv3H5fyHmr4XjYffC+bH76XzQ/fy+aH72Xzwfey+eF72fzwvWx++F42H3wvmx++l82PB2Mv+//+v/8Pe/fuxQc+8IG5n80kdhVsg1tvvTUkoqzX6zj99NPnrvChxAknnIDzzjsPj33sY/HVr34VV199NUajEW6++ebUCSSODXzyk5/EJZdcgh/90R/F7t278dnPfha/93u/hyc84Qm46aabUCwWH+omPuxw+eWX46abbsLzn/985PN5fOxjH8PHPvYx/OzP/ize8573PNTNe1ji+7//+/GoRz0KT33qU7G6uoo/+IM/wC233IL3ve99+Mmf/MmHunkPS/heNh98L5sfvpfND9/L5ofvZfPB97L54XvZ/PC9bH74XjYffC+bH76XzY8HYy/74he/iDvuuAMAkM/n5yOSj4sm7xsE5513XnLyyScnpVIpaTabyVlnnZXcdNNND3WzHrb4yle+kvzgD/5gsn///qRQKCT79+9PXv7ylyeHDh16qJv2sMXHP/7x5NnPfnayuLiYFAqF5JRTTkkuu+yyZG1t7aFu2sMWb3/725MnPelJSa1WS8rlcvKd3/mdyQc+8IGHulkPa/heNh98L5sfvpfND9/L5ofvZfPB97L54XvZ/PC9bH74XjYffC+bH76XzY+H+142lyLO4XA4HA8+3vWud+E3fuM3cPDgQXzHd3wH3vnOd+K00057qJvlcDgcDofD4XA4HI45MXeOOIfD4XA8ePjgBz+ISy+9FG94wxvw2c9+Ft/xHd+Bs846C4cPH36om+ZwOBwOh8PhcDgcjjnhijiHw+F4GOOZz3wmnvGMZ+Cqq64CAEynU5x00km4+OKL8brXve4hbp3D4XA4HA6Hw+FwOOZB/qFugMPhcDjiGI/HuOmmm/D6178+XMtmszjzzDNx4403brl/NBphNBqFv6fTKZaWlrB7925kMpkHpc0Oh8PhcDjuH5IkQafTwYknnohs1gOYHA6HY6fBiTiHw+F4mOLo0aOYTCbYv39/6vr+/fvx+c9/fsv9V1xxBS6//PIHq3kOh8PhcDgeQHzta1/DIx/5yIe6GQ6Hw+E4znAizuFwOHYIXv/61+PSSy8Nf6+uruJRj3oUbrzxRiwuLqbunUwmSJIExWIRw+EQ6+vrSJIESZJgbW0No9EIhUIBhUIB6+vrWFtbQzabDW/mM5kMstkskiRBPp9HkiTI5XLhWqFQCGUBG0d6T6dTZDKZUFaxWMRkMgmfj8djrK+vo1AoYDKZBHVfJpNBkiTIZDLI5XLIZDKYTqeYTCbheX7Gfn/lK1/Bvn370Gq1QlvY5rW1NSwvL2N1dRWj0SiUs76+jslkgvF4jLW1NWQyGZRKJVSrVVQqFWSzWUynU6yvr2M4HGI6nWJtbQ3r6+uhbJaVzWaDCpFjw7+z2Szy+TwqlQoAoFgsolqtolwuo1qtYnFxEblcDktLS7jzzjtx9OhRjEYj5HI51Go1LC4uolarYTQahTnLZDJYX19HvV7HiSeeGMaE7VJFhY6F2kO/30e320W320Wv18NwOMRwOMRoNMLa2homk0kY50KhgHw+H+aC8zGdTpEkSeh/kiThGtvENui/bDaLQqGAer2OPXv2YM+ePWg2myiXyygWi8jlcsjn86FOzsFwOMShQ4dw0003hbJ5DwBUKhU0m03kcjmsrKyg1+shlpHDKkar1SpKpRLW19fR6/VC32nDvJ/zrf0oFosol8vIZrMYjUYYDoeYTCahDwCCrWUyGeTz+WC7LEfnj78XCgWUSqWwlnq9HtbX10ObS6UScrkc1tfXMR6PQ9t03eh8aLs5p/wdQFgH2WwWuVwO1WoVSZJgPB6HvhQKhdRY79mzB2tra+h0OhiNRlhfX8f6+jqm02lY3zEbzOfzYQ00m02USiXU63XUajUUCoWwbgDgzjvvxOc+97mwHnWPsHN7T0pgHV875vY+3fM4hqyfY8Qx5FqgveRyuXBdx8DWyWt2vdDWnvCEJ2BpaQnLy8th/2HdHB+2aTqdhrlcX19HNpvFeDzGdDpFpVIJ9r2+vh7ax75wb+HztN9MJhPmv1gshu8G1s89s9lsolAooNfrodPpYDgchrbyHu7zbBv3w36/H67RnkulUnQuLLLZLBqNBnbv3o1WqwUAGAwG6Pf7QTE+HA5DHSxL55T95NhzHu188JqCZXDOdd3ZvY/jyu9Lrm3uEYcOHcJll12GRqOxpR6Hw+FwfOPDiTiHw+F4mGLPnj3I5XI4dOhQ6vqhQ4dw4MCBLfeXSqWUw0Ls3bs3kBP5fB6lUglJkgSiq1arYTgcBidNiQQ6CdVqFevr6yiXy4GMyufzqNfrweEmmUIHZDQahbrofPV6PRSLxVA2HbjJZIJisRjIuUwmg3K5jOFwiCRJAglAJ9Y6rgACITidTjEajbC8vIzJZIJKpRLIHJIpJBLYZ5Io0+kUhUIh/E4CIZfLoVKpoFqtYm1tLZAUJCPYZ17L5XIpgkrHp1AooFgsotFoBFJpOp1iMBhgOp2GeaQTnyQJyuUyKpUKdu3ahX379qFerwfSkmQIHd6FhYWUw2idSvZVyTI6pXTu19bWtjiVdDzphNNxZLkkJelcEkpMaN20AZKptLNGo4GFhQU0m03UajWUSqUwdsViMZC5/X4fg8EAw+EQ5XI5zD3nI5vNol6vB1KA40n74v3qZLOvlUoF9Xodk8kE+Xweg8EgzJM6yyQiAITx5JxzvXHNkFig3ZOw5drUfzp2nINCoRDIWo4H52M8Hoc1nc1m0Wq1UC6XQ1u17SRAut0uBoNBsGUl41luqVRCsVgMbVlbW0vNpxIZmUwGy8vLgbjl+I7H40CclMvlYMvsO+si6Voul9FqtdBoNFLzzf1hNBqhVquFubSwpEdsv7Bkm/aZY8Z1oWQb+8r+syzas+4xSsSprbPs2Pq0ZKIlfh75yEeiWCyGNVqv1zGdTsPLFM6ZJX+4r1arVeTz+dB+jimv0ZbL5XJq3ZOIK5fLYX65ZovFYmpcaWMkyjOZzJY9mLaRy+XQaDQCSZvJZAL52u/3w1pptVrhe4L7iI4T54ZtJhlYqVQwGAxw+PDhsIYBBCKQZJ7uBSyL8wkg9cJHSXjOr86djrvaF78juGcDCO3hiw2S57STmK06HA6HY2fAiTiHw+F4mKJYLOLUU0/FX//1X+NFL3oRgA1n7K//+q9x0UUX3etyJpNJICdIKpAQoaOkyhoSBHQc6XyQ8FEHaG1tLVynwzAej4MToSoNOnPqqNDRJYFAtQ+dNKo4+v1++IxlKDGkxBj70O12MRwOg+OTz+dRLBZRKBQC0URSkU4VHUwgTSCRpKBzViqVwr2qguP97AudPTq0dFTr9XpQI5LIBDbUG6PRCOVyGePxGMPhMDjLJOFarVYYC5ItJA3G4/EWNZ7+1L7pZ/o7+6ukmipQ1AaUSKJ6knOhtqPzpQ6rQlUkStYpaajKR5KVJGsIrYdEmbZZiRHtM+eNds11o3NhbYMEgpbHsqxDrspAHVMlI60Kzo4PCTPaebvdTpG5HB+SlGw/lZ/5fB7ZbDaMC0lmEhO0T1WcDgaD1LhVq9VAiFF5x3lbX18P9sx5LJfLYa7Yd6oMWXelUgn2MplM0Ol0kCQJarVaUDWSYCKJoXNhCUE7bvZ3vZ/P8CdJ5iRJMBgMAqlo/9k26H5p77Hkkd1HtQxCiT/t4+LiItrtNg4fPpzas1QtSkKayttyuYy1tbWwv7Cd3As5j5x/HddqtRqIY+5TJN/G43HYC9lOqs5oe/1+P6jmeA/3xFwuF8aYexnth+3gWlQbVKKT40vb5z1UGnNsOD+sX8ddCT7Ww7/1BQDvjb1smLWn6c9cLod6vY7FxcXUywPOTa/XC4Shfic7HA6HY+fBiTiHw+F4GOPSSy/Fueeei6c//ek47bTTcOWVV6LX6+HlL3/5vS5DnX8NN9M3+ySmqLShs24JGKoaSG7QSVLSRZ0d69zwcxJbdKTUcad6ANhwRumAkxhiX5IkCaSBOtNKJg2Hw6DgImlEhRXbQKeLqiIbfsY6Vb3A8uiA6jjTiVQCSkOyWq0Wdu3ahXw+j6WlpeCIsh4Sj+z/nj17UKvVsGfPHuzatSs4cHRuWReVS7G5n0Xw6HjZEFMNvbKEkpJ+VADa31VVRzLNhvTRvvQn+63KM5JqnHP2m2oeACkCT+eCoaHWVrX/Wr+q2lQFqWSsPqfhmfzckjF27FmP1qltU6JTQ4sZsq0hhaVSCZPJJIRLK7mcy+VC/6mM07VCO1ZFlyo9rerHtpnKWRIfxWIxkJN8VtVjCs4X12elUglKRA1L5drs9/uYTqeBpLM2PUtVZqF7miW5dBx03VrSOla+ErkKS+DFFE62TLZH+0dFI4nJpaWlsJfbFxg6Zwru6ap0476mik7aNdcX902GrJLss/bLeeVaUyUwbYKklpKBSpRxn6B9a5t0nnTcY8pDto99YDkcA47rPc0F7YEqQaoP9TvPfvfoPqBzmsvl0Gw2ceDAgaBcHg6HOHbsGPr9fiBE9XvT4XA4HDsTTsQ5HA7Hwxg/9mM/hiNHjuBXf/VXcfDgQTz1qU/F9ddfv+UAh+2gjhLJEyXa1ElUp05JMSXYSDyoaoFOl3XKlIhi7jmWy9BKqpqs0wWkVSF00PQ6w3noyCnJoGoJtm88HmM0GgVlEMtiW60zr7ndlKgCENpuyUYAQf1BwpIhSc1mE3v37sWuXbvCGDA8djQahfJZd7lcxuLiIvbu3RtypmmYqJKktt/WBni/dfjZV6qklESx93IcNByTxJhVpHDOrQolNl467ixXSTaOs+ansiGudi5plySuNG+aJWA0xxWfJ8lKZQ3HR+fcOtt2TO0atJ8p8UNFpa4b+zwVRxxb7T/tEUAI8SyVSoHEUjKJZdFONXyUv5OQV9KD/VX1lO0blU5K7pI0JpSE49qoVCpoNBrYu3cv6vV6IPkGgwHa7XZYH1xTqo6aRVrEiJZZBB7Hhqo+JVXUpnSO9bmYYjT2nK6jmJ3oT9svEnFUxTHPJedU9zXWQfvnHsh54L5s819ybpWYo/KZa51rSb9HdF/i+tEchTHCW8kzknv6fWNDoFm2HRclwdbW1tDr9dDtdlGv14Mtq6JbiTuON1V/FhwzEpLcU6xNaZ5HnWslGKmGZg5MVVxTDRdrg8PhcDh2HpyIczgcjoc5LrroorlCUS005ItqFzpl/J3OioZ90oGgqmEy2Ujoz3CfyWQS1GWqSqMzT+eDdTO0jyFIVEowFJNOHdsEIIS7sd1UfdEpUxKOhJYSbHSESBzRsZxMJiiXy8E5UxWYhrySLODnzFkHbIZnWXJGE6czNK9SqaBWq2FhYQGtViscttBsNgFsJLpnSBcdWyawbzQaaLVaW3I/cQw1lFSdzJjjq2NgCQjOdYyIs04w71fnXkklJbaoNLTOs62f10jMkGyzc0Pb4HjEiFc69EoG2vyCCktecq41xI42rQcQ2D7pOCjRouSXHVPttxKJlgTScDgS4cPhEN1uNxBxJLTL5TJ27dqFhYUF9Ho9fP3rX0e32w3zblWPNtSOY6D3ZjKZVAhrNptNhaFWq9VwPZ/PB/KN651rWQlRhoBq+eVyGQBSB8bUajXUajWsr6/j2LFjKRJO508Jnhjs52o/XBcMubUvKfR+tVm9bnPEWRLP1m0VcrPWhM5JNruRA5BhptwzuH9zfPUlie5pHHtgk9jLZDKB6GTdXDe0Z77EYdksi/OsBBqA0B4N82Z7uPdz37ZlAgghr/z+YbuUdFM71u+ZdruNarWKWq2GarUa1oYq83SN6fxpHZa81nmKqR/tXqvP6r7NegaDAVZXV7G8vIxut4vxeJyyDYfD4XDsXDgR53A4HDsczG9FZ8UqH+iM6GmgmneNjqk6PAwl03xzJFAymUxQEyl5Np1unNZHZ48KHj3sAUDKUWF9/FtDHtmPRqMRSCl1mFRpwWc1OTkdRyp/GLqnagcNh6TTyHBAfgZsJnknIcKxYAL6RqOBZrMZ8mvRoW40GqhUKsFZ7fV6Yaz10ABLDipBQidYFUdAOol8jDzg76oYVAdVlWO2TI4vsBnaTBvQULYYAagElSrL6JzTYdZE6UrMar9UkafEjO2jEi78m2Xp2KhjTltgonlNVG/L0z5xfaitsnxdJ3rgg+Z4s6SAko9WBUj75Tj1ej3kcjn0ej2MRqNwOiTzTilRxp8sR9VxSuLo6ZgAwumTrJtEGw/b0Ho1nxsJWZ4QyYMb+DtPfc1kMoGMU7UVQ14twawkrCVIYmo2+7cluqzNWJVajEhTO4yRzlrXPCSLtiVJEgyHQ9Tr9dQpm5VKJRA49hRT3WtV3aj7Zb/fT51OrGHAbC/nV08zVYJJcxfqQQQ6/rQrfj8oUQsgEN8cR36H8AWNVf/a9U474PXRaIRerxf2HR1P3sM9zqrjdI40BJ6EuL7w0br1+ydmY2tra1hdXcWhQ4dQLpfRbrdx8OBBHDlyJHU4xSwi2eFwOBw7B07EORwOxw4HyRpVCQGbYXudTgeZzEauml6vhyRJgjOtoWUktTKZjQTelUoFSZKEExo1lw6VLqoQKBQKW/KwJUmCRqMRFBckvVTFpyFLVEyo2ol9JHnDvHBK5GmYlTqIJE1ICvB0Rnt4haommNycY2OdcJIs1Wo1JJmvVCrhJx1PtpWEXDa7ccqnnoBIB1mdQ5tHTAkzJQGUtOEYqdOpKjg60hryyvHXebRzSpvQOaHShaSnKlesA83fLbFm1ZmaC4v/SPAq2aMEmzrNqm7kOFjb4PM6dkyiTvKVOdDU4VfnmWMfy0PF+kulUiBkSZ5p/kO2yTrkSvSxfbQPAKk8j9lsFs1mE7t378ZoNApqNFWk0SaUBFQbYQgw87UBQLfbxdLSUiDFNFSURHY2mw1jxc+pfiOJRGUpx0tPzNUTLTkHJIF0DPQkaKvos0SvJU1n7ZOW+LLrRcu3cxtT2im0PFuPlqnl8qcSvSSwFhYWsG/fPnz9618PIY3FYhHNZjOlJKUdcW+zLye4lnK5XAhz1dybtGcq2fQ5kuV2f6JSOpPZUMSSKGRZnPNMJhMIKJ4wTBtlvy2Jxvq1XiWv+RKAbeCLAs1dSGg5ltizije1CVXoat91X7EkP7CxRo8dOxbCy3u9HjqdTnih5XA4HI5vHjgR53A4HDsco9EI7XY7OGtKulA1QMWCJrbXExGpBiDJtb6+jm63G5y3ZrMZnGdN0l8qlQBs5tlRwkLDcFSdpKFMSmx1u92UCkVPCdQyeSqgKh7oVJGMoMqCaieq5RYWFsJndNoGg0E4+U8Rc8JJIlApVCqV0Gg0UknP6cySNFFnjURNpVIJ48m6VAmloaWWhIsphqxqSO/VkE8NSbWkQqw+e+AFyTsbLmaVXTqGaheqdrH1McchgJR6iqSd5mhSEkaJZAsl0nQslCRieCqVW7TvWF8s6WnBtWSVXAolEGPqKiXRGCauJ5syrLLf72NpaSmo41T5qOSGJTu4BhkSWiqVcMIJJyCXy+HQoUMYDAYpclXLoIpWSS/aOQm7YrEYQs15ajNPTaU9xUJllcBmTjkSSJZUZjtiyiK7Tuwc6k8lf2JKJ96rNqpzrXaocxubV93bbNu4LvQAi3K5jH379oX9jmoyVa6pkov1U+3IFx9UNJLw55zY/UaJKt2DdO3SLnQ/4AsFTQ+gNs6XKGrbrFeJPoUS+xoSy+8LhjKTpLW5F/WFAvdl2r0eXmHtwtqRLYvPxVRt/JsnGpNUVdWs2lqsTofD4XDsHDgR53A4HDscd999N0qlEobDIdbW1kLYGB0PDVWlg6TOPoDg0NA5oVPFUCaG8BUKBfT7fXQ6HRQKBdTr9XCqI0kozXWmRA6dMaqfmJNIQ51ImqnTS8eP7bWKE+0H/7YkQrlcDqRDpVJJOWbdbhfLy8vo9XqputSxVEUGiTiSN0qqqWNJVYk6rxxrko8xRy/m9PO6/TtGwtnPlYhTApL16liqg6jEnTqfLJMOLR3OWeSUtgXAlrL0c9qtDWnlc9q/GJljx8rahyWWaE+cE6pAAQRnWsdRQ4FtHWrzAFKHD6iKhu1TQjRGgqq6UxPjkwibTqfhRF4lVNSedCzZXq5TSwQpsc2+WgJFQ1pj80lyn/UxLL1cLofcXtlsNqxBHUsN6S2VSoFs4WmWDMFlzjxVter4z8I9ER+x9cVxsTZliXA7dwqrvLL1qf1wz+B4NxoNHDhwAEmS4OjRo6ncnHqaL4DwYkPVrgRzWGrOOfuiQFV2uhfonsuXEbyXNql7OD/TQxBI8ul6s4S/toW2b4lAtbnpdBq+85h/Tcu0JKvuJdxftXydA93H7T5jlciW9LX56ex9akMOh8Ph2LlwIs7hcDh2OO64446Q6FxVI+poKUlCB0rDWOnoUw1HZYUqYcbjMcrlcvisXq9jbW0thAkxHI2HF9BZoXJEQ0apoGHSd6p86OhTuaAOC9U2DJNlOaq+oCPFdtNRU1XC+vo66vV6Si3HZ+mk8h/rVQKGpA37rTnclKigM6ckmR0TAKncb0qGqKPI54G4Qm4WSUeHlvNrc8Wpbajiyyq/tHy2URVJ6qzGfqqzqqGpmmie95K84thqnUoQWEJEw0VnwTr0VOExHFUJIgAhrE6Ju1iYopIyNlTPEm5WEaWEhw21ZNiskrgMP+Rz1Wp1Sz46S7QpMUBlFP8eDAY4fPgwkiQJOQz7/X4IXdX1kclk0Gg0Uoo5tU2C9s01oYccMPSSRDdJHM4hSf1yuRzCZnk/f3JerG3q7zq+MbvcDvZeJeMsGatzYZ/Tud6uHbxvNBqFnJjMyba4uIi1tTUMh0MsLy+H/VdJIiVN2SaqlQGgVqthcXER3W4Xq6urQVVH6N5mFbOaRoAqPN6rLzx0T+PzhUIh7Dk6RnxhAyC8ONL8mBwTJbNoQzyBdDrdzHVKVTNtX9vBPVDzkNp0BPodwrnWeVYCnz+tbemYWfvT9c2+zCJoHQ6Hw7Ez4EScw+Fw7HAw1xvJH5Je0+k0HDqgSgtV9gCbToTmTlNnQZ0bHmZAp2J1dRXZ7MYpf1Se9ft9jMfjoGZRskxVYnSiAASFGZ1PTRbO8DQSSSxPyRQNs1InS8O0qCDqdrspxQ3HQMeE7dKyAIS2VCqVoJ7i4Q96+IBNnG9JKd6vxCSwmQCd/Vanm4oXq84grLPI+kh+8J+Gh1kyhfeTACQppQ6pOt/EdqSgfq7l2lBTvdcSdKrAY9vtPz3plOPC+aMTT9tlf9VGND8ilWcMC2Qb1EmPEQdK2lklDvvFe5XQ07HRsdVcarVaDY1GI7XGOackwUmYMBeYktOsv9vtBvujepUEkJ0fJbB1vthHhv2xDQDC2mDoNk+2rFar2LVrF1qtFnK5HPr9PrrdbshxR5Usw+dVPcU1pMo/Hed7g+2IMv4euzd23a4ZtafYc7F1YcnLGFkHbJCvu3btCvvcyspKCOPXk3SZk5L7O/fZcrmcOgRFCfdY3kK21YZ88j7u0WwbbVHJP4bX6gse2ibLWVxcRK1Ww9GjR3H06NFQj64ZVVhqDtFOp4N+v5+ya907uVfp+Ouewj2V/xj6y5+a6zRmQ3qohR6coXVq3QTJbaY4cDgcDsfOhRNxDofDscNBxRqdOE28TUdGnRsSPPq8OkhKWgAISefpyFCZogTEyspKyEXE+4bDYVC1qEJCSUOGnVEhx/xF6rhRHUJSyhI4NocQnTN12vk520+HtlwuY2FhITiY1uEE0qSLkk0sl7nFSGiQoGDomCYQp0NIB3YWCca6lIDkuFtCJKYCs2PAE0I1Cb8qepQoU2ed4YJUwbCcJNkMR1UCQvvEfllliJJn94ag0Lm2Y0RlHW2Pii7tC8eDZavaj1hfXw+nSzKMmSHZdn2oo087VnWfKnjswRLaX0sUxELeGPo9HA4xGAxw7NixLWoernXOVa1WC3NF9RhJMmBTVUcCRwkSjiXLUyJObWYymQTynPfQRpIkCaGCJOlI9HOvYht27doV1jXnYWVlBf/5n/8ZCBGSORwDkqOzyN+Y/ShBFvv7nsg8S+LFbFbXrULv17VgwXGjopikbCazccpss9lEu91Gu91OKXGTZEPVyFB/zZumCsJSqRRIOtsu7hGcZ1Wg8SUGgHBwiCXqqGAsFosphVu5XE6R9xyfQqGAhYUFtFotDIfDFBGnL4pImNmx1LoVdm3bPVLX56yQUVU7WmJNiVK+TOJ+bJXGthz9/qXS1OFwOBw7F07EORwOxw4HHVueWmrVU3SANcyQih8AweEh2aQ5bjSERskIVQWwDUreqJqOihcSgP1+Pzh0NicRVRX2ZFU6T0qoAZsqHe2bVTIoGQUglbeN9yoxpgSYEinslypQ9HAGOmLqrOl4qxPO0FtL8JHg0fxrdkyt+oLPK0nEZ5XEG41GqVxuNgxSnUXWRcKEp+Ra4k9JMV7X/ti5Zf+tE6rzFlMG6TM6RkoasC+xdllVk96nyh06ytVqNZBxsbVjFTd2vrX/nAddl0pOKDlpSc2VlZVgrzxtkqSXkjG0a5IySkSQrIyRASTsuE4nkwna7XZQB9r8WNwnSFLSFlWdpeHZqmTjmh8Oh6mTZfk851OVfgw7TJKNsNl2ux3IVkv4zsIsks0+c09knL3H2oOu7+1IPrs/6N+6N8VeWuzevRvr6+tot9vhM+4lSvzoXpQkG6pd5pgbDAYp5TFfQNCWmNeP18rlcors1b3XnrYKANVqFdlsNhD2JMw159tksnGa8J49e1J5GYHNNckxtS8eOIa6b1mCTVWy2katg+Wwj/V6PaWq1TWka1n/qRJP2wJs5mLU9urLoXtjbw6Hw+H4xoUTcQ6Hw7HDQfJMFVx0bNWpV4dR1V/8qSGLMQJJFT7qBFEZo4QCnXI6K9YpUTKJDp6eskonUx0XPqMEoPZJQ2YV6vCo0oz1UCUGpHO0kTwgycl8VeVyOfSZBJA6diyHiJFKOk/smxJHqj7SZ2YhRiow/xmVcCSbrGMZsycNZePc0aFVckadW2svNueSlq3EHZ/VPlvlkNantqPO8CyyLUaKWKdcnWyqcIrFImq1WsoebN+VPAS2nqRpVW9KMOh6sTmj+FmpVApkFckTJRzYf/ZD80OyjcViMWWvJGho6yThuAaU4ORYs2/sF0kcVW1xLZGUJwmYyWSCYoprh8/1er2Qj07VtGpDVMF1Oh10u90tJxxvN9fWJpR4vi+YRd7F6rLtsc/xn4LkKElR2gZtstlsIkk21Kirq6sAEMZT9w4l7XO53JaTcLmnAZtKLlX4KtEEbL6sUdWzPkcymy8qqIQkeaz7rn6H6NqxJLd9EaTjpXM+i/i3a9zOEcspFotoNBpoNpsYDAapU2VjLzXs/FqFsd5vXy6Q3Nb15nA4HI6dCSfiHA6HY4dDDziwOaaATcda1V3q5NCpouOipJmqEaiO4rOqcNA8ZuoUkpSj0gNASokDpPPD0cm0hIk6PqxfCTpVxilZYtU8quBRZRWfVUevWCyGfFeVSgXVahWVSiU8S2JLczCxTpZDp1UVV7YtStio08a50X7HnHcdH/2dRBydSyVotJ2WzNQcfXQ0VbFkHWILdZxtTkLNj2QJFPtPoWPENvK6jilVhla5Z8lSdcp1TEj4lEolLCwsBOWWkg46zjHybJbajSovO942TE5VkrQ9kmVKRtOZ1z6zX1qurhnOj6qm+BlVWNVqNbXGVEnK+nhaMNcBlVT9fj+Vs1HXGtcBy+F4DAYDZLMbOfBIEJE8TJIEw+FwCwlHm+K468sBqzTTnzrnsXUUI2t0fm0dfEZt2D4Ts2X9PFYP92SqHu2LDJKTdu65z3IcuQfQ7mgDWhf3bIZ0sy4l7XUMy+VyinDVe1UhTBtQZRz7Xq/Xg3KOc8m6YgrXWeQpx4QvCnQNkFRkeKyS1FoeFXGlUikoLVURqHXYOePa0v1b17LuWQQJvVhorcPhcDh2DpyIczgcjh2OtbW14NQo4cP//DOPk77VZz4pAMHpVqUDE6SzDKpalGQjoWYd/FKpFH4nmaVEDh0VOiJ01BgCpXl26GQqMUQHne1SsofX1KlT4kXL5DU6X0pg5PP5QLzpyZFM6E1SYTqdYmFhIfRbnXVVBum46rN0hDUBOpB28FRBwv7FoPewDIakMleg5jHTObOkKeeLzj77ZuvRcdWxVzJRx1ZDKmPQfqvjzbm1hKU+Q4c6SZJgU1ahpsSYkrbaB6qwmKuLByaQ1LBkmW2HJXTZblXsUBlk8x3qmGazWRw8eDB1n+Z7ZPv1GRIw/GlD4TTkEdjM+cU1xXmnKkhD7wqFQiAsMpn0CcPMkdhsNlOh27lcDo1GI5A3S0tLoW2VSgW1Wg31ej2E13MMlLwnwceQSruut1sTaj/2HiVK7BxY2LVnyTRLyukeNKttSthoG1SFCiCo40gKk8TO5XI4cuRIOEGWLxbYV1U7UqWmKlnep3kC+YKF5VjCnKQe21wulwPBRdJW88hpSgJgUyVr94AYiWqJL/bPjmdMmcq20/YYct3pdEIduiYYBq2nS/Nzq3gluUfyj7Zp1XLWdrROIP0CwOFwOBw7D07EORwOxw4HyQYAKJVKwQFjSJCSBsDmiXZWsUR1hYadZbPZcNgClVEaPlWr1VCpVFLOFZ1olrG+vh6UNsCmIkAVWCSuqMxTQkND8KiqUoJDQ+Ni4URWGWRDnZRwtCFe/X4f/X4/1KWnjrL93W4X0+kUe/bsCeoLOll0RpnXiSfKKnFSq9WCwogkGJ1xOsgcN6v4sOQb66RzTOUKiT8lb5RkVTvR+jhmdNwtqTUrdEyJPiVllOC1ykV1kFV5Z8vUseX9JJh4SrCqxVRlqGSYVbywPSSiOp1OGKdKpRIObiDpoPOsBJ/Oi9qSkh6qSrNkku2XksocP3taJa8BCPNOu1W7UNtSIkSVeqrWUeJAVU6cz3q9HnJ8cZ2T1CsUCmg2m2i1Wmg0GuEkVbWh8XiMbreLyWSCRqMRbF7XGhWdeiqmjlNMNWuJMp0j/s650zmMEW722qw1Z+u15G+MxLMgYcb+ktSkvVBFWCwWsWfPHhQKBaysrKDdbqcOF9G2cG9XW9PwYP4j+cpnSMpSOUmlIm2ALyWolOb3Trvd3jJW+tKh0Whg//79aLVamEwmoV4Sr5x7fcmjRJ397uA6oXKTtlmr1bB///4QcqoEva6rtbU1dLvdsO5JfCpJT5svFotYXFzE7t27Ua1WMR6PsbKygqWlpZRak2223yc256LD4XA4di6ciHM4HI4dDv0PPlUPdISBNCGljm6SJMHRAzaSqKuzTSeEThgdH5JN1Wo1EAAkQej0AQiKHCrDSB5oeJo6V9lsNoThAZsEo6o9qF5Qh9E64zGHmPda8oqkgBIk6qTSubUJubWctbU1NBoNLCwsIJfLhdNf2c98Po/RaISlpSUsLy+ncgppTqWFhYWgwuPYkhhbX19Hr9fbouJRUsU666PRKBzQoCe3qnNrSQqOs1VuKHmizrt1uC1Zpg4zbcQq/zTPlC3HtpHlxUg6XQMkBqw6zdoJn1WVGYlHtpdkEwlNYOsJifqPds+yNXejJR6t+lPtfDqdpogP/dySbxxvVfcwRJF9Y3422jVJFK7L4XCI6XQayBKSpSQveOrmcDgM6kMqrEgwq122Wi3U6/UUccf+s2wAIVSZuclIAHGsdf0prK1peKMlNy0xqqGMWlaMZNPruu9oaCHtyZJt1j7uiYQZjUbhEAsNd+/1esGuaWOZzEboJV++8DRo7QtfPCh5RTvXlwr6fcHx5yE7+k9fZqg98iWOHjDBn0q+l8tltFqtcLLvysoKVldXU+Nkx8/+znFkn5Q81rEulUqo1WooFotbvtv0pY0qnUmy62ess1gsotVq4cQTT8T+/ftD/sjl5WUUi0UcOXIEnU4ndVK5rm+Ore6/DofD4di5cCLO4XA4djhIlNFB0bBUdZCUTLGkAMOS+AzDEUloZDIZ1Go1VKvV4ICVy2UAm2oakkIsk8QKyQQN66NySXPq0AGko0kSg84clWUaGgUgFf4IbHXMSQLSIVWHjnXzfir3qHQbDodbTmhk/9gXzsFwOMRgMEC328VgMMDa2loIbySR1uv1ggPMdpGUaLfbqFar4R+VhXQQe71eyN+lTpwqNpSIGw6Hof02cbhVDNHR5hzEQjZ1fNVBjoXPckw4rrRBS8RZFZMtW++zZIj+rSQrbZZkpFUl6U9V0ljVDduQz+eDYpFhvuqgK1S1RoIiRg4pIcX+a18t6aBtJOlA21FilOVwzamdknyi7QGbYY/5fD4o2/RwDktya5gux46fcx1S5VmpVDCZbJyOCSCEX9sQQj1Mgm3XOYiRcApLTqtdWXJH16wlkvUevWavq/JR9xM7f0q+xWzFknSxsMuYOpTkP+2n0Whg7969QV3IMVOlsJJpan+cMxJxJM/YP0v06osL228lnC2pDCCcTNpsNlEul4MSbTQahTLsyxJLzNk5tnu5quPW19dDLr2VlRX0er0tod3sD19YaOoGvadUKqHVauGEE07AiSeeiFarFb7DGJqt5LuOF+vTUGA9LMPhcDgcOxNOxDkcDscOhypOlBRhmIweDMB/qk4D0knirXqOzjbJFH7GXFFUgVlHVx0yYDO/VbFYTKnerGNPhZiSACxPyQfrPKuzq86+huFpQm9g05njmDAPk6rv2Cc+Z5UhJDyYUH55eTmQk1SAUOFC9YolDklY0JmmUo4KGCa1P+mkk7YQUEpmchx4SAPD+mblL7L2o0QU22gJrJi6aDunmTbC/HB07lWho8/OIuMUvE/JBvZRT4O0Sjvtq9qlKvhsCBkVksxrRuWXJQ+V5FR7tuQvn2X/WacdMw2DjY0/264knY4n1zfbqDnWNEcXyW9VC41Go1TIINcjCT7uG1TZ0a5Z9uLiYsivp7nq7LjR/jW3nap2NURQ16vaspbLflhijPXYlxVKmMQIU/2Ma4WfcV/VvY9zowSWqq/UfrV9/KdzouHCHBOq3miXHLvdu3cHMknJYq4Fe7I11XUkknRsmK+PfdAcmmqrllDmfsn1wvHVPbdQKKBWqyGXy6Hdboc9TwlRux/E/ul9uvZUiTcYDHDkyBFMJpOQx03XHeeH60SJPd1Xs9mNg0R2796N/fv3Y9euXamXUPrSQ0NTbZuVEOXpsw6Hw+HYufBd3uFwOHY4SG5oYnUAgUBjvjg6AcAmKaZv6DWUiGUOh8NQB4kBEnDqwDNMTRV4dMg03w+dyG63u0XFwFA8YFNlRxJNnUEbfmUJGyUAVaWnB1bQ0VMSA0AgFQaDQUr5pM4n+2CJIOYKarfboSyOe6vVQrlcDgokko9KwCj5QiKEYXt0FrVv1mnVZ/VfLARP+2yVO+wX28kx5U8lgqxDrM/qfGluMyXw9JrmJdP22fbOcs4ZTloul4OzT/tTsszmtQOQukZCkvXRyS6Xy8EBr9VqwaY4p9peJeHU9pW4Y18tQcO6lfjimtKwc64dXldFIwkCtSsAKYKF6s9+vx/C85RwIfnDHHn1ej2lWmPOMA17Zh25XA7VahWNRiN1wIDuTwz71jHTUFhLxMXWesyOlby3YLm8j3uUhjaqolZtJKbA4n16D0kuG0LNeVFS3No0w8i1XO7NVBRz3njIC21g3759Yd8gWUwVIvchqzrUHHCsUw/u4FgpacRrJHM5p9y7tT8axgogEPKDwQArKytYWVkJa0vLtsS0qtN0zvVvDScFENRwdv+2P61NsFybf7FWq6HRaIQUDAzLbrfbWFpaQqfTSa05VaRa8plqc4fD4XDsXDgR53A4HDscfGuvagl1gNbW1gLZpg6W5vQZj8col8upvFDr6+uoVqtoNpspcoVJ2YF0eBXJQOY3I5lFooAhtGwXQzYnk0kIJ2TuOA0hIiGkjqM6y+wjkHbGY8oMPmtVUSQceCIeHVkSSxw/Op6aj4w581ZXV0PieQUJMasMInFGJ5flU3UHIJUQnf0lQaIEGts0Go2CCk5DUjlXhCXylPDQsEvrUKu9aTksP0b4qZ0qIQUgNQ+WUFFom/gZ54SfKxFNxclkMgmHaeh4cVxV6WTVZvxJso2KLZ4CTJKbShgdL6qDNMxPr1lFJ+uz6qsTTjghELicTxLrg8EAAAKJwZMbtQyWTwJEc7ENh8MQyqjkEclfEjzZbDaQaprzkOHXJI6oaqvX61hcXES1Wg0h2RoWq2tXyb5CoRDCtzmGmufP2oSOWYxgsSQX/+YYKTFlFb1qp9pmJQgtOU+ilzn2uA9SZca+kbjVdanrjIcxFAqFkNuMY8T20e5YXyazob498cQTUSwWcfDgQSwvL6dshuuCfWaotaqT7dhkMpmgrOWc6frlmrDqUyWcRqMRMpkMWq0W9u3bh1wuh7vvvhsHDx4Mh8BY0orjks1mA2lFpabauCr57P6gikIlwdlXfYFhiWoNVy0Wi2HdUpmczWbDKcBHjx7F6upq6hAetU9dh7xWLpediHM4HI4dDifiHA6HY4eDKjQ6zhqqQ9WaDcWxfwObqgM67THSg+QWsPW0TV4bDAbh3kxmIxSVeaIABMKQbSOZovmylOiI1cGfGgarYVC8X9VkqtbTvisRoOXp3yS76DSSbKNz3O12Q/43tk3JFhIpmndLQ2z5T9tv+0qihOQFQcJiPB4H9RbVILNylLFPs/7FHEglJTkOqihhv2hfdJiVTLHPqaOsqhl1lNlmJdI4RxpizUMKOE8kgnhN22HD63QdaJ2qICVZo0Qwx14VcOyLPd1X51xtwc6Njs+RI0eCjRWLxVQuKtavp5XyWW0r20fCkG3jutO8WCR5lIhZWFjA4uJiUBmS0LZqvXw+j2q1GhLkc/653mu1GsrlcuoET66Tdrsd+lir1cKcWCWTJVws6chxjhF3OtdKpOsaJ+lNwipJktTapZ2QvLJrlGNbq9XQarVC3r3RaBSIFxJzLEvbz7XFfYGqN44NSS/aOF+esKxSqRQOEjh69CiWl5exsrIS1ovdH2lP7XY7zAFVdFR/0aaVgORBDtzni8ViOKVbFXb5fB6Li4soFotoNBoAgH6/H160UCVIlZklXXmITbPZDPtsv99PEYhqF+yn7lu6t1jFrpKHqojjdwmvjcdjHD16FPl8Hq1WK5CkR44cwaFDhzAYDLao+LRtrIdtsqcWOxwOh2PnwYk4h8Ph2OGgg0kVCx1CdTbpYJEMATYdcDo+VGepY0lVkR6eoIRQTJVglUZKrLAulqsOGz+nIkGdXn1eyRxeU2eURAedWJIodNysc28TyPMaiQ11yJScyWQywVGlAo39U1KK5WreJ17X5Pd8JqbysiGploTgfaPRKORDorOqCr1ZKiFV/KiCREkCjq2OA5VeLMOSSpbcU0JVoWQrSR17n1WQKaGmtqd50Gq1WjjRM6Z24xhrH5WYo0OuJB9PT9V7eR9JC/aBddpwR9ZticFZ4Y7T6RS9Xi/kbaPNUylkQ6zVxjQEOJPJoNlsotVqIUmScGol1W2aH5IEyO7du9FoNFJ2zbBEnX/OIeeBBB1JLYZIWpumkpP7Cteyrh+SNAprn9YmOA5KsMRsRdcc2818hjondr51L9X9QX+quo7rU0k9C93H9dRlXaux9cW9iGPH01RJnPb7/VT7ebrnwsJCUN+pnY5GI0yn05ATkf1Qcl37z/bSJthn5rmkorJcLqPT6YSDE/i9EluDAEJI6O7du8NnVNHpPmVJV0vWKxGnima9l+AzfGGTy+UwGo1w9OhRTCaToPBkPtB2u50KubaqTB13a5cOh8Ph2LlwIs7hcDh2OJSYImkEYAtJAWyqzjRHnDqXqlCzjjywmXeO96mDoWo7tkXLiTkerJ9KFP5UdYTtgw0zJGweLpIsNhcbHUiSiXTUqIBTRZMqUlg3FTP8nCSNdazVCWN/mK9Mx1pJFz2xknPLfugYKlmkubX6/T56vV5KNaLjxXbZUE+rUGMd2hfagoamqsJIFUNWaanEhCVFWD4/43xYRZxV4Ok42jEmocETaJUks4d3KJGoObPUbkjAZTKZQKYo6RrLZaa5wEgscc3wutoux4P1ci0oicBxsQobqpH0OY4pbZx5wXQeGYbN8G4ds927d6PZbIZQXPaZRKPmqdP+6F6ja5IEMde57kVJshEqq2pVq1KM7SGxPcUSK5YQUSKOaj0SV7o3WDJTyXpblta9traGfr+feonBz7iv0BaV0NV2qX0ztJ8vE3T9cc0p0coXF41GI6yDI0eOoNPphDLH43GY94WFhRD+yZB8lt3pdAAgdcgKFXNKVFs7zOU2DiRYWFhApVIJh+BkMhn0+310u91wrw1LtXsT7UhfOtjwf7UNfSGga0/nT/de3VN0n9I2aboEjnlMBT3LVq0NxUhkh8PhcOwsOBHncDgcOxxUTtDhUIWMVRdouKcSA3TeAIQwIRIPqu7hTzrPmvSb9QNpp5z3WoUZr/F5OjlJkqRO1rSnbFonhmVpX4A0YWcdIRITDPcql8solUqo1+vhYIpqtRqSffPESWCDWGo2myHMjuoRgs68dS7VCbZ94f0a4sixt0SnLZOn9tHB7Xa7IQxRySD9qW2d9Zn+TfKFqiU6uCSuNPeZzo+WrQSHhSUHLawCk3auSjKqevg8yYl6vR7aqCSqLUPDe5kfyqpItc/aVuv8c2yVwFUVFdce592qVHk/8ywyNx3DQ5kjTk82ZSishi5yTGjDtL9+v5/qPwm4er0e1kCtVkM2mw2KQgBhDZNAIiqVSvichAvJabZzOp2G9WZfFrC8Wq0WCCy1iZhNxoiMmGpsFnlG0ozkGIl1zomGNdOedN3Z+vkMy2beTc4LbUdDTElOKtFux5p2SfJS7UbboIpG7q179+5Fo9FAvV7H3XffHU50ppKS9RSLxXBwxnA4DGG0zA2nxJjaK/tMBRnHi30ul8vYs2dPaHO73caxY8dSOeUYWm1fsHCdrK2tBdUZ9zbua7E5IPSlAG2ceywVhLVaDfV6PYw7lcQ25yPbpiGo/G7gOtLvPlWL8n4SikD6BYDD4XA4diaciHM4HI4dDiULSHjQeSCJRudCyTaesKcqJ1WZMdeRnrTHUEyGQNmQImCTAFPyTolBkn65XC4kI+eBB1SN0HkqlUrBobdKPauSUidMc3cBaUUXw52o1igWi6hUKkG5ASCVi4vPjkYjlEolNJtN7NmzB4VCAaurqymykeAYAJuKMD0MwSrhVEGldXJ+SHjq5+wnk+4z5EtJOLULO3YxkoJlK1nBMatUKmFceIABCS4NtduO+OAc2H7a+y2sUkjVMsAm6cYwOBJtdLipdsrn8+FADptvjWuJZBxJMDrlJJE135wSebP6btUxJFcsUcfnleSo1+spsvvo0aMAEPq5sLCQUvCRAKANUPHFNlBhpyG0SjCTLCUxoqf8lstlVKvVYMNsd5Ik4STl6XSaCnWlMko/J3GtijmSTzqudk3pGN+TmkgJ4JgaTseedebzeTSbzTAm7XYbw+EwkJq0Kbve7UsHkunD4TCl7uQYNhoNVCoVTCYTrK6uYjqdhn0QQDhoRElVzjmAoGSjPXNfHAwGqQMAVNG3sLCATCaDSqWCXq8XxrdYLKJer4e9kCeZ9no9rK+vh4M7uO+TEOTao82Q4OVLDBKwq6urKJfLWFxcRJIk4YUBCT6bFkD3dI5bv98P5LiGZ3PMLflKqKpRiTt+r7RaLezduxe7du0KKsWVlRV8/etfx+HDh4MCVNcwFc20ZR0Hlq/fpVwnamvr6+thb3E4HA7HzoUTcQ6Hw7HDQWfDOt029ItOAdUPVFcoaaTJ2nkaI9UO9oRDXqMzbp3HyWQSHDh1lujQalibOpaqNqKTrGo6m+Ra1UgkEghLXvFUx1arhYWFhZC3iH2hakLVLRwnhpsdOHAAJ598cnA+lYyxJIESAXRkVQ2kZJzNd0S1G5U42j/2meomJeKoLpqlcJulOosRfTrflUoF1Wo13EtCxRJSqnqzxJpVjWldsXbYOVaFiVVfKtlEJ5gKuHw+H0KIVT3Ge9VxZj8ZgkpSU3MBsk3aPsUsEpQEiIZvWxJT7bnf7wMAFhcX0Ww20W630el0MBqNwnxz3XA8VAnX7XZD6JyOEe09dqgE25TL5cIBC5ofjAooJeNJUDAnHMtUskrVXJq/jIqw8Xgcwv10v7LksSU3LbFm7YH9ioUzqm1xb6hUKmENUeFFAlfXHeuOqdM4p5oqgHPearXQbDbDulIilS89SP6xXRxvkuIaskpiTpV6tGnOW7/fD3tJq9VK5fmkEnBxcRGNRgO1Wg2rq6thDJgjjUQebUDVbPqiQPNyDgYD9Ho9lMtlTCYTtNvtEDpNNTHXg4Yxc150f9WXC7P2EO2/EvaqRuWLmF27dmH//v3h8AW2azAYoNPpBNJMv0vV1mIkvCUFuRb1/vF4jHa7HchIh8PhcOxMOBHncDgc3wSgaoVEhTpswNZwGT1xDkBw9uh4UCVGsoXP02mjM8ayVc1m62UoFNupoWl0xqn8UhKFzrOqyZRoU+dKnSBV/gCbjjydaZ4CSWUKQ8XYr/F4HPrPNpLQqVQqOOWUU3DgwAF0u10cPnx4ZqgYn9V2qGqRfSDorLGt/F0VOOwjlVuDwSDkhaPKQokdVTuyDkuMETECg2WwH1TfqNpklmrpnkAb0r7ZeWT5qr5RUpLg/Gl4IdtJ9RiVNYPBINgUVZ5Ux6kax4bDkugej8chjI9zZNWN/EzHx5JSlkjg3xqKzfWzsrISSEGGx1nVmBKKOnZUtVrFItcbCah6vR4IPBIIAIKCitez2SxGo9EWch5A6jRQrjdtE/+pkjKbzYaQW5LiaiPWvrZTxMVUajoXs6BEIdswGo1QLpfDvHMM9dCUWWXpnOvvJINpeyR9GfpOslfVbrRVtQnu91wXrFPDQknA5nK5cOgC9wbuw1S7kUjLZrOo1+shPJjzRPD7RfNP2v1GCTWu62KxGMI+GVrKMVdiS/vIfqpK0o6v2nzMNmy4K+usVCpoNptoNpuoVqvhu5NKWRKVds3YsmwKAq3Xfi+RFOUc67g6HA6HY+fBiTiHw+HY4aCyrFQqYTAYpMJg+BmdBlXkWGeIz2iuNb2uhInmtFLH2+Y2syoNYJN80rw6DIOiE0fig44v67GqCetwK8mgZAf7WSqVQq6tarUaHF11BpXwo1NLNcji4iL27dsXTuMkaUZHzs4LyQqOlZIZrFMVg7PCtNTRm0wmIUyLOeGUhLPkjM6XOo3sr3UYrTJPlVy0Hav0UiLNhnvyHus0c45VAaltoZ3oqbUsS++jwso60fy8WCyi0WhgfX0dS0tLgbSkeqter6PRaATSiP3j4R1sK0PV2F6q41SlY9UyMSJJw7TtszoGJMpIfA2Hw3CoghIEJJB1PKgAVAKHdsgyNdcfQ42pwAI2STXalZJrXJMcH467EiaqQFI1kIbIA5svAWz+uBgs0aJ2bglPQudB11bMRvmZEi58XvOa2TJUnakksW3X2toaut0uSqVSKqUAUwUocaR7LBWKJDFJgNmcnTr2aoOVSiWsYc1LxzayXqrgNN/gyspKihADkJo/knW6t3FMSPYBCKHSs/Ydva5rnX2waj+dX7tnqr1YWwAQCEgSz2wv94RyuRw9iGHWywq7zmMvFdg2fTHjcDgcjp0LJ+IcDodjh0PVSTEiw76pp6NFpQff/DP8aDrdOBFuNBqlQpFIZmWzWVSr1UAK0AnL5XIYDAZbVGt6kIR1+hjiqoSCzZ2jxBvLVKgDakkiIK120RBUzd9EkoD3cSzoTFarVTQaDezevTuEkw2Hw0COUE2obdMQPBIQ1mlUJ90qsKgipPNJR5o5zEjE9Xq9lEIlRqJZkium4pjlXJJAYF/ZLs2NpOOs/VNiwarAWO52B31Y592q55i7i8oizitJLobwMSfXcDhEu90OhxUUCgX0ej30er1UmLL+o/2ThGJy90KhEFR2NleiTSavc6KHcShhwjHgmCmpzTXKcEaSY8w7pmPLe5jknm0kIUK71HHq9Xpot9shXxjDwDm2Gn46nU7D+mebtP16KIw+x7U7nW6E/yoJwpBtPZ3WrmFLqsTItRgJd2+gZCTVaTx9mIQ759QeVKG2DyBFhFtl3Hg8RqfTQZIkIdSd+x33TVUlWpKb5ZGsIknH/Znzzu8CVQIy56cSoqqSUxKUNkfVbafTCUo9S9rryxEl7LjP5nK5YF/c8+3cWFKf9cTGcdbLCdseO2aWKNcDXHSPqlQqWFhYCER0LLRb2xR7KaFkrLZTCfHtCGeHw+FwfOPDiTiHw+HY4aDDTNUEnYBsNovhcAgAIVk9P7OhrMwDpE40VSrdbjckMqcTocQaHXHWT0ePaiS2TZ00PYSBhAfv0VNd6ZAqOUenS0OsYg6SDcvVEFQbesjnLMnDMEeSMJVKBblcDv1+H+12O/SlXC4HdRTr5DPqxLP9OkesXx1akp3MVUa1DIkC5i9jqKWSQeoAWkKObbOOqh07VaAQJOJU2cF/26k7OP6qMNOxUJWRknHqLNNGOV9sL21Uc5jZPHI6lzwlkYeXMC/ZyspKCM+sVCrhpElVrNHmNbcXiQ+uJyUouI6UcLBOOe+3SjK9ps47QxqZc0tzmWkOLQCBRCRByTJ5+iTHjwdxNJtN1Gq1kMORodvaDqrgGO7LdczwaKozWT/nkW0GEEg8KuwKhUIqeb+GpnKcZtmV/q52oeNox9uqDwGEE0yXlpZCPrV2u53K5UUlo9pXrJ5YGCzrnEwmgejr9/thjvQ5Er8cHw33VxUibY5kNFWQJI5of+VyORD9PAmXyjzu0zzVlrbAnGkrKyvodDrh8A32hfu2VYqxj2y7fg/p6bC6f/A5zg3HV/cp3RdjhKTWq+kZ7IsGkpO9Xg/Ly8sh758qAJkvj6Tc8vIyer1eihhXElS/C7Uvsb2XbbbXHA6Hw7Hz4EScw+Fw7HBoXiBVZmiOIIJkDxUU6uRkMhnUarVUrjjm02Jo32g0Qq1WS6kwtAw9oIFOHtVl6oBZB4pOjap/SOTRUSJRB2wSXeqQ2THRvFh0+hiOpAdLqBOoYYN02vg320lnmv1iubEcezyFVQkSVYnRsePY0IlkqJ/mnyMRR5UO20ACRp1XS0oodC5IlMRCKa1iTu/RMbWhtvosCQCGgs0KG7PEnyrgtF02nI1jy7xpahu1Wi08w/nhSaPD4RCdTmfLCajD4RCVSiWlEiJ5xXs0v5ltnxKV7AfHbhYhBCDYslUxWfVikiSpAxqYE495vmifHAP2gbZJ0kaVdkyYPxqNAmGmdsuDIaiKYq5E5lfMZDIol8tYWFjArl27Um3nfLEcrjElNqjUIvHMuq3CzZIqdgytKmk7sG3aPoYiMsSeJ3WynQxNVtWpJVss4W3bzb+5ZrlHKmmr64mKLCrnqEYE0iQUP9N9rFAooFqtBhKbtlmtVrG4uBjUbqyH9s89hoQVVWwk8Lhn8hRpEoCDwSDYZDa7kfev1Wohl8vh8OHD6PV6W8hP1qtqPF1Puk/aMdfvE36mz1rb0T2R+T25d1ANyzyFuVwO1Wo1EJccC64rJT3tuqJNab5T3SfsPutwOByOnQkn4hwOh2OHQx0VKias2kDf2tM5UOeBZB4drEwmE8IqWTZDN/U6nQqrCCBB0+v1AvmlTi+dNiUwlGRjHarUUMfGqiLYdyCtLGM/GZ7IsEqG5caUYVapxMTa7DMdaBI8VJwwRBcAarUaarUaMpnMlpxeOg6qYlPCh+2hk6nhrzwl1Z6QqmoyDRfkOGjeNOvgWgdRyTprY/rPErFKpJF8pOKRc8rP7XjbNqmCUudD69NwXCUUAaDf76fyIJKYIOnLtvJ3kstUl3W73TAvnCfNZWbXmW2/hmhr+1Vlx7lXcoE2DgCNRgMAgg2yf5zfwWAQwsHVvkioafghCRJgM0dWqVTCrl270Ov1AglDtR/bwnVXq9XCWuYa4+EGbCPbzYMzlCQplUphjVQqldQaTZIE7XY71T6OfYy40LGOKdBoY7on6Rhz3G0OQO4LSp7o3MUIVTvvdh1pm60t6NqlwlHJOV7nCw4brmrzeHI+aMtUOdPOaTtUfVIRSnUdc08Sum9xbfBvPRAHQCqUXteuEm5KZFsFqd3zdKwIVZ7GiDv7TGxeONedTif1coMH+JDU1ryHXLOaq0/3DLVzJd9Vlaft2u5FicPhcDh2BpyIczgcjh0ODSelY0Rll4YxqWNgiTF17tWhoHOnhzXQmdGwKjrQGiJoVT38nY4uVW4k2gir1FICSZ13VZbZPHn8x/JUPaQqBauwUMeNeeCoBFKlHsusVquBWGCi78lkEogIhpACm6F6NvE5sKnAAzbJPz2Vls+pIo554QglTrRc/X0WCWFJDSUCFBx7O6c6jjEywhJx2h5VSeo8augX7+c4aRiajo/ahj2soNVqoVAooNFoBOKUxCbvJeHAAx04Pla9xRNGSV6rqk7VL6ybjrpdFzrGupa4nklMlMvloPBj3+whCiTIaAMLCwtYX1/H6upqIOyUTKaiqdlsptYiVWBKMnL98HRZknh6MAYVY9xvGFIdIyVJ+Gu+NSUzSPLQvtUGrD1u9/csKAlviWi1NW0vf7d1xeZRQ9Fjz2s9SjjyGm1aiTaWr+Gdqvi1exptSAlFzlWxWMTCwkIg/zqdTlBQ8xmuSc6lTRmgBJ/OH+sigUsboG3pHqrjFdub7Bjb/UznSvdT3cv0+0BJOdo51YQ8uIW2x2ep9hsOh+j3+wDShDrrs/ufbYe2zebLdDgcDsfOgxNxDofDscOhb/o1uTywSdKp08LrfNY6ueqAsVyqbEhgUKGlYZAsh0QBgKCW4Wcs0xIuVtGjIZrqqKo6SYketofXlaBTIo6hVEq4EaqsIxnDPFGj0SiE5JEctCq7Wq2GcrkcnFqedMn+MV8cCQtVTlgFjTry6shRiaeHM6jTZ+duO2dPHVOF1m2hJIMNwePvOv4ce6ri1PlWh5zON5WPtKFY2K2qgmaNGW2m3+/j6NGjwd5IxmmIKnN2AWk1pVXbWQe7XC5vUebo4ROKWYSvqoI4LnrfeDxOhYECG2pOhnbyeao+OcbVahW7du0KpMuRI0fQ7XbDWub6JBFWrVbDWuVcaO492hvJuHK5jGq1GmyN9VNhS4KHRBL/kYymKkpVXK1WC/V6HUePHt1it3aMdB5i5Jl9ZtZc6J6l6zH2jMLWGdtH9HNLwMXKApAKRwc2bTqXywXylWOtdSkBynusEo7zSRsolUqBjFtfX0e73U7tm0rU6/eJvshQoktz1nGNFQqFcPCPkor2BZEl0WLQvcN+nylRp/9iSmRCX3gUCgW0Wq2UgpYEN1XPqtJkmSS/Y9+znDvdi3Wt2nyZDofD4dhZcCLO4XA4djiYQyhJklTokCoqrGqMZJCqeuhw6YmiVMPRUV1bW0O/3w+kgCq86LRbJ5n18Hk6hUqq0PlXh4WqCg3V4jVVzQEIag2CjiGw6dxWq9UQEkeHlY6lkldUEbXbbayurgY1HMeKZBGA0Deq4ZjknaGENuzQ9kFDZC0hR4dZx5EkqFXVadmqClM1DUkmtnsymYTDNDjXmgeLZVs1iSW8LKmh5C3HTUOLFSQM6NRyXHjwhSp62E8Ni1aih3XTnkjojUYjrK6upkIs+XNhYQGj0QjApsNslYpsJ+tn2KqeMsy2KgmnJJk66UpwMFRT7VDtgOGIvV4PS0tLgRBRdZrmM8vn82g0GiHXGpPRj0ajVJgjSftKpRLGSYkGqoQsOU/yplqtpkJPSVYrocl/rI8/2fZWqxX6oCG/XINKyCt0rrcjmpX8UvJNy7G2Y5VNFrFr+pJA97OYekuJ6hhIsGnoO8uzdej+oteVRCbpw89o6wy5zOfzaLVa4ZmVlZVwnUR4qVQKh8Zw/+Y64QEQxWIxHAzElzb87tADJDQdgc6T3Sc5Zlahq/Nk59Huf5pDVMvT7xfaerfbRbvdxsLCQjiQx5J2tGFVJNp8hjFbtfXyflfEORwOx86GE3EOh8Oxw0GygwQGf9fcNXQkSLAxxIa5oPSgAVW4WMUBQwzpINFBp7LG3q/OIJ1qhijqaZMAUk4ksOH88MRWOjxUhZA44KmVdIRsqCvbpw4QHSqSWuw3ndtut4tjx46F0wKLxSJarRYajQYWFhZCTjiSQsBmTiuSE+wP28Z6bY409p3tVCfXqgO1zZZks0SUDY1UQkgVLpwPKv36/X6KqCVUcUOliIYM8x5VgajKTUlAgu0h+UYiTutSNUlMwce+69ja0FCqG1n/2tpaICIqlQp27dqFbDYbSNeY4tKSkZr3T+fHjoVVLHGuuc4IJV2VFNZcigRzLJJIJvmm7SLxoXnHeKAF9wSedEoSkMQZ+1yr1VKEGstWtRb7wTVKu9XTZC152uv1sLKyEuwom82iXq+j1WqFwwX0BOaY+umeSDh7v96rxLa9L4ZZajjO26w6LdEXK8+uMd2LdH0psW5D6oFN0pd7IrG+vo7BYBD2cs4V1cFUT6ria3l5OdiPvpzhywu+dGEuwX6/nzpIh+pNkrB8hrbBclXFbA+lUYKdz+neqfnp+N2j64njqmGmui/a76q1tTWsrKwElSvDtYHNPU/7wvboPqgvD5QY5D+1txjB7HA4HI6dBSfiHA6HY4dDc2/pm3w6AqoW09w/JEqAdCJvdf6YJFydX3VkNLzMlqNhUHQsCc3BQwfUKuqUwLPJ42272Wd17tR5pcOoSjQ6jyybyiGqI5gEv1QqoVarodlsBkKQpJuSnOqgqhqL46ZEmjqCdDw17EsJVPaL86e5z5TcsgRcjIigE6iEGk8YpXNpVTWcO/ZTbUCVapY0YN/UbggldmmnqhSzZBoVNuqkK2lJW7LEK/s5Ho/DqYfT6TQcPJDP51GpVDAajTAYDFI5y9RhVhtn+3Xcde3puFinm/ahTrzaKcdKiWOuJYb4kjjQsN319XXU63Xs2rULlUoF1Wo19HcymYQwUlXgce2RQLDkxHA4DDbOPYTzRRWe2gxJXPZf51VDpknsKLHfbDaDEkkJGR0TO74xIsOq2dQuZyndLEmniBFps+rStTAvlFRXol/JXF1LSgRxH+bpprYtmseP9QwGA0wmk2BPuVwOi4uLKBaLuPvuu3H06FH0+31kMpmQC1BJWGuLPMiHKlHmzlTCWHPPsc+8xrVoXzBonbrGldjVfYH7oo6Rfg9a0lXL7vf7OHz4MEajEZrNZlCV6gsF3d9YHwk7G5Ies0/97pxlVw6Hw+HYGXAizuFwOHY46AwBmwQXr6t6Qp0JG5JJIkhVKvpWn2oADR9TIgRACM1j3XSCNN9ONpvFYDBIOVuqeigWi6k8cnTG1AHnT82fBKRP1NRE2ky23W63U0ownio4HA5DmWtraxgOhyERPtUdDGul86ntYX25XC7kztIcXqqwUseSbeXY6XVC51LnSsdPw9MAbCFVdI7Ydx1TEiJU1CiJaudYy+Q/q1qzhK6GKFKNxs9IWrJdtDMSYkqqKYmo46NECO1GQ+A4ZrQ7bSsJIeYpY6iaJRK3U69YAlPL59pRgoqh1lYlqGQd51VDy61qleNDooVtYPghyyTprPOj80lShWNPgoGhrhwfhqNatZISZhoSzLXHPYi2T4KDc89QVasesmOp5MssctcSLbPA52fNZ8y+ZpUbay+vW+XavSFfdEwBhHx9um5VpaUKQrVVVXDq/LNtLI+EcKFQQLPZBLBBfB87dgy9Xi+E5Gv4NX8HNlVntEVgU4nX7/dDugRV/JIw1HboP46VfdGgRKR98aD36feKKjdjZCnv46m/zMFYq9VQrVZRr9fDmPC7xo6r2iTnQde93Tdj7XY4HA7HzoITcQ6Hw7HDoSFxqjSjAoYOLAmK6XQjrNMqioBNMovXrTqD6gY6GiT0NGyHBILmm1PnEUBQUGjoHtsFbDrKDIdT50ZPCgWwxSG3Tg5JhV6vF0g3tpG5tdRhUmUFFXHlcjmVRN0qv+igMeSrWCym1G+z2so61GFUZ1pJRv7U/tEptfmR1FkleaWhUvo7+wwglQOK88Cf6sjyb20T26PkoObVo3Ou4ajWceUhFyTiWB4JHbZBlS62rUr+anuTZEP91e/3w5qoVCqBjFJbZ/2aC1CVhDZU1c6tVePo3FiVnd5D6JrgZxq2qG1gX6jmJGFerVZDn1mnVZKRPGFYaSzXHYBAxNVqtTCnDE3kWGl/+RnbqMSE3qcvB2aRXNup2RT35jNLiMyqM4ZYG7VOLduScdu1Tz/XsGlgM+RdFYWWiCTByXBg2q3uK0qWc+44J5wjtqHRaIRQ45WVlXCqsO7DAFJEHOviWgcQ9lbdNzQU1do261fC0e5t3KvYBs3ZFiM+VUGrc66Eno4px288HmM4HIbvC6pMy+VyIOr5jH4f6ffDdoSbjrnD4XA4diaciHM4HI4djslkEtQ8lgigw0PiieSQhhUBCLnSNIRViQASQlQNqHpOw6EY+sYySQaUSqWg1LGJ6TWPmj6vjg4deP7TPHjqUFpCkmMBIJA8dAb5tz3gQh01kkb6jCpLVDmoJCHJET6nxJ51zji+VoHGurUvqj4Ctqrd1Hnl/VombUJVdCQiqQrRRP1aF+tT+1DCiP1TMo6kDe2r3+8Hh535rJTY1ZBLzoHtM9thx5C2paoVJXuJ8XiMdrsdnHSqeFQZpoSsksUsl/1ThRnrs3bE9muImx0vLVNJMz1QIZ/PB3WOqjdpw+rYMxTXKiGVCNO8kkoCU6VWKBRQr9cDKdNqtbCwsIB6vR4OW1EVHduj4ekMN+Vcrq+vo9PpANggmWq1WlgvGrJo16O1AyVU7gmzyDK1nVg52xFn9jPO370p1z6npB1DHWl/HDPuUapi073BEnRKuPJeJdn15QP3U1V8Uf1br9dx991348iRI2HtAkitaSX7qHSkApb72mg0Cuvd7hu0lXsaY17nMxxvXWuWFLf7RIz01nlThSH3Aba7Uqmg0WhsUVFzbfN5nU9NFaEvCjhODofD4di5cCLO4XA4jjOuuOIK/PEf/zE+//nPo1Kp4Lu+67vw1re+Fd/6rd8a7hkOh/jFX/xFfOADH8BoNMJZZ52Fd7/73di/f3+454477sAFF1yAT3ziE6jX6zj33HNxxRVXpHJR3RtoGA6dfTrImqcN2HQG6IgBm6Fww+EwOCrMhab5fVgOFTd0FPWEPDpVqpBSlYSSgXRUSCLS8VEnn/fRwSGJpKoqkiVahhIlNvyTjiz7SEdXHScqBun4kSDS+tXZ07pV9aTkCtul+e7UAbR9zWQy4fANEqcxIkKVhrxuHUBLShKTyQT9fj8k8lf1jMKWoc6mdXjVsaWTr8SvKn+UQGYIpZJHBEkyEhScG0LJW467jo+WScULbZFkkYa9qmNNspr1KOFrlW86FvynpKISbrOIBpISLJOOfy6XC3nZ2FeODQ854BopFAoYDofodDphredyuaDWtMn0qQAi+UcFKE+bXVhYCApSKhTZRq5vPX2X/WTuPRJ8XFuq8hqPx6hUKlvmUu1MyWQ7XjqvsfHUz3TNxew4Vs6sOmJrKrYedK3a9WfLpBqOexJfNJAY1ZcotFe+AODYcrwApPYrqhT5jD0ERElPrjUl7ZWM41rlPsx7ufez7cCmjWhoMfuq30ush0S1XTccO11/9oWDVZqRhFTlG5+jPbEs7ruqQuZhKcwTWq/XMRgMwjjqswp9IaGqWvaHa8DhcDgcOxdOxDkcDsdxxt/+7d/iwgsvxDOe8Qysr6/jl37pl/C93/u9uPXWW4PC45JLLsFHP/pRfPjDH8bCwgIuuugivPjFL8anP/1pABv/cT/77LNx4MAB/MM//APuvvtuvOxlL0OhUMCb3/zmudrD/EBWaUNHl4c50GGj86EnjKryhk4WwyuZjJvqADoZDOsjMafkG+tg7idg62l3bDeVFUpi8X46oXRk6aBSwaGne9qccZb0YB0kXuhg5fN5dLvdVH47Qp1O6xRq+Ur+0JFWQo73a9J0dYg1xJBQ0k6d+RhJpo4g28X26996jb+rmsYSDZYw1HnRMVDCS8kNkjqqtlGiTxWCdG6t8kmVJ3YMdS5m3WvJS/aB5GuSJOFAEj5jlS2WvJlVpt6ndmhPFdbx1b/VVkjEKnGm6k2uASUZrOpG1WgkKwaDAUajUSAJWD7rW19fR7fbxXA4DKo1EiQkr1XFpIdckFDRxPskYrgXcN2TFLS5IK2d6d/29xgZu91n9vfYWrJQEmi7Nlk72a7eWXWPx+MwNzxgQ9c2VatcQ9xPVekKbCpydZ1Ygorlck5iOd/0oJq9e/fi0KFDOHz4MFZWVlJkFglC2oSqjTOZTLCxfD6P8XiMbrcbDpfQ/qmabjQapfZdu5b1+0YJciXjVGlpx1pfFlhFss0nx7EtlUpYWFhIndSq3y2WCNT1zDoZBu+KOIfD4djZcCLO4XA4jjOuv/761N/XXnst9u3bh5tuugnf/d3fjdXVVfze7/0e3v/+9+MFL3gBAOCaa67BE57wBPzjP/4jTj/9dHz84x/HrbfeihtuuAH79+/HU5/6VLzpTW/Ca1/7Wlx22WUhXO7egP+xV6WKJnwHkFKw0AFSNY8N9UmSJDhSShhQEaNKCToidK6VDNTT/GyYJckqqs+y2SwqlcqWcFXNNaWKEA0hUoJRyRpg0+nSpN0M5SuVSqhUKiF/mYZcKoGnCghtEx04q3yiU2cPVlDikSo4qlU0tFWJCZYVI8s41lqHOqUaNqlqFI63JXBixJu9rk6whnrZ+pSAofpFySudPz4XU+PRfpX8sWSgKmS0X7NyyWnoMMkoPYHSkm1W5RQjXQiWrevP5rezoZiWYNATGbludAxtWxlOzLVBAoQkCImX0WiEcrmcWi8aiqqnxuZyOdTrddRqNRSLxbA+SqUS6vV6II40v5cqP0nys77BYLAlJFkVeToHhCU7Y7apc2DJTS1H74uRy7HyrH3F7tc9064fW461Iy2Lz+vLDu61qlRNks2XE7rONVef9oP7iypKSX7pychsh1Ufl8tl7Nq1K8wPD6QhmUYbY47FXq8XrlPxyn1S26iEuiVxuQ50f7P7h5L4lvjW+dIXO1pGjDjXMHmWzTDvcrmMSqWCer2O0WgU+sP+WUUdx1b7wLbpCymHw+Fw7Ew4EedwOBwPMFZXVwEAu3btAgDcdNNNWFtbw5lnnhnu+bZv+zY86lGPwo033ojTTz8dN954I57ylKekQlXPOussXHDBBbjlllvwtKc9bUs9o9EodSJiu90GsJlzTZOhAwiOOZ9TgkrDVYFNdZqqE0hAJUmSSu5Nh0UVRZlMJhUeZ8Pv1EFWQoufabgpwyTVKVLFWC6XC3nEVHmmZBCdHatuoGNFB8qGuSrhpSQKc3FREaTON+tge6ig0/FjHRwbVd9p+JISJEqQKfkVI4QsKcVyrUOriIV3qk0oWaBkllX66bPqUJM8Yj4kDUNT4s2GobE8S5ooycMybPvVTmnTNqyXbSUJyxNxGYLN/E/st4bz8boSAGrveuJwrF/aBpIRMRJXHXYS2jqHfI6EsNoEiUiSZIPBIKUmip3+CGzkBatUKmEcSZrR5hlmqmNChR77q+tBSU49ndaSsvoSQOdSESPjZpHF1nZ1zG059t5YfbacWQRszGb5u10/sfoAhPEm2a/h7nxOlZCWNNJ2KnGtBwqQQOIaVbuz/eQcl0olNBqNsM+3Wi0sLy8HQoprvdfrodvtpuaf7dI9T9ck26T90L4DSO3hHGfWqXkgraJWSTggHdaq86HfjbxHyfPxeIzBYBDCqBcWFgAAvV4vRXprudomtQOqhF0R53A4HDsbTsQ5HA7HA4jpdIpXvepVePazn40nP/nJAICDBw+iWCyi1Wql7t2/fz8OHjwY7lESjp/zsxiuuOIKXH755VuuK3mgzhiAEM6mDmCxWEwlZ9fwRxJcwKa6iI6IOhskOdThm0wm6Ha7KJfL4W/+bkkaAIGgodOZy+VC2BwJCLZNVU42zxzJR62D5B3br3nk1FGjMxcjdTheDKWi01cul4OzrI4i56HX64WTP9URpLOnKhZe14MCOF8alqZts868Opn6O8dZVS+2LEtKKKyyhOVZAkPtTnMSklRg+K8lqLQc66wqIWgVmKxDT0MkLHGhY2zJShJPjUYjEFAaTqdkslXr2bKZp61er4dcXL1eLxyYwDHRcqlSYnmqeCJpy/DQJEkwGAwAIBCGmlNQbZvzQCKYZBnvJ3kCIKWSWlhYCMSJ5o1cW1sLaiCGGOoBKryP+4ASe6VSKRCd2lf2UdVf1u6szVvbVILN2nPsmVjZMULbPq+fxdphy9ZnLbnIz2NkHJBWMtPOda3wHj1IhPdoKLLa5mQyCS83dO/RE60BpFS6Ok5UUfLgjkxmQwG3sLAQ9j3289ixY2i320H5xpyGNl0Av1OAzTXLfIxsM7C55yhhS/DwkkajgWw2i16vF8gybRPHW8uIzbd9uaDzS0K71+sFRSif4WEnMaJWv6PY5mq1ikaj4UScw+Fw7HA4EedwOBwPIC688EL8x3/8B/7+7//+Aa/r9a9/PS699NLwd7vdxkknnYTpdIpSqZQioehwUEFHB03f0jMfD3PA0eHjPRp2CKSdEg2xI5nW7/dTRAJDTukwUsWhyggNx2S4DokMKtBITOk/daS0vXS4VHGhzp8+z+f6/X7IuwRshoUCmzmZVldXw7PNZhNJsnmoBBUmvV4PnU4nlTNLnTpVpZCIYU4oEoKa58+qOdgenQ91HpXo0edUGWjJOHUcbQgn516JLQ2vVeWNqlV4D8kbJVtUZaL9iZGESvyR7KKNaG4mEhe8T21TiQ914qnqVLJQCUHmuLIOPe1MiQU617t370aj0UA+nw/rzh6YwvZrX7TNJBjZfw3lI3FChRkPY1CCXfvBUHESfsypyMMTSCL0+/1A7tRqtS0nMFM9ReJAlahsD/Mu0oZpB/ydJEaSJEGFqCGIOp7su+btImap2JQ4iinPdM1YBZUStJZM0f0iRlZb4sXCrrMYEWjtVglLm/dNc2IqGTudTlMnQnMM9YWDvrTg2OsJycCG6pH2xTqKxWIghNk+TYHA9c36SMr2ej1kMpkUEay2yfu1/6p6VVvQvdTuMY1GI7Rdlau69nWPo62pek7LtvVwnhiiWqlUwhrh3q8pHGY9z2tcp/MeyuRwOByObyz4Lu9wOBwPEC666CL8+Z//OT71qU/hkY98ZLh+4MABjMdjrKyspFRxhw4dwoEDB8I9//zP/5wq79ChQ+GzGEgYWOhpeHR8SVKo4kEdEyV81Emkk6VkG6GOLQ914DMkR0iAqXKJjjyJGHXSSVSwPHXW2GZ1yNmHGGlo1U8a/ghsOoLqDGs5Sp4pwafhd8AmSVOr1VAqlTCZTLC6uorV1VUsLy+j2+0Gx0wVKiQh9SRD1jsYDIKTpmPL+jRkWJ06G/5rVR7qtOocxsilGGFJzFItxRxe9oPKQRt2qO3VOVXFm7ZX67BkIm2FfWS7NI+gEizsY61WQ6PRQL1eDyeEWvUh7UcVhUp40qaKxWLIpUZCSskPbY+qNJmUn0RZNpsNxAjXc7PZDPfTXjVUkGuIa4wECdVRrVYrdWojQ1z1xGPNU0gFG8eEn2mIIwk+komFQgH1ej3VP84VQ4BVKaeEoyXICD2cwpJulviKkVtqYwp7j7Vze03JW7W5GOxLAl5T+7Ptt4Qc9xvbJiWiuWdRzQggqGnVhpV0I9HKvT+TyaROA2Y5tVotfDdw38lkMuEwGx4gQWKX64/ro1Kp4IQTTkCxWEyp4/S7Q4lztlntLDaXVkWsaQB4iinDRO33gY41x5CwOSktKavtpuK53W4HxbOSf+yb3Z/UdtgvPRzD4XA4HDsTTsQ5HA7HcUaSJLj44ovxJ3/yJ/jkJz+JxzzmManPTz31VBQKBfz1X/81zjnnHADAF77wBdxxxx141rOeBQB41rOehV//9V/H4cOHsW/fPgDAX/3VX6HZbOKJT3zi3G1S58Equ5JkM8ebkkN0xNTptPmGqJhTEoZqCpJKwKZ6iwolzQ1Eh5rP0uki6NipE0xnX8OwWJYSC2yrhnGyb5acs06vtlOJOZbHe0l+kDwYDAbodDpoNBqo1WqYTCbodDqBjKNDaBUfSvCQbKJTyjqsOkbJBs2Dx3KtskTHRR1B3suyrdKI91gSTvMn8R5FjAjk3OkhDdqeGDEcc1q1XKrBbDioJVOtMs4SPGwzx01DganCtCfeqtqH/3idhFir1QphqaoY03VoCQgNCed92l4+b4m0JElCfkjaKokrVQxShabjTLumiojEzOLiIhYXF1GpVEJfaeu8h4Q7D1bIZjdDx1dXV1N5FvlSgOGM9vAZq0TT9ZYkCRYWFkK4oZ4SqvajsJ/FyDJ9TveOGElsn7Plxu6LhZvaOmPEjJJwGnKt9dpygM1QY5J3QDokXclO7o20OxK4XK+cT93bAaROySXpRFJZv2dot1RH8kRc2ghVmGojui9acl4JN0uAa9425qOjvbM9uk51D7QvdLQNOt6z5m88HqPT6QTVn315w2fY9tjePxqNsLy8HNrrcDgcjp0JJ+IcDofjOOPCCy/E+9//fvzpn/4pGo1GyOm2sLAQEjn/zM/8DC699FLs2rULzWYTF198MZ71rGfh9NNPBwB87/d+L574xCfipS99Kd72trfh4MGD+OVf/mVceOGFUdXbdlhfX089o+oTAMGJptKN5Boddj7DsvRvzTllCTt1HAk64Sxf1V/A1oT6qjqjw6IklZIZMbBNsRw9StLRCbPPWVLLklh0oLS/a2tr6Pf76Pf7qFarSJKN8NZer4d+vx9IO50PJYdUAUL1mzrNHJPYAQf8XOdF+8O2qqPLfnIcOS5W5RVTj8Uc1O3IBdqbJeKsU2yJFzunmsOQddowL3vdtlOVa7Y/qqDpdruB5BsOhxgOhyG82Ib9qo2RYGL4J8sYDAbodrtBGRlT3ahdAJunGusYJUkS2qE2RAJSFZ9q46po1Tr5LOumMs2StLonVCqV8LuG0nJd61pl2RpiyTq4JjR3oxLJlgBZXFwM+1a328VwOEydsBsjcLSfMVhCLUbsWZvT52Lkm33G2qbFdmSifY73kSwG0qcUq/pZ14EdD9oJ54pri6HKJGhJ9BJUj5EY5Pzpnqi2wHIymY38i7t37w4vWQ4dOoThcJhqk7ZVy9DQbM63Jeu5R+hJ10qwxQhWfcnEfVNfYiiBOYvE57pi6Ll+x2if1GbsHss293q9mTbgcDgcjm98OBHncDgcxxlXX301AOB5z3te6vo111yD8847DwDw9re/HdlsFueccw5GoxHOOussvPvd7w735nI5/Pmf/zkuuOACPOtZz0KtVsO5556LN77xjXO3RwkVJbBI7JTLZQCbajU6VHo6H5VnbBuVDCQBNHG4OjRaj6qM6BCxXIbfsZ3qHE4mk5DfSAkNSzLQEVfij/XYMDe2n1C1lpKMdESV2JqlpGO7Sa5MJpOQjLzf74dE/9pmS1ppfjQq/hhuZp02dQ45pjb3mfbXKmo0/DVGJsR+t05yjMjS8bT/SMCQiCOZGFMfab22bI4hoYSBjgkPHiARpIpGEhV6Eq069zY0jEogDQ1l21R9ZEk9knm0qW63i+Xl5RDCpiSC9kHJL4aqKcnEdaO2TMKCh6CMx2OMx+NAglG1xPFXdRCwQTz0+/1AuDCPIxVLHINcLhdCd2u1Wlj/muOOtsgceUrsUaGnNqn7ic6Pkpwc93q9jmq1GohOJuLXQ1BUiTSLKLa2bcnUWc/E7F9/2nuU6Lf2YQlh2kns5YLuj7a9LJ+Hy6hqk3NLeyS5xTaQ/FelMm2JBxzonkN7smH5+nLA7ic6LwBQLpexb9++cBDKwYMH0e/3o+Oq60tfVHDviCl8dQ3THnWcdM9Tglk/i82PfZmjn1slsd6rZXI+dN9jO7hm9QR0h8PhcOw8OBHncDgcxxmzlBGKcrmMd73rXXjXu941856TTz4Zf/EXf3G/20PnSFVEdJJV3QMgkBXW6bdEEMkqOs4AAvmkTqeSb5ZIIglHp0NzHCmRR8cdQMoRY9J7VVPpM+qkktBjvSQN6IBZYoogmaPEj3X2NDRRnUXez5BGlkOoU6b95bhynEulUnAqNfk51Sa8h3PJMYwp3zRcyiqWlLRQ8m6Wuoi/q2NJaPiYtRuSJ8x3p0oTrcOSWmyvfs7f6eSzfHW6bf482raGoCpZQsWmOvpKaKhdsd/qmCtZwsMPptMpOp1OSNxOQlZhx5X2onNoCYFHPepRyOfzaLfbQcHX7/fR6XTCWHC8uRfk8/mQTJ7P6PxlMpmg4uMY8fTJXq+Ho0ePot/v4+jRo8jlNg/dqFaraDabIRwXQCBw2u12qFcP6FC70/nXcHeGSrK9VChWKpVQZq1WQ7fbDYQcT3PVsYoR32qv/GkJHSXa+VxMTWiJO1unJT1p03btzSL1kmTjoAMeasO54VwBSJHIqgZTEpykFl98KEmv+dq435TL5TCPPBFX7+Fcqs3Svvj9oAeecH/kGmw2mzhw4ECYM7V3DbuOjb8NM7UKYNoU1am6n+t3kd6r5cdUdLZdCp0/tWdrd3aP1XuUlHY4HA7HzoUTcQ6Hw7HDQWdLk0bbn3SOlBxgCGGSJCHvk+ZWYz4gKnJUVaRKAXUsY8oGhjepao3JvpU4UoKLjvl4PEa5XE6pkqiOsgolYKtjZYk0q3Dg2CliKhgNo9XwOn6upA3bwTlR55E5xJQwYr8qlUoqlJOECZVzw+EQd91115a5twRPTBXC3y1ZaolDe5+Orf3MEmssk3Nrw5JtG9W5tkQUoaFfSizSruh8c05JSim5ZsuNEUPqPFsCxd7PZzh/lqzWsaRDb8lOS/7p2OgYUUHU7/dT65dkZKlUQq1WC2pMkhBav5JpHEslEofDYSBjcrkc9u/fH4g3HgRD281kNpL8k0jjfGcymUAu5PN59Pv9YL+WYAQQQuWpKKUtkngjAUSVLA//qNVq4XRiKvt0/9Cx17m2Yxu7T39XAsXOiSXuYmXonOvcWmLHlk+b4MuE4XCYOoWX93Ev5eEgQDqUc319PdiOTSvAPZ3qOPvSRPc3XQe6/+s4AUjtc6xH98tWq4WTTz4ZxWIR7XY7kITD4RDj8TilqtYxsSSmgiQ7baNSqQTC3pLg+oIGQCrc1qqMY4R4jDS16rhY2+xeOstOHQ6Hw7Hz4EScw+Fw7HBQ4aP5fIBNYkydd2BTCUEnyZINSlQBm6o4kh7WydF77UmtdFRUtZckCYrFIgqFQgijYv0knTTk1SrdlIRTEoZ91iTiSgLR8bQkE8dIQ8tYnxJM6oxRVcj6VHnCMizJxLFi29m/6XSaUrJQkcETLHmyZ6/Xw9e+9rVU+Jd1EmPKKlVx2Xmj42uVPVYRZMuY5Uyy7STilAiJKeNixJte508627QbYCMMkwSQJXI5lkpKaT+tHStBpnVbG+Kzdmy0b3auLRmjdmYJQSU+gI28kyTaGJpJBd5oNAqJ46k0KhQKQZGmxAoPoSCBSRQKBezZswe7du0K+fFItlF5RhskqUfyizm/eIIq7ZX16z4wHo/RbrfR7/dRKBSwsLCQUn7ypypE7frjQQD8pwo5DYvUMdZ5i5Egs8iQ7Qi0e0PGWYLXEjmzSECG5irRo/PF+0mo6T6iRJ6SoNw3dSyn040QalWFkvzUEGM9fdiuM86Dqs9UKav7SzabxeLiYiCuV1ZWQl/0Of1bP1coAcZ+k2zWE8RtagIlDnVOLcFo7WQWmavfCzFC3xJxum/b71iHw+Fw7Dw4EedwOBw7HJa0UueFyhu+oVd1EXOcqTNMB9CSc+qU2XAlDfMBNlUXdOqssoLl2mT4AIJzCSCEWqlzQ8eTUMfS3hcj6WJEHKHlKCGpDpqSK6xD84mp82Xzus1SQTFEifnESGJksxunclYqFZTL5S3PqpNvHVclj2JKHkvWKWIk3yyCSVUvrIMhyDbU17ZJ51Dth+WqE69EHNWS+ryedGrXAMdI+6skAa/pWgE2D+hQglQVOzr2HB8l5dQZ5z1W4ad91/v5fLVaxe7duzGZbJzM2+l0AlHG9qitc9xJdqvqiQQpn2HOSADhkBGqTdlvJXuU7ND5VTJ3MpmEMEe+GNB5ZN29Xm+LCknbpnPLerQPlUplS7gqycbYYRXW7mIEj7VHJYTsGtEyLEmjZWxXfqw+njgKYMu+yjpoe6oG5Fhyv6WKkHNCQo9rhf+srdt+2BcNSkyPRqPU94qeIKrzpoR2s9nE4uIi2u02ut1uaJ+GmttwTt3bde9mu7n3cgxie1+MWLMkoJ0LvUfL0u9H+3LB3m/3TYLj5nA4HI6dCyfiHA6H45sAdLBUEQQgRUapWkIJJwDBSbMKLlU6AEg5eqxTyRobNmgPXyA5ByCEwVKRRqWTEnrW2dWQJ7bHfq5EX5JsJi23yo1ZJIhet+ScDaNUAseSK1YZwfFkuUqiMJSsVCqFOkkocJxsCJ7WoWPAcVDEFFdskypwrOPKZ9WRjf3OskneqMJPy7Hk33aEID/XOWUYG++3IWfAZsioVbNpO1Q1R9tUMlWJAS1LP6ONaPi39tPalCWVYmo72inL7Pf7ITyR64kh3VSgZTKZoJIjuc6QbqrTisUiarVaCPPmONHGVldXw7pkXdlsNiTaZ/nD4TCEUDMPoCquNN8iFXQAggquXq+HE2s13FLnmPNnyWO1ByrwKpUK6vU6BoNBSjHIUF0ty5K328ESMvazWWR2zJZj/YiVZ8lTkp0xkiyTSYfoK8nLHJL8nGOgquRcLodarRbKpNKRexG/C5SMtgrXwWAQCFT9/lC71tyOvHf37t0YjUb4+te/jm63G0793m7vsXuQVR/rYSfsg3436XN2PSpJrn2wBJxtjyWSY98fswi+2F7ncDgcjp0FJ+IcDodjh4MOQKFQSJ3SSCWRJRmy2WxQrShxRoeIzgJDXvmcdSpU+aL3AVvJG1XtJUmSCl1T8pAqjel083RSVdwUCoVwGiSAFFGipBxJM22LOqxWnaCOuoY12jBcVWxYB1GVSZlMJtU/JbmU8FSHzp5aSwIkk8lgNBqFnE+WVFNnUpUjOldKXFo1o6pe+Iwl0KzjqOoQPjProAatR9ti67I/VRGk4ZU63xr+qO2w9VrixPYhdh9tjHagqiC9R+3MkplKlOicWTJHr+t8DAYDtNvtQKhpiCgPYqBykgo3rsnJZBJCQUnA0D4LhQJqtRqq1SrK5XIIS51MJkF9aMkwnT8SXzy4gcR8JrNxSnO9Xk/l3uJYcA9YWFgIY2vH3SoV7TxynvUgk1qtFsJl+/0+er3elrBV2lKMuJ4FazMW1pa1zVpHjMyLPdftdlN2Np1OU+SclktlIIAtJBTHVXP5kfikspTlq2qT+xHby7BYfj/QRvSEa84PT9flfkd747xzXfI0VX5nrK6uhrVh1xDHR79/YirTtbU19Hq9MBa6Zu3aVxvQ7z6bL5N9U8JTbUe/Z+2ewH1f9xeWGyOGHQ6Hw7Hz4EScw+Fw7HCUSqUQusjDANSRUMfMnsipji6JOOaWsmSEKt6U8KODlc/n0Ww2Q8gpnTj+zrJIEtC50sTZ4/EYlUolkIjaRhKDdOYt4cR/lvRS0o7KMhuqq6FsVtmwneMeU85ofy3Jpc+pMtAecsH2k1hg39Vx1r4BW0NKbf9ZpzrQVNnp8xZsk5bNfqqjS5US541jTDux7Zs1jrYPdOppyyxPTza0Trcdk1n94d8agqikpZKu6lBrW+3vtlx9TsM0Y/cqAUxyI5/Po9vtAthY6wsLC9izZw+Gw2EI8ev3+6H/xWIRjUYDzWYzHNAAbKjSeAInD0WgApOnr3JcrUqU5BxzOiqZ3ev1cOzYMUwmG6dpNpvNlGJP+8wcXlTXdTqdFMnZbDajxB9hbYljT7UgDzdh3/r9PgaDQQi9tXuGLSdGYMfus3MXgxKHeh/Ls3XY8mkDfCGhLwZIhvEfw4Y1JyJVcJq2gKQV55HkOfcDDZlURR7/JvFHO+FLncFgEEhh3WeowOQ64gEb5XIZCwsL6Ha7wQZsSGpsb9exVNKOB40kSZL6blIFtq5F7Svriu2f9rtk1jzrPGp/td26r8TsyOFwOBw7C07EORwOxw6HnnSqDoWSJ3RSSGbQMQMQyLV6vR4SpZMsUwUSHSx1NPg86+n1ekHZNRwOg+JAlUssQ3NWUWFhSR5bbyaTwXA4DMQAEHdsrVOlTo8NDeV9CqtuIOkxHo/D5xZKfJHsUadY69A8VvrZdDoNpIGG4aryQ4k1rdu2RfvCshm6aMdK23BP46nl6jMMh1teXk6FpsbmwF6bpRACNpSXzCdllTJW5WL7H6tjVn+0TCVfY8ThvNiOVIgpbTgfd955Z1CcJkmyheBkCJ4lFnO5HFZWVlLr1ZJ/aqs2BDemGuWeYIkxDZkuFouo1+uBgIupImmHVLCRiGfd/X4f1WoV1Wo11Sc7lyTdtT/aF9YxHo/DT6qbbJmxOY+RP6qMmlWGXtd2zbIJVRHfeeedIUec3qMEGudb9ydL/nBPBzYPlokd8qJ7K9sKIEWqa/v0Hp0DVXzZvVPnTdvOPTCbzYaDI7Yjp7R/um+xj1QMc+75gkXbrPPC8dQ2xsZFX1zQTrnuqOpjHTak1X4n6/em5jp1OBwOx86DE3EOh8Oxw8GwNQ2BBLDFKdOwTP2sVqth165daLVaqFarWFtbQ7fbxerqKlZXV4PaQHO+JUkSSCESaFRvWSeJ5J+Sa8zvtGfPHuzZswfNZhPNZhOFQiEoWOik5fP51OmhKysruPnmm3HSSScFR4lOjSqYstksBoNBIB6ViGAeM2CTsFTlHICQVwsAbr/9dnz2s5/F4cOHU4o3S7xRkUNiSsObeMonsJmTj47prHxDSmSoUlGde3WQrcKD46D50JRQ0LBYPeRAiYMY8cWfqmZin/v9foogiZFQ1jGeRXywrTZ34Sx1miXrFPYeVdHFQsu0f7b92i/+rmQEr9k+se2x6zGyoNFooFwuh/WTz+dDiC5tn/ZGJZuGKQIIyqRcLpcK1YwpNZXAoV2QAGS5GmLOz+v1OjKZjZDTRzziEdi3b19Q2HF/GAwGoV7mcuv1euh2u4E4YejjYx7zGOzevTtFrrEdbBsJSrVlji/JxMFggE6ng6WlJRw9ehQrKysYjUZb1g73GZKNGi5PeyAJRoIRQCD2qADTFx7WRlVlSHKM88O18+hHPxqNRmOLrQ+HQ6ysrODYsWOpPthUALxWrVbRaDRQLBYxHA5DKDHHxq4RJf2z2SxqtRoWFhawb9++oFK0e4Y+GyOWaR9KhsXI7f/8z//ErbfeGsZf9wMlhQuFQhhP3ce0T7RhtlPzomrIc2yNsnx+7xSLRVSrVbRaLVQqlUAcJ0mCTqeDbrcbSGiuTVXp6voh+D1N+3I4HA7HzoUTcQ6Hw/FNhpjjr86AEhKa9LxYLGJtbQ39fj+Eu9FpVzJCnU09uc+eVKgOqSV3SBTYXEIAgkPDdmtIqpIYVqmhobCawF/VPWx/LK8PgEBGqZKPIXSdTieojWyeL4blFYvF0CbmvGPb1fnUXHIxFYgqYWLqEqtO0d8tEWptQ51cTdCvjqEldWMEn7ZViQtL9sZIwxhifSJsX2YRbTESTscsRqLZv21dsTDSWeMfIzK3I9y0jthYtVot7Nq1K3zG9cLDPXjqsYbvFovFFClDgohkKxViSiIrCUXiXQkWqyIjAQYg7BuatJ9rENjMwch2MoxS1yHDL5MkSeWni4295gjjeHK9xuxiPB6HEFUl5WfZgBKR2lfdGzRkk8/GVJk6bpxnbbOOqW2P2hMP3OA/3QvVFnW/5JxYklEJebvPsD3j8TiQpHy5sB1xZG2XZanC0vZR92Sbs477KPcT7qNqR/z+UtV2bA6VoOU+R9KNL0t4wAlDtpl/r1qtBoJ4NBphdXU1HEjCdZPJbJ5gyzq5H2oaBCWxZ+37DofD4dg5cCLO4XA4djiUeFGywTqFhObIoZKDzgRDMDudTsrhUOWTnoaoYU9af4zYsCoPzXvEMCGGqlI5QAKLjphNqG1zpFlnUkP6lNxT5UOMwOHfk8kE7XYbS0tLQYXCcVPCJJPJoFQqBcUS8zOxHutAxsgYVf+oY0snU0ON1ZmLzbNV47B+9ksVjqrO0bYoOWrJJ0tsar0xMsSSpnasFbPIOuvk2/tixOMszBo3tSF7b+x+bYuGf1oiVMfeEqaz1imAcPABc57pWuN6jeVAo3KHqpzRaBTWTyaTCUQYiSaGhisxreGdJDHK5XKwa9q4nvLJvYH2o+GsJEGYT4w2p+GP1Wo1peiz60NJabbBkjAcA97HU1p7vV5Q8bI+Sz4Dm+SP2gTnUnOoKaGnRJ0loWatIxu6HYMSceVyGdVqNYTz6osMJbqm0428ciRpaQdKSGn5antKPna73ZACgApilh87UGOW7SuJPIucX19fDwpKVXPqCckagm0VfHyOJBvtTudWVWgkorkGNC0CiWLmZ8xkNlITdLvdoCrkWqPqjuOjB/RMJpNAKOqLCiqgXRHncDgcOxtOxDkcDscOBx2f7UL1rFpHnTM6I4PBICTP5gEBShqo46tqDiXMtF59NkYOanlU4tAho+pDySeGOamjF1N3sGzNQaTKDACpcE0dRyXa2EcNn1MiUR1/OmB0gHVcbR02nIxlqFOv0HHSMdR5tfZg6+Q4sh6emlmpVIJiiASiKqFUZcNyY+q82FxbqOM96z5blraBiNmSxXakmY4D23JvSDFLyOnnSs7YfsxSv8wqT+2Cp5Iy/Jz2QXJsOp2i0+mgWCwG4pxrhPOpqlW1BbaZBJwln3RNaxuZtN9+RpKeBC+hZJHeFyMu1caUkKHaVe1Yn9H1oXOpxJKq+Oz4a/v4t12fGt7NcvWFxCy71n3HrnclFJVUihHtJOI4z+yP2oKSXprPMqZUVhuwfeXznU4nnKwby/moe5b+rWOsZKBd07G/1U6UQKQd2JcZsXWkxCht3s6h1q0KPE3BoGHUw+EwNc68h0q46XSK0WiUUh+qKprl87tH++VwOByOnQcn4hwOh2OHQx25mLPD39WRAjZVBbxG5QxzUMWcSnXmtd5Zqo5ZJJx1npQwYIib5oBSBRCdGnXArTLOKudijt92oWEkq5IkCeQkkFax2NA4VR6xXFVB3JPqRZ1adcqtY2vJL1uW9sGSZZzzQqEQ8h9R6achtKybip7tCF1rT2yHJXZ0rLfDLDuyfZlFYt3TOMVIhNj4xcrWuYo9N2stzCID7TUdvyRJUKlUUKvVQrgpgHDysRIW9Xodo9EohJSTTNJ8aFaFqrkfAaQ+471KSidJEsidcrkcSBEqf0gUVSqVQJyxL0p6cn0reUUCmyG3SnApuWOVZ6qGUztVWMJd50PHetY1rgfOjZJqVBLa8MvYutX1oDkm1W4sEcfPSF6SOF9fXw/59JTMU4JPVa46frG+2vZx7KmQ5nwzH6Fdz7F1F5v/GIkNbJKV7CfvtWHAdo+JrTfNS6d1MXyZikebhoAhsaVSKezZPCiG+Q1pZ9zXuZdqzkWWzXyC+j2pSrzY/u1wOByOnQMn4hwOh2OHQ0MsgTiBAMSdGKtCUcScNQApp8KexmehZSuJESNzbBgcc0/xmhJG6jxadQmdIttndZBVxQFs5kTTz7PZLHq9HpaWllJEXCy/lNarTq2OmTpgvD5rPrRtMeXQdsSCnS8dd1VjaBL/Xq+3hZBQe5ilQFEyyJIVs5zuGAGl91ny1pJpth32eWsPlgCYNRe2LPu3jo1tI9upykFt/6zy9XM69bxvfX09dQDAdDoNzr2Gf5IkWVtbCyqdbDYbQrNJKmiCf1WMZjKZEBLO9WUVXNo3YDOclONYq9XQarXQarVC6Cr7x/bqYRLj8TiE1LbbbfR6vUBik4ijPemBJUqcWpJYQw91zPWkWT5n15vOB7B5aIUlddQWNBQym82mwkU1R5nuU7E91ZJyloTTPZQHCGhOPY4tVY92r7ZqObv3WnJZX2ysra2h0+mE0EvuG7oedPx17ek6iM2fHR/dm/RFCl8M8X6qLe33m44tSVI+o/sT26fjri9/+BxDqEl8WsJRbYM2xmdtHjkAoSy7dzocDodjZ8KJOIfD4djh0P/Q21CjmJKETpM64+qQWYIjptCgQ61Ou1VwxZxOS0Zo2BqJOFXY0JnhdTozmn+JDiSJCTrENpSUTr1VJFjnXvPJra6uotPpBIfL5spT0kQVPjreHGM6a+qgafiqJUat0iOmeokpUmz+JvbNkgEMP1PSkg5iLJRNHW+b40iJ3FibrC3EELtulTaxz7RObYvOfawv1ibt/WrHOo56v5LKdnxjYX+xtrIttDuSXFSfaZt1bpQsGQwGyGQ28hQCG/ZYKpXCqZ5KFJM4ImGWJEkIB9c6WQ7rIxlDQojkXS6XC6d0Uh3E9pHgUKK93++HddXr9UJ+O1XqcY3xeWAzLDVGim5nr0oisV3cK5R01zVIUmiWrcb2Vf3MEl96UAKf5d6lKi1LWlvbYZ6+Wq0WiFZ9jm239h9bi9Z+7f28V1VxJH21j3pAh4YOx9a9fSlCVCqVQG6NRqPQB7aFykM+a0OdSdDxu0L7qio7VRvzAIxsNhsOaCBhPRqNwgENSnCSvIupfQGkTkmlilXHlmNlx8bhcDgcOw9OxDkcDsc3CWLKHiDt9NjcR0pc8d4YUWEdTf0ZqzvmUPInHRk65nT2kyQJahk6Rjacjs+oU8V7lKiwpJEm01aViCo19KRIOozMl6cOHftBNZF18C0xoGNgyVGOmXVkbdisKq0sYaQOqaoy+BzvUZKBDmu32w2ELMuw7YuRSHRKdewtgWiJLCWotJ57Ijti9rTdc5aIsPXHMIs4mEXu6TMadqf3WeWk2qWOhS1TCVudb7U/JW40DJSfMZcYsEkO5HK5QISxHq4JJQiUVFQ1W6lUCmGsDN/j70y0z3XCz0mOcJ8ZDAZYXl7GsWPHwoEwJD3sIQ1av46FvkywCkxdK1pGpVJBuVwOeb6s7Vmb5Gd6wIE+o2S3hs/q+uf60fBeEu8cD63f7r0KJfYYVs6xY9iktUmSjdae7TrU6zHCezqdhpOjGXasOQC1Xt1jgO1fxtj1aMlP9oMvZEjQcUyTJAkvZdhOEtmEjiV/MhybB6AwD2OhUMBwOMTy8jLa7XY4SZVknSoeWR+AMBaq2uOeqnZiFZ6z9i+Hw+Fw7Aw4EedwOBzfBIgRZbyuyiXrcNEptISNYhZhok5f7F51gtSRpANDRZ0l4hiKRDKuUCgEUoFKPG2Pzc1jFV3aVtsPq2BSZ3IymQSHTPtHR1zbYuvg5zpGSrypo0rHln207VJCLEbwsA57yATn2oaJcnyolqKTa8MqCVUc8m+qSQBsUebo+M+ymfuDWWSf1mdDU2eRxpZs0/5rYnct09ZrxyY2hoQ+ZwkHXY8AQoijhqayLaoiVfKBz9ZqtUCuklDg55ZQIgkXmzuSfAxj1rDTXC6HUqmEarWKUqkUiA2WR2JFiSeejsyfzPmoClZdK3ZulWBSFSznS+eRyOfzqNfrqNfrIe+Z1qW2oPah65fr2SrIrJ3rCw2WQXuxRJOS4voCwdopy9P1XygUUKlU0O12Q1naD7s+ZhHIug+RGNS9gp9PJhMMBgN0Op1AXOnztg5FbK+yJDtfsOj8MTRYQ0z1J+2PZWiuN83RxvGlgrNWq4VchiSiqV6jffCwohjZp6poEnT8jOuVc6Rzw/vZpu1eDDgcDofjGx9OxDkcDscOh3XYrMMSc5Csw6Whl9vlfOP9sbq3K1+dUWDToWGeHTqhGn7KZPF0oGLKDUuExBwlOswaMsd2abintj2bzaLb7WJlZQWDwSAVKqXKuVnqGv4kmaHtjDmwVglyT+Nr26r5lbRv1uHl3zz4gmojm+tvljJGCRaGKbJszpmSAlblo0oQO5/aRkt22DG217XNs0Jk7X1aJ3/qdfZTnyPJpPkMY0RfrI+qmFKCx4YRkpy2ORg1/xjnN2YLLLter4d+VKtVdDod1Gq10GbOoeZvs4QSc9apSo91lUol1Ov1kOCeyjglb6hepdKVJxAz7xZ/kpRSxaraMMdKx9EScTqfuj9kMhlUq1UsLCyEMRyNRqn5tHNmVbUcV50vqy7TdWIJYjtXs0IbbT8s6WvJOO6NCrsnWrLZ2omOM/fN2NrgYSCVSgWVSiUc3KBjvl37Y/san1MySz+nLWgYP5+zCmWb41DTJvCFTqVSQb1eR6VSCWNHMk0PZtC9jmuQ+7/u72yjKt2U3I2R+LGXXQ6Hw+HYeXAizuFwOL4JEHOC7OfW+VEnkeFr6vir88Dn1DG26gb7e6wd6rBRlUVnnCoVngioDh/zV2nbNcTUOs8x4kedK94fU26RFOv3+4E0oBNuYdVpWgaVbppnS0PQYv2wKhU7dyQ29HMl4Vi+zmOMLGI5qshRlZG1K9smS2zyn4bC8f7tbMDeFyN5LdEcu8YxsOTrLNLY2i7rtsSbEntU4OTz+XC6J1WF9hm1MyVpLCxpoWHiJKUZksf2KWlGokzti+VWq1Vks9mQT6zZbIaDXdgf9oV7gB6iQCWQhiKOx+OQp6xarQbiTXOwsc8kb0giDodDrKysYGlpKdRFJaYSLUoI0zbtSbEkEe0c82+7d5VKJSwsLKQ+1/mytsOx557EvinZbcP5YySwVenpWtc28+c9EXoE7Z0hllT5xe61z8QU0rE1qWXRPobDIXq9XiBgidgajf1uSXf9vVgshhczetqo2rf9rtE9zKqh+ZO2xYMu9ERUlk1VMNXPzOlnXwBZG9GXRSR2Sd6R7KX98LuNpxU7HA6HY2fDiTiHw+HY4VAHANhUEVjCzD4DbKrhSHJpfiXrBGoZdOpiCoZ7cuxUycK6x+MxSqVScIoYukbio1KpBIUDHRolELQdmj+LzhmdMbZRFW5K+NDJWltbQ6/X2xIuRWj4IMuLqR9IUOjBFkmyeVCDEoWa2J6nxdKZtwSROqY6pixfVYaxeee4xdQrlhBUZ5LlUa0VU/bZ8uz86/3q5Fr1jG2TPmMVSQTznZEU1LUQa8ssAjBWtyphlPS0NkQ7UnJUVYuWLNWwTZ4IzDnSA0GYb41hppYc1VBazgOJuiRJQh6sQqEQbMuGz2UyGYzHY3Q6HbTbbQwGg0DEMbyvVCoFgpzlVSqVLUSaEn4k4rrdbpgXVRqVy+XQN3sKtLUbtpMnhapaDcAWQpnzwTDa0WiUqp/Psi88rXkwGIRwcUtecp7VtnRN6v6r5Iwl5blv6J45y7a1LwACCccQ/u1OsNb+cYys7VvyUtcC20hVHMORecgC77UHv8TIbrueaafaVt3DaVMcS/s9pHuQ9oEhp2yr/Y5kuZ1OB91uN9g59w6eQqwH6jDPoobj66EMHBMSe1Rf0o64/i0Z63A4HI6dByfiHA6HY4eD+Zn4H3w6olZxAGwNkaIzQsfcqjz4u3XQlFxQBYySRHzGnhbIz3ivntzK+tbW1jAajYKqR091pCNnE5GrEoptU2JHSSJesyFZJEuSJEGv10up4TRPlE3iroSPEjRsd7FYxGg0Sqn62Bb2XZOCa/tIKqijrs6hjrNtix1vS8xapYneqzZioQ6/DdXT59WJjxG69pq1E7U/23Zro5bE0+dj5LAlinVtqM1b4ozkrNpfTBWnBxyQtCKRwDDNwWAQcqTpXMfaraSzEgR6eIklo6hos+RiqVRKka7lcjm0vV6vo9lsolqt4tixY+Eeqn9IbHDfIdmndsncXnyOyf5JSHC9qs1rnkIlLC10varaSEkejoXuA9xrSPZxzXBcue6UeFRCRYlp7YOuvZjtxkgvXbOxdTBrreg+pwcO0LZ0fPRZqrY47yR92Ue7x+vzWs76+jp6vR5WV1dTisgYbDim/m7LJSGrc8VnbO5LVWoCSOUP5brTMGol3YbDYThIhGuw0+lgOBymxpfts99dXH+0r9iJvnxxxBc6tCm2hWq8mG07HA6HY+fAiTiHw+HY4Wg0GuFkOeusKeFlnT7+1MMagHgYK6/r53qf/q1Js6fTaSoPlL2XTjvJCA3hoZKADrXmUWM5dDqpolHnnM6WEhd8no6aJc8YJqeKOB1PrYPlsC9KqHBch8NhIGSoomDb1elkWVapY/PL2fnRedL+WFjH3NrALNLOfhazD6sE0vGyBESMHLYOsCXRlIRUslX7r/WTZFGSIdZfW16M2CMppCQPlYQ2dFAJENpUsVhMJYenOrLT6SBJklR4Zowk55jwBEYqm2aNtV5TOwOQIhv0Ovujir9MJoNKpRIOfSDBoCoo2lypVNpCemubeFJrt9tFv9/H+vp6II5IwPA5JcQsUcprOk8cYz28QhV5SsCR3B+NRqkXD0r8cH45xjrv3Gc4fjaEVm1by+N+ZO1vFnRviI0B+w0gqL7K5XJom9o8nye5qP3SvmvdagP2us5nr9cLNs19MEae6nWdNwX3bw29VmWkviSx32tKQAJIEbDAZoi39qndbqPdbqPX64Xwac4RST6SsbRJ/c5in5UIT5IkhHTzu2dtbS2odG3+1Vlz63A4HI6dASfiHA6HY4eDjrCGy6hSRJ2jWaSEOvDWaVLH3RJR+jyAVAgYFWxMgG3LozPIgwNIuvEe5qvSME4l09TZVIUaCSw6PyxvlppNnTZVTnQ6nUAKWDJM+0tHkMoeVWIMBoMQHlWtVlMHURAcWyV8VBmk98WgRIFiFpEWmzdbthI2WkasDUpYWLu5p7bH7rPzu10fLKxC0fZvO1LREhJ2zu09hDr82m4lHUiY0FaA+KnBtk3ZbDYVXgogRTBrgni1GyXfldTRdUe7I1nOsDwNoWZIH9tlk+aTPNNDAzhGHDvNLdbr9cI6ZFvG43FIpq8ka2yedP5U9UYi3NrM+vo6BoMBut0uRqNRUCBynWr4L0kVjocSwDpm/Md5Y5u5D7FehhwrMWvnmM9aon0WaJPcB5Uc1cMJ7EsPDcu0JLStT8fUqmtZP9Vk3OfZHk1XECPdtN+WuNWwTRK/ujZtegFVfWp5JF71u0+f63Q66HQ6KRKOUOWakn9WBcd2aig50yxoX0nq8iUNy9S+OBwOh2Nnwok4h8Ph2OHQkwAZ8kJHwebbISwhoaFXfFZB5ymW7FvLpuqiWq2iXC6HPEtMgq3PkTSgg0zSig4g8zQVCgWUy+UQXqUKCNYdS/TOvqjDy2t8VkP3dAxIAioRpwoT/q3OIp0rDT8i0ZjL5bCwsIBcLofV1VUMBoMwV8yPxPKpyFP1nOaZ0vmzSi7eb+fNXrd2oM6xOt3WUbf9t8SbKoiss23r17IsUabk0SxlkH5m22VJuHtSn8SISK0jdp+SGbG2Uk1DglnD2GyZ+ozWQfKHOcBU5adtpV3wGa4fzYGmBALHiUQDSSzWrfkJlYBXRSDzxGlIJ1U/SmTwkIaVlRX0+/1AJKqiCNjME6Zzafchtl3HiGvWKiBZNkMph8NhUOSxH2ynrkG1HVVkKcnFMdd51xcU+vJC284yrYqR827tUPuve5C+OKEiTg++sTbK9USb0L3G1k97UZu09jqZTAIRx1BlJeLsMxw/20dd75rjkG2280m71lQG/J7T+VGFHceabeYLFt3vdb64z/LQCFVd8neSbqxb54r90zHUF0L3tBc5HA6HY2fAiTiHw+HY4ej3+8hkMimlVUwVNItcAzadd+vs8T693yocrBJHk9BrOI46/wSdJoboUUHANpHE05PveFofy6N6RR0prZcEhBInGgqoCh9+TkdMnT1VlHCsSHSoYoPhpHyOxOSuXbuwe/duHDlyBEtLS+FEVo4BE89TPUVFjeYWi5Fl+pNQsmKW8oWf2Tm2tqFzreOu1+w9lhzTa5bkstfVBi1Zp+VbQsZ+bvtmiQHOj31e2zErXJZOvuYn058kHphfjOQBcx5mMplwMIAqqJQMATbDm1kXbcsSzIPBILTJ5qBiDq1yuRyet8Q0yQe7V9DGNQRQbZT5tthWVYkBG4Te0tIS7r77biwtLQXigkQcx4H12ANMFFwnSoAr6atjws+oxuv3++j3+2E+dC5J4Nm5VBWUKl9tPr8Y+awvLLQt2lZrf9YGZ61ztXsl4/TkWkumk4RjX/kcbUrJO92nlcTTeZ1Op+HwjXq9jkqlEvY/2qANw9Q92hL5bBvzDtJ2mCqAJC/XkraL7VGijy+ESA4mSYLhcBhU45pGgPerPeg4cLwYqqrh5PrCQBV9mmqB9lAqlVJrU1XRDofD4dh5cCLO4XA4djgYvqlv3YGtIWJEjAyZRejwmlUY2Wf5j44vE7MzObo+GyONNExP20IyjqoPzSEEbJII6kSrY61OvVW00Lmmg6R9oGJNHWetQ9uupB4dNnXuGLrF0yWTZCPkb3V1NSh1VJGkDmuMkLDk1Kw5s2RcDLPq0Ovq7OrfMTvgs0oIbEd2WeLOkmW8rnnfYqShDZmeZe+EKquUpLVkq5ZhiR5LcFriT1WqzE02HA5RLpeRyWRCyDIRm0e1PRLQSgLTbpSYILHNNaV5EhnGruuGRIyG88VsQa9zDZIkZBlJkgTV6ng8DmQNyXQ9ZIL95TqdTCZBhapzoaSk2kps/9HPSNwNh8OgzLUKVyValMTnOLM+SzDxHqts43Wud/aXhKo9nVrnOWaDasfWHvUeVTza9ah7G9vO/Yk2oO3XcbeEl46t5v6jOlLnRV/sWMLd2rqSiHqasw15zmQ2DhNhv2a9bOKeQbuc9X1AgllfqOia0zng95OezJzJZAJBOxgMUveqwk/bpaSvw+FwOHYunIhzOByOHQ460DGFkCXYLLmiZE5MbWEdXS2bz1uHiw4a1Sd0rKwDrnVQKUACQUkvEguaD0vbQOdJHR/WGXP8qVCwYbYagkTnzY4p69VcdlZ9pyf88Z5+v49Dhw6FnFv1eh2lUgm1Wi2MlSaqtyGINtRrFnmqIYT2npjjZ8kLbbM69TZXnt5nyShLhlliJ0aa2H7Y+vVzS0DGHHuLWDk2HM+OU4w0tKSUtX97nZ9RhcN/PG2URBxJNbv2lNDJZrPBTliPqnB6vR6Gw2GKgOt0OilSmWQck+xnsxsnpirJR3LBkm9Uh1HJByCQb7QRDQdMkgSdTgcrKysYjUahLEuo6dypOlX7x3qsSktt3baXY8oXAkok237qXqftVAKFfdO1SQKH48PPOF+qJrMvMmI2q2On9m8PhrCEkd3LeF8sjNnOl+4ZwKbiUclVXrdljEYjdLtd1Go1NBqNsAdawm3WWtex595NMpAqZCVKY6o+S6jqmLGMTCYTvo90X9L1o98XqryzbeVcc33q3NOmqD5VkpOgss6qIR0Oh8Oxs+BEnMPhcOxwKKkBxMk2JS+s88vPYwogS7LZ54C0g0ZniqfU6T2zlBJ0mug0MxyTThiJOFUFaf3q9OkY0KHUHHnqsOshEHT+NDG+dcJ5n61L83CpI03HjIooEhnVahW1Wi0ooiqVSlDLaPgVlTTsq839BKQJOnUsSRDGxkXL0PFQ9YaqvWYRvPdEqFliLUbsWkVejGyYRbJZcs0qP22Z+pwNT9yOsJzVX46/zoFdc0rC2H/VajUoMqmci6m+AAQlFckB2msulwvEGw9Fof10u12srKyEgwpIvPAkV+ZjpB3y9GW1IZ0fDZXmmucaYtilJR96vR663W5ot7U7/lPSW8P9LKFjCSc7j1yHSpTp4RN2bq2qMbZWlGAjQcXx0DnmGChJpuXF9l6da/6u+6batSVpdd1bkkwRWz9KVMXUWawvppjVdqyvr4cTVIfDYSB4VTFmD6bRvlhyNqY61n6xzRx7Pm/3K2tfOlY6ptp3O446Z3Z+tC/cl0mwcW3yJ++jbcRytjocDodj58GJOIfD4fgmgXVyYqooe68lDvQzAKlQLXuvKigsuaFv/G1IHz+3ZVEtpCobOjYk9mybAYQcU+qEWVJKn6OiR0+us05tTMnBMlSdow6rkn4kFZXEoPPY7XZRLpdRLpdRqVRQqVSQyWSCMkkTqFPZxFMnV1dXtzjhtp3bEVcWqoiZZQ98Vuu0trWdLennltBVO7Lt1HAzbaNCiV2rcLN1zoJ91pJA9j4db/v8dmQg51/XBXNrlcvlYDOxtcHfSXKo0oskiCrfxuMxlpaW0Ol0wgEFSlT1+/1UOOHy8jIWFxexb98+tFqtlCJOx4F7gRInquDS8ELabmyt2LmOjTOvqfpI22IJqdg1Ld+SMzqPrFPJM1XYcv50retzaj8sQ8NXY0SRbaP2IWaLVgnM362CL6a24j12j9bPtazYulG7VbvgCar9fh+NRgOZTCbktQSQsmkdHyVH9VAQVTAzbNQqlHUcOU+qjrP2lclsnvirB4WwHPab9sr7dUzUJmMHNFBByH9qF4p72o8cDofDsTPgRJzD4XB8E0GdTAurCJnlDMScGVuuJSViZcac7Fnto+NKIk7LptpE88gpKaMOGPvIz9WZJhiaZxV3VHEAW0/AU6US62OYHj8ncaZttWrBJNkMU+z1eiFUkPnjisUiGo0GarVaUOeNRiP0+30sLS1hZWUl1TZVnwCbeYw4zhoiGyMANBRQnU8Sh5aI2W4+LQmic6SkmrWNmIPPey0BZfsRU5aosiVGRtv7YwSx7Zfte4xUmUX02Pln3kMlhEulUlBu6cmWVLBxHnnC8Gg0QqfTwfLyMobDYSofI0mLdruN4XAYVdnRNqmK6/V64XRXnoLJtcPnea1QKKRCHmn75XIZ2Ww2JMQfDAYhTJMh35ogX08r5iESag+zCDX9W8lPhrDG8q9xbnUu7SnHSnzRDtku7kG0RSUTlYQHkFLgxfZYq6KMvajQ+9gHq7Czdsh+2JBaHSsNQVWbtoQY67fl6RwQtGcSwrVaLeRB5J5u58KGIFNJp6Q29x/OKcdJUx1QJa12FQsX5XOqfOber/NI2+G+PuvwC7UHKkRpx3ogCm1B0xWQbJz1Pe1wOByOnQEn4hwOh2OHQ504qwABNokqhXXo9Lr9XAkv1rGdo6kKmFmEni1bnRslIlQVQwKOCerVmVXiiQ4nf9fP6LiVy+UUcTadTkMuLio4LEnEepSIswogEhzaBqv+UJWFPkPigo4iVXONRgOTyQTFYhG33HLLln6zHUmy9WTGWWSojjnHme21SiD7PKF2ZR31mBJRHX5tB69zzq3CBUDKwdXwNDsWVDVp+fxd647NhSUbZ5FrrDMWxqaYReCxDM1hVSwWUalUUiQU5zyfz2M0GqHdbmN5eRlLS0shFxznu9/vB0UcCQclvFQpxbaPx2OsrKyE008zmUxQ1jUajUAuWKKI60/VcDYvIgAMh0O02230+/2U2ozkB9tG4lQVZGqTOmdKwuhYWgLJjrnuB6qwKxQKKeJfx57tY7/U3nR/U/Iotu+obceUpBZql7GXIto+u+fr82yTJeD1Hm2/tlvtXKHzwnKm02kg4vr9PhYWFsLY8SAc3VNteQBShCf/6cERamt2fDT/oLUZ2hPLYFv1ftojX4QocWdf+vCwBiVJNU8gbZn2bu2UNlSpVDAYDLbMvcPhcDh2DpyIczgcjm8yWMJDQ4HsfUCamIl9po6PdYwtWRNTbFjMIuKAzTxUSiixbA1Rsm2zpBmdbKqoeD8Jrnw+H5REzM+2sLAQwlzpnGmIK/9WVQfbrOOsBKgqP9Qht3+TiGAfB4MB6vV6SIJeKBRCeK4lBRX2c+uIW8c9prjRMDF1OJVE0HmzRJTail63NsBytB4dj1g4n6p0YuQi64uRYrNIaksua/uUYNHyLclMxEIUtX5VT9E2+QyVPTpf/X4fR44cwdLSUiDgGGrKNgyHQ6yurmI8Hof26cmTdswtccY6NXchTzi14ZWFQiFFxCnhQ0UdCb2lpaUQnq3KIiWTgDQJo3ZlwyX14AAlN5Tks7agZcVCW5V8smQlwXmineoYxohm3TMymU11qe6/1n7snmkJHEvgWfWX7vW657Fds3IPWtj1NuuwB32eLzSYD3A0GqWUkJxbhn2yHJ0Tnqqrc8BDe5SA1xcFansAUuSzkvmsD0BQH/P7pVgsolgspkhLJVu5H+uaZC5HJZL58ogq5slkEhSkJACBzbQIzWYTw+EwOgcOh8Ph2BlwIs7hcDh2OJT0ALaGf1pywSooYrAOm+bv0UMEbKihJdlmqYRiYVZ0tlSlpo4UP485pUqsWEdY+09yzqp89BmeNmnDUflTFRBUtAFIkRtWmWGdeEtuMr/QaDTCsWPH0O12A2nYbDZRLpfR7/cBINV+HTuWS/KP91gCwD6jc0XHW09/VbKM86KEiiVAYkq8mH3wc+swW5Wezq+SEjECWcmLWWSHtjtG2qh9xtbIrGdtn1ie2lo+nw9EFwmG8Xgc7iMpwH9HjhxBp9NBp9NJ5X/r9XqBEGMOQWtXtu36N22iWCyGkyIrlUoIL9V5VPtR29f5YKJ6YCN89ujRo1haWgr5uPRZe3iKhqWStLIku92HYvuM7kWWFKYtxeaKc8G8ezpOSkRZu7F7jT5HAskSW7PIN4XajCW5Y7/rmtF2WVLRrr3Y+tF5JQml+7Der+1gKHKn00Gv18PCwkIIN2V5SZKEUE373WLbofnZNDechq3qNe7r+gKF82fH3+41/FzzKNr9WsvU35WUBTYPm7AvFJRQzGQyQb3qcDgcjp0LJ+IcDodjh0OdPut8qzMxixSzpEKMnFCySkkuhXXWYvXFnC91JG1iboL3xBwk/UzroHOlznyxWNzSThIgJLDW1tYCEafEjlUAsXyepqgONJ26WQddqMNHMoQOHMk9kgSdTicokTh22hY7xxoaNYsoiJFJLI9kpyqjlJBRwi5GTOicqDM6yy7UfpRYiM2zJf5iZOAswiNGntmy1SYIVQTaZ2eRKbxfCVwSrjafGG2ENsjxBoB2u51S4DAEsNPppJLgc/zYru2IOCVgSPbasE2Srrp2aO82DNSSf/1+H8eOHcNgMEA2m0W1Wg2nuGoYKG1TVY6cd13Hut7sSweOqSXi1PbY3hipxv4wJxjJEdbPttnxZbtYtoaG67hTRcjfVc05i0iO/T2L2Fby0trvLCLaXoutCZ0TW2/su4SEcLfbDaSxzg9TAej8xr4fVJXLMVaVm+4Ndvxi/VeVHOdHv7tUhavfTXxWFYd8AcU5ZXkAwj7JvVdf+Fib4YuebrcLh8PhcOxcOBHncDgcOxwkc+gEqEO7HQln1RYx9YU6OyT8qDxQ5UXMKaJzE/unjo8NC2JoqhJcs5QftiwFnVS2nXm46FCtra1hOBxibW0tpQTSnEYxEottJphbTutlOaqm4D/2j+3SEDclGegEcyyUGFFyyCrUtD5NSK9qNp0zS0ap80qnk44nx5zKFrZRbUTDTG3fbcJ+rV8JsJijfk92OotUi8GSkgolzkiqqlqG9+jv29mgElW8puNAZ359fR2lUimVw5BjPplMwoEdJIl1rrXtStDqdf2deeE0byLLU5shGaxKz1lrgnY1HA4xHA4DmdtsNjEej9Hv91OnqHJtj0ajVNh1bD6UfGG/lBC0xLCSfbRfS/KRdOeexjZZFZklAtVudZ1oW4B0+ChVh0qmz7Kb2F4XI8z4PG0pRsjFyD4l7C15buvgfOi42bJY/mQywWAwQLfbxWAwSBGjDLvmQR4WNmSfOTd1nvX7grncSHbroRAMzVUCNpPJhOtKuGn9nCsl4fi8zjfDS1kHx0ZVoRqWy76wrbQ7S+w7HA6HY2fBiTiHw+H4JoASU3Q4rTpDHS11epTosoSZLZ9v/umQ2JPntC59Th2pe1J9MESTOXSoLtA2KwmohAQdIFXaAAiqDDpCPIl0NBphfX0dzWYz1EHVER0+KpTYFz0Bkk4mnWx1vlVRYx1r7bslytRB1pMllSizZbL/doxVMaSqDEuKWkWREnKqGNRwOxKDSkbY+Y/Zp9oaoXWr+kXbZsk2SwDHSLxZZJ7aW4y4YxtoL5rjy6qyeM3C1qGOtyp7eF3Drq2tttttrK6uot/vb8n3xTnhfCh5YAlAYHMtUAmXz+dRqVRQqVSwa9cutFotlMvlLTncqAaiTXMc1tbWQjnMu8j1NZlMUK/XUSqVUC6XwymuutaV9FBbV0Wh7lNK/qqKUokaXWuq4tU5Zh1ra2upsbREiVX/WtUn61QikWSOVUXqgRYcS0LtOdY//Z394Fzoy4tZIcC69uw6YNtUFWztNwbbXiofmSuOZJTuzVSB6h5EksweeFMsFlM2wjyESvbzvlqtFvrG7wy+UFHb0Dm0BB3tRMP/bbi22giJao5zqVRKvXDgd5nulVw7MeLe4XA4HDsHTsQ5HA7HDoe+cQfiyb2BrU6TJeNijoE6S3TWGLLI53hSozqLqiCxTscs9RCf4WEFNom7VctY8sj2TfP0MAQP2Mhhpc4ina18Ph/yHFnShM5epVIJ+aSo8FG1kI6lHnoAbBI4eiosrysJo8+r0wkgRUKoU20JOC071j4lBNRBtEo1KqB4oiBVJ9peHf/YNUuqaIiZtYftiDJbrrY/RvjqOrBjpnat92gddMZpk3zOqqJipKMll5XMs8SbbZuSDLw2i4Qjgaukjm0PSWES5qVSCfV6HfV6PaWIIzlH9SNVapacnE6nYd1YopqKuF6vF/aFpaWloEQtlUpBLUd1nO4tSq5bgteGK+o46pxagjo2FnyO9XEdM4efEi3aNzu+rIfrwq4xVcmpIo916Qm3MXLMrnHdX7VcJeFUyZvL5bYccmFJKY4LVZIsQw9XmLVf63hwnfT7fXQ6nXDgDD/L5XIol8vhHrsuR6MRAIQ8iVTPsR9JkqRessRsQgnd8Xgc7JOfc6/lmuHzundoeDifZfvZVh7MoHnpSOpy7ej3Hz8vlUopYtXhcDgcOxdOxDkcDscOBx0AG0KzHXkRu6ZOmhIOVsmUz+dRKpXCv16vh36/nwq70nr1eSXOrKNpCRcAKVWJkkezyBXWzzronJVKpaBc6PV6Idk9FQ5URXQ6HSwvL2M6nQalEcsslUpYXFxErVbDeDzGysoKut1ucIR17IHNwxvYd1WUqVIjRlZuR0LNmlerqOE9lqBVsF5brjqLVJvQiSYRo+FW2gYLjgmJD9s/29cYKRdT8ViSWG1EVVeW+I09b9ubzWYDKUU7JYGkTvm9WWc6BkqS2rBermMts91uA0A4qCE2Xkq6qkrInrypz9IWqVIiCcN1oGWojZB40DA8XcfD4RDtdhuDwQDAhsKJJ7oqmcX2cF2p/Wi/VL1JzCJCLQGt/VS1l9qMkmwk7JVAtyGEMZJayTz9XMfFqvTUZm1Ypq2Lv9u1rWXbHHt2754FHV8SsTz8g/VsZ9O2ndwbeGjDrl27kM/nU7nVisViUImxD9yL7Tq2ZKyS4vqPoan60kP3/CRJwtzyJ+2f9+hJ3Rpyqgpkzqk9lKFSqYQ2aAoBjp8NjXY4HA7Hzoe/bnE4HI4HGG95y1uQyWTwqle9KlwbDoe48MILsXv3btTrdZxzzjk4dOhQ6rk77rgDZ599NqrVKvbt24fXvOY10TDPe4KGJ+mJozFHSYm2WYSG/R1AcJaYUy2fz6PRaGBxcRH1ej0QFvqsJaKss6h5jfRv1tPr9dDtdtHv9zEcDreE2lLFYdVdQDrnUKFQCM4+lRdULOTzedTr9eDAdbvdQMSx7exPPp9HrVZDo9FAq9XCwsJCUNlZ9UOMLKFTRgfQtttet8/ZeVOn1ZKl6qAz3EtzzdlQNiUIbJvK5TKq1SpqtRpqtRoqlUrqQAFCyQRLUGl7YmrNGAlobdASIuw7c4ApaWZJ31lkmbVTta1yuRzmutFohBA1Oxdq97Ng+zaL3OF8jMfjcDqqKuE0XFZVNTpm2j4AW+ZY7YZKUSrkqEbSJPS6hklMaZ4s2hZDaElOs73Mb8d+aPi4qvEABBVUTJFq7WK7cdY1S6LRrmcl4dnPfD6ParWKZrOJarWaClFUG1HCj/OhSj2713EslOSLzdWsPtkXGrH6dF0pSWr3YSUE1RY0FyDbpORmjPy0tk174N7NU2iVIKRKza4lqx6kfepBOjHFbmyPZX/K5TJqtRoWFxexd+9e7N27FwcOHMAJJ5yAE088EY985CNx0kkn4cQTT8T+/fuxe/dutFot1Gq11CEbqozVfVRzZfLUXT25VV9AsDyrhHU4HA7HzoQr4hwOh+MBxGc+8xm85z3vwbd/+7enrl9yySX46Ec/ig9/+MNYWFjARRddhBe/+MX49Kc/DWDjP+Nnn302Dhw4gH/4h3/A3XffjZe97GUoFAp485vfPHc77H/srWNuyQO9T69bR1UJFBJhdG4Z2qZkwKy2sQzWRSclptKyRA4JISayV9WCzbmk+daogmBYJYkOEpUsR/PD9Xo9rKysbHG0lfCiIoLJ7qlGpGPJclUFQ+WL5t2ySg910G04GcFnLOmipBP/tg6ztQ3eF1POcHyplCqVSkHVMUudY/9mn9ShtwRUzInmdVuHVflYIoHjFktaHxsHfY6EEZVgJGmq1Sqq1WoqRFjVj9reGGHBv7UN9j77vNqN9p9tVpvSsDfaZTabDeOgbbFzWqlUUC6XUSqVUK1WQ9i1tlmVPzqmeogK84mNx2O02+0QdjidTgNZR3tm/cCmyo/rmwSkfYkQGwdLpsYIGbVjPYDCEqhWkcpQbF2Hul/NIpC1vbr+tB5tE3/X9bydgk3v1fURI/7YDlUC2jVhCcYk2QipVDLJ7gnWhm372B4qI3u9Hsrlcmpf5IsRHVvOP/ul+6l+x5A0tWuVZeshJABQr9dRrVZTxC/nWw+hmUwmQRlHtW+/30+p2/S7Q9dEJpMJh1MoaaxEHMlr3UdmfV86HA6HY2fAiTiHw+F4gNDtdvFTP/VT+N3f/V382q/9Wri+urqK3/u938P73/9+vOAFLwAAXHPNNXjCE56Af/zHf8Tpp5+Oj3/847j11ltxww03YP/+/XjqU5+KN73pTXjta1+Lyy67LDir9wYxos06pABSDqGSIta5VYKCzpGq1ugcUQ1A5YMtT0kCGxqnJNwsEkNzNGmCeXUG1ZFX5QcdPz5DcoKqHCUUeOIsQ6o6nU5wYqmIYQgTw8801IjlUSVGZw2I53Tj+LHMmHOt82Md8xgJZoksJQ4s8WCJH84vf1ciyobeDYfDQJbYEDJtr1UsxcgU2ogNR2QbNIwxpuzRsliGJkln+Uoqa/lqWyyDNse/SRxNp1MMBoOQx4rzoyola/+2z3beLEGp91sFG9ujZDb7q/2zxLuG6nI8SEDwAAXaIcc8m80GIsoSKCw3digAT0ZVAsPm4gI2SDmqPzkf6+vrKQJMbTtGNmq7dAxj+4muY7tm9G9gQ801Ho9Tp9fyHobeW1WWjq22x+Yi03lRoilG3MZIW7UFjj37PSvfoNqEQuvQQwWAjRya2j7dwxS2bdr38Xgc9tLFxUUUCoUUGVupVFJErFV8qu1ZAhdAIM1I9vI5VTiSSNd9TMdhMpmEQ0Wo9OZBI1Sjcl7V/lRdzZ+ZTCYQgDr2Go4/Go1SBLar4hwOh2Nnw4k4h8PheIBw4YUX4uyzz8aZZ56ZIuJuuukmrK2t4cwzzwzXvu3bvg2PetSjcOONN+L000/HjTfeiKc85SnYv39/uOess87CBRdcgFtuuQVPe9rTttRHJ4Fg/ihVdWgeMiXQtiNvYteUjLDhVnSSSGpRQaCkDMu06pbYdW0Xoe0fj8cYDAap8FQlZujQswxVhpTLZRSLxeDUDQaDcG+hUECtVgtk0MGDB3Hw4MEQtqoqElVIkMjgoQ+j0Sg4W0pyqmLJjot1NGNhSzGC1c6hVazoOCrJpdetA63PxtSJ7Od0upFfjznAYrmtlPBTW7IkAdsX65vto4bZadnApuOuYxdTA9rylShVUkgJnvX19VSuLNqaJcR0DC3JFyPf7DjM6reSUCQM2T8l2KbTafiM48QTjVU9R3tvNptYWFgIIbd6+jHHgmXzUAYl0jQEWMdc69LDXLRNNoxTFUZKlMXs2pLKlsxkuXqNdXNerbJP66MaKtZuEouW6LRrzs67Xc9sN4BgT9zLZq3TmC0rsTwrvJx2Yu1Qx0bXAYkxPeVzVv12fPU7B9g8PbXdbmN9fT3swQTtjPU0Go3U6c7cc0mSk6xVZTLrpDpZCTkll3Vs2F8ScAyr7vV6qRcouu7s9x5thHXZA3to13YM1aZ033I4HA7HzoQTcQ6Hw/EA4AMf+AA++9nP4jOf+cyWzw4ePIhisYhWq5W6vn//fhw8eDDcoyQcP+dnMVxxxRW4/PLLt1xXR4m5rUqlEjKZTFB40EFgGKU6J0A6pEqhzjzrYg4gquBsyCkdnlnhN1qPJUisE842U6VAZ8z2WR1xS2TYz4ENZ4i5sRg2euTIESwtLYU2WDVRkmyErtLRYwiWdWpj/bOkgTrqJDGz2WzI52YVavydZJQNfVMHXwkctQ+r2CK0r0p00DGmukVzlqlNxYg2S1RoO3RuaS/qcMegJAuh5KeWaevYjrBU++Y4cAzooFMlR2JDQxxt+3QMbV06X0pasA8xhQzr0ue2Iy2VoFVb477AUFuG6+mYayJ7HROqi2zZ7B/3E74oUHWTkkJra2spkk/DtGeRtto/O552bGNklL6g0Htj+46qOrvdbup+u6+w7Fn5HHXPsXXE7lVSfjsCzhLc2m4dI31W92UdSwUJOP2OsPs522v3G00RoMTeYDDA6uoqut3ulpySmcyGgmw8Hqf6ShtS4sySq2wDFZ2qaOV4DAaDoIJmfevr60HRrN+L3HfVVkm0AZth1bR1Eov8nT81DFhVvGzHrNNrHQ6Hw7Ez4UScw+FwHGd87Wtfwy/8wi/gr/7qr0Lo0oOB17/+9bj00kvD3+12GyeddFLKgaQDQIeazow6JJYkiDmldGrVKVZHRdUDhA1hUodSf+rvtm7rMKrCQHOx8ZpVZ9h+WSKA15mkXgnLpaUldLvdLYSMKjSoGlHCIkY2cQwtacj6SR7RQWP4rJ7yF3PK6dzF1HXabyURrSrHzgHHR9vHflPZwlBkhnCxjTbvFMu1tmHH0s65VXgpWUKi1BKJmrPPOtExAiymClK7UHKBbRkMBoEs0NMaY/OtbbsnJ9vOF9tnx0avKyGnf3ONW6JF82pVq1XU63U0m82QG44qJZIuNln/rByMSZKkyAlgUwFFlVGSJIEgURKC4Xvcj3TerUKIY2TJGCXTlXzRMdA1QSIxpsDUvVPnUMMmOUaW3OK8WGJVlZtKatq5ZZmxsNl7S9RYUk7Hjv1Twtq+VGG79eWMqqiVjLM2zj3Sfq420el0sLKygnq9jlKpFPZtpgQgQUcVHg8psYSr7h2cLx7swTygVDfzoB8SbIR+f+g425cWtAlVoBKaZ47jpUSb5uOzhKXO8ayXVA6Hw+HYOXAizuFwOI4zbrrpJhw+fBjf+Z3fGa5NJhN86lOfwlVXXYW//Mu/xHg8xsrKSkoVd+jQIRw4cAAAcODAAfzzP/9zqlyeqsp7LJg030Kdp1wuh/F4HJxqOjY27EaTY8ccP+voW6cw5nipk2SdjBihZ++zTh0/ozNkyRhV4mnf6HzTSQIQwgzZH57GR+d0ZWUFKysrGA6H4Xm20+ZBU1JzVo6wWc6xJXGUtOChAOr82/nQfFNKWqmzp+GFsYMFAKScSHUQtb7JZILhcBjGZJbK0ZKBMeWNfhabc83DpNAQSJ0DJel0rmKkGOvRa5ZU1j6oM237a8fcjkWs77avdhwsIaegAlTHxpJNStJawiSXywUSjkRcrVbbErKt5LOdFyUZlJijTZJAGQ6HmEwmqTBLtRnauyWDWIaebMq5Zf0aZvn/t3fuQXaX9f1/n72c216zCbkJREALRS4VWtOdVmpLJoFhKq1MSymjaFErjVaLpRk6VSwzLQzMyEw7EXVGxRk72jrjZUqtTrgEaomIgRRRuwMYCa0JIGRv57Jnd8/z+yO/97Pv72ef7wZKsnGPn9fMTnbP+X6f73P5PM/J530+n+dJzYtU5KOuBXr6qbVR/bERYPoMW74VR1W44t/6pUFKJKbgp+J6ym60TbYeS2HnrIpQWn8bzamipa2Hfmbolz22L9rtI6nshw8fxtq1a+P+nkwH1whMrkfd3d3o6+uLn09AVqylfVPMZVQbv1Tp7u5Gs9mMWzhoZLF+iaOfFyqm2c8a7Yt2ux0PreFzNZLY2hCwcKKwRlGryOk4juN0Li7EOY7jHGMuvvhifP/738+89q53vQtnnXUWduzYgVNOOQW9vb249957ccUVVwAAxsbGcODAAYyOjgIARkdH8Xd/93d4/vnnsXbtWgDArl27MDg4iLPPPvsV1Ued93a7HZ0EAJlURxVxrBNP1Am14o0VD2yECOtindW8b/5TETwpkYHX2OgVjShJRWvQaQohRKeNThb3FGIfHTx4EBMTE9EpVkdU60+RQR1WexKerYs65ozis46gdWKtE8qxVYeOzqiKrNZBVpFQ66WOOK9PRYbYfrcOpHXata3sa+ugsk55zqjalBUOUrbDftHybESP9k3qefZ6HUttu62L1jUltGo77cEctg52PlmBl6+rHQCIEXuamklxslQqReGN6diDg4MoFouZU5CtSKV9ounQ3A+LpxBrhCTLp8DEemlqq+1LTU9V+0uNG+tgxz61BlkbUoFPn2+vt3ORtqTlW7uxz7JzUa+3aJ9Y21F0zuSlMdt26xrJ12wf6Tpk09NTbdTXNNpObV2vm5mZiXtK9vf3Z+plD6xhPXiiL9duTZVVUZO23dXVFSPiCoUjJ5j29PRk9jdk/bkm6Xjyi4tKpYKZmRk0Go1FdsN7rFjHdjAyns+rVqtRiOQc0z5lux3HcZzOxVd5x3GcY8zAwADOOeeczGt9fX1YvXp1fP3aa6/F9ddfj5GREQwODuIDH/gARkdH8eu//usAgK1bt+Lss8/G29/+dtx22204dOgQ/uZv/gbbt29PRr0dDRVA9IRTG0VGBzPPwcoTGIiKEfa9PEdSBZXUs7RcdTDVsVPnz5bDqC+mOdH5ZIRNu72wzxywcGoj01Ln5+fx0ksvoV6vA1gQvzT1VeugzqR19NgWK2LoxuHAQnQHHVCOFUULFfe0f3hQBPeWS4mqumcRBRv2kzrzOnZ5QpuOtRVSUtF01m5UPMkTV1WwtDZmo89s/dhWOuxEHXsVMfiaig42koyCk2LtQMu0dqv9ps/gxvxaZ702JcLRWdcIRpaX2r8RQDyVslqtRlGDQsWqVaswMDAQRWHuccU0QV07KPTqPldWCNfN7nmAB9vASKeUSGlFUxslpCKYFeXYB7pPofZD6oAaCh867qmx4v2KCr0a1ZYSrvmFh9q/XXd1nNm3eeKawjrb+W6/BLCiWEogs+uKvkd0zU6J5nZO2jFlmxkVx7Rozi+e2MuoONoXD45Q4ZpfPOiY6OnNjUYD3d3dcc9PitHt9sLed4VCIUYgaySfpuXq4SEqAOpY6fzQKDe1OT5TT9JmGq1e7ziO43QuLsQ5juOcAO644w50dXXhiiuuwMzMDLZt24ZPfOIT8f3u7m7cfffduO666zA6Ooq+vj5cc801uPnmm1/xs1IOmnX2UxEOeVEM+q+NEMsTTxRbBslLgeS/VuRLXauOsEZ9aYQQHa1KpRLFAEbo0OnTKIy5uTlMT09jdnY2I2gCi9NS6aSrs02HSjfq5jV0Rq0TxzFh+dx/js8vlUpxA3w9fY/pgbpfme0X3sdID0YwaVsowqhtKGpTmg5nx9SOrXUwbX+m7M868zZ9zEZB2Xpq5J72u9pNSsRj/6uzbFNPdYysMGrbbMUffb4Klyp2abtSddRDLHifihMqGhUKBRSLxXgYAyOQODcGBgbQ398fBTdtuz6T48W5o/OFNsN0d86tw4cPY2pqKorDnJsUSDkn7enA2jdWuFSx0+6LaO2DWLFQyywWi4tSHrVfbUSrlmHXOR0rK6SyzJR4ZctUMZvvLYWd63lCnLVzKxyy37TeNvLSCqe27XqPjqEdj1qthomJCTQaDVSrVXR1dUX74frECGUKYnpKNSMuVQBj2ZwP7faRAxqAI7ZZKpVifbi/JaPoVCTkWHFfOo6HCvEUV2m7tCXOD/1MYNn8QoXrsa5Tuk+d4ziO07m4EOc4jrMM7N69O/N3uVzGzp07sXPnztx7Nm3ahG984xuv+tnqQKQEizxRi++lnEUl5ZiqM7aUQGOdwlTdU89KiRr22XbvHkYxMNpCxQBeNz8/j8HBQZTL5Xj95ORkFBHUMbaROFb8Y5katWMdUTsmdDy1DeooFwqFTOQU68xnMMWWkUhWaAUWn3RLMUejqfTaPBHUjtFSooKijq5N78pLqbMRUSlxztqxFd/0Pfu7ra+Wqf+qOGHH0T5PN6vXlLXUvNB7NQpH22jT16zwp0KvnQsUuQYHBzEwMBAFWwrSq1atwsjICKrVakaI4g+j26w4x2hOCggcVz1Rl3tyaRqk9r+dTypcaj+qzbIfrHikYrYKbvrMlB1RTNTrdT7rHoQ6dvoMnavWntTm7f1WyFMhfqnUTosVFlkW14JUdCSvtcK6folgBTlbBysU5gmQdp1g+2dmZqIQByBjc7R5PbWUtsZr9KAetRmb8jw5OYlmsxn7hSIcx5jvsU3WJrRPtL0aEcm5rrZtI5h5EFBPT09cq1VM5vruOI7jdDYuxDmO43Q4dCpUeLLOV55AkXJal7on5XipQ2Ydy6XEEPt8+551TFWc0GdrpI0+V51gRqQVCoW4ZxYANJtNvPDCC6jVagDSG4NrX1Gk0NdVnGPd1LFmhAcjKTQFkOPH+vPZrDfTlOloU/BQZ5BlaB/Z/rLjTgfSijqKikT6Y7GOvP5uxQuN5rFjzr5LXWMFRBsFx2vs8/V1K4zxJzXWNtrMCmqsn02fU2FTn8kxo+hj54DOYRVeGamjEZXaRxQT+vr6UCqVMDAwgGq1GjeIHxwcxOrVqzE0NIRKpQIAUXDWiDAV0VTgpiBsr6GAUa/XYx0ZbUZbZaqwns6aEjH4DNqJClXWbuwYsJ3sZ9Y9FVFn00T1GZz3Oiap+ZAn+KbWOX3Pijv2Gmvzth6pNZN9TLFH1xuWYcuzZetY8zX7r537dq4vBcezVquhVquh1WrFNZCppSGEuG0A7ZL36rqtQi5f59rLLyg0+ky/8OCYW1GNdmvbo4fd6DxX4VIFcB1D9qfu36lrPfdXdBzHcTobF+Icx3E6HJtqaTejTold9nUVjlJiixUwlhLqrPOXcjzzsKJgXl3UoeZeQyGE+Dv7gdfwh++z/jMzM/jZz34W9+9Rp4qOl/ap1kGjIVRIslF0vF/fZ1qfFXN0nzM6mSre8eTXPLGK/6Yc6JQApBFBeQJryhG35avolxK77N+petvrraCozrMVtKytsUy7Sb8VJ5lqacU07Y+8VEA+h+On6ZMqIFlb1HboeGn9FdoT66qRc8ViEQMDAxgaGoqiAIXd/v5+rFu3DoODg1Eko2jDEyYBRBFHX9O+4FzgAQ82LVrHgdFLKpKl+lHbT9GCdVc74nU6X1TwTEXOalRraq3T9ilqy/qarh9WWFOBSMW/lDidqgfbb8XH1Nppf9foWBX289bmVD3y1g97nRXUUxGJec8BEKPiarVaJipYozNZLv9mWr6uxSq8sg48TVxFcF1PWRc9HIHPnpubi2n8fC6FYSuudXV1xQMgdM0GEFNf+TsFPE1r18+VlP05juM4nYULcY7jOB2OFUSs4GEdv5QwZp0oGxlhn5cq52iCgr1f70mJM1qe/VsddTpRVujS/aLosFWr1Uw6Eh1EFcCABYdM+4fPUzFGI4tsSqb+0NmmI6eRfUzDsn1OR5MpWGxHqu+0z1NCnApJVoxL9bMdKx1XK0LYZ6uDqvsn5QlwxL5v+94697ZOtj9UILH1VhvieOu4KFq21otjmmqTttcKi0ul2dr2qkBB2+IeU5VKJaaiqq329PRgYGAgbo5PQYLPrVar0e56enpQLpejYKFttynUnBPFYjGmpFKUoyikc45tV/FC99Vi1JK17ZQgq3txWdFpKfvR1xlxqIJZno2x7JQQp/ZgxWmN2LL9aetnRUwlb82mfVLwVGFUr8ubR/qergtqk7YeKsKlRD6NAk71Pfe0nJqawtTUFIaHh2NZGkGpayn3aKMIq2u9rWuj0Yjt4N5wuv8l+5k2zvv1sAUVyPlDgY7rQr1ez3wOaD+y3qwHT+TmmOkXHioiOo7jOJ2LC3GO4zgdjjpYKr6lnNS86IWl3k8JNeqAaTQIcPRNv/PEmJQQp3VXh5AOKKN09Bpex9QnOkr9/f3xVL0QAhqNBl566SWMj4/H9LqUg23rz9fa7Xa8j2i6k0buqBNOR05TiW20EB16FXysAGEjf/LSPm10TmqcNe3Tirg2JdQKelqGRg3xJxVtlxpz+5rtd21P6v2UvfMn1Qe8js6xFRysqKdl6bgx7Vj739bHRgum2qVzkNfbKDteMzw8jJGRkYzDTwFgYGAAa9asQbFYzER1ajor72N99MRhRvPYKEGK1V1dR06prNfrqNfraDQacZ84zkWKXhQBAURBmWIKUwltxJ9GuWlUnvZhahx17HUcWGcraKdEMfaVntCp42fFOUbQ6vxk+znPdQ6yLlr3vN/t2mPXArt3WkrQS5VvhcTUPXa9t2txKtI0r2yu1UxP5anVPERB97dTkYx9ruIby7PiOAViYMGOtC0cIwprtANGYurc5vhrW3WdZXQm32eZtBkeksPx6unpyXwxpPc7juM4nYsLcY7jOB2OFUTUWcyL8rD38vcUKYEvJSio059XpnXsUk5nSgCyTrw6g3TK9GTHVquFEBbS7RhBVCwWo3gyPT2NiYmJmO6ZErC0jlaYUaGJ9zC9lVEg6qCr2GOdOytWaftVIEmNt40Q0bboeNn77HU6XlZwsOJdnginTq+OfUrA0+dYG9F/U222/aPtTKUFpsZTf9f31K5s+VbYsynL1k7y6mpJ9S3rxXr09vaiUqmgUqlg9erV8eCFrq4jewn29PSgWCyiv78/ng6pKZ8q9LEumhJp90njvl02XY+2SCGo2WxmxEzag+0n2i+fY+cC2612TqEmNW4qpqWEOO1zTSPnNXqvinx2vus8Z5/pmsODX2ZmZuKeeSl0DdU9PfW0Xq2/FW7tGquinF1n89b81Lqcsse8sng9IxlVHAQWn1jM+3kK6uTkJKanpzE0NITe3t4oTukJoxSC89Zj1kFPJlUbYz+pIEeR2n45onXmmGp6t7UNXq+Cqz10BUAUG3WNUHGWe+Q5juM4nYsLcY7jOB2OOusp0YjQQVGhQfd7UqyIkooW0nLVaV0q5eZoDqCWr89UgctG4LGOmrrGPXtqtRqKxSJKpVJMQ2o0GpiZmcH09DSmp6djxI5tmxXnbP11ryI6Y3wWoz1mZmYwOzub2UNI0/yOJvbwervfnTqHNjqF/WEFPbvvUUrEsP2uf6s4pP2hgp0tLyVcpqKDtA+0Hra+KmYAC6JOasz0taXsW21WBVKtp7UNFY5sJJwV/axgmhI1U3W35TDldNWqVejr64v17evrQ19fXyZ1VPtb+5NRQ1q+Fc/1XptirWIHgJiiqpGnvFdFJxVLbJsY/WS/ONDrdb7b8VH7TK0vrAeflbdGav3zIuasMDM/P58RSLu6ulCr1TICWZ6QxXWCa4SNbEsJ1ryX63bKRlPzL7WWvVyseEchiZFeXNtSc4//cn/L8fFxjI+Px30LdU7wGSwnT+wOIcSoM9pOoVDIHFjBzwMVoFWEVeFQ06l1/8Wenp7YttSXKdrfnHP8TOX48LPICoe9vb3xFFnHcRynM3EhznEcp8PJc1ZSMC2NDkhK6ACyzrj93Tq4eSJLnuP3csQ4FUQ0mkUjbXSfKTo/KswwEoOpR4yUGx8fj3v+UIhTIUAjddQBpxOmf6ugwd/Zx3qyH/ccUkdeHXrd3FvT4qxgxfc1xUnf1/vYR1qPlCBlHXk9BVZRMcRG4ahoZMd3KTtgv9vxP9r9efat91ix1gorVpygLVmbttEzqX5JzRt9prVpnStqPykxmCJYqVSKdjU/Px+j34aGhuJhDNomRuSwfAoffF03suez9Pm6P5aOE+vdarVQq9XiXnE6B1RU4jNZL9oubZIRqjq3dczU5nVsNQ22UMgK4lYI0jVExUIdw7xTZFmOzlf+3mw2MTs7i0qlgt7eXpRKpXiSaaoca0uMutL3rThv79O/rdBq13Feq+TNA/t6HhR0GTm21AnOKuLNzs5iamoKhw8fxvr16zN79qmIxvVa9+3ULz10zWTkM+vDLQHa7SN7gnLdZ2QlBTwgu98egDi3dD6qwKx9o6eodnV1ob+/P87BZrOJRqOR2ZOOdsV+1j0PHcdxnM7EhTjHcZwOR8URG22T+lcdY42IycMKFuq0aTRKXnqX/psXsaLPWSodks9QwYrOuNaXp4yS+fl5TE9PY2pqCo1GA729vdFhtgICy7N7uNm0K62rptvxUAY9QVJFBwCLNlinEKeih46THgqg0Wc2ukf7EFiIFGR/qlNoxR8bnWIjvbQM7es84SmVpqYCZ8rZt7Zq7SwlkKXsRfvI2ljqGSnBz9qs9tdS12m9UqiYx7G3UUV2jlWrVaxatQrVajWWX6lUMDw8jGq1mhGItK60YW5MT3un/TGqSA9RYDtok9rHLJ8RpdzzS0U3CuNsnxVoKWLQPjSFm3NAx5T/2lS+vLqlBCW9jv2j656efqzvW4HV2lCr1UK9Xo9l67xPnezKuTc7O5v5coHRunn2ZEXb1J6R2mYVw1LRXNqOlMhs13BdAyg4UujiYRxLCe7s22aziYmJCUxMTKBYLGaixNQmNIqMY6t21mq10Gq1MhGgerIu10ym0OqXNXZsKaxp9Fq5XEapVEK5XM7sZaj78/X29qJcLqNcLqNarWJkZASlUgnT09N44YUX0Gw2o1BIm6JtqL06juM4nYkLcY7jOL8AqANlUwf1/bm5OczMzETHgg46sPjUwpSoRyfHihJWjEk5ffqede6sgKJOHR1POlIaKadimRVf6FRRGJuZmUGtVosRFBQBbESIOunqoFunWp1AFUHr9XrsaxtJZJ1yPldFRUb2McKD/cGojjxBjONi+9mmu/F9/q6RWnlOOtuTsjnrsKsdqsNrr1XbsvdZQUqddFu3lNij42WfzbIpjFqBKCUoaHk6N2zbdO5YcUL7XgUIOuu0V61nX18fisUiqtUqyuVyFKH7+vowMDCQSVOkTbdaLczOzsZ943Rs+Lf2h/adbmKfmpM8ldJGDvI+pmFr/2paNa/VemnkJtMddUwY5cQ5ojau46FirQrfug+eRt3pnNFoSM53TVlcSjRutVqYnp7OiKoUPFMiNe+lSG+jsFJzSO1UD2rQjf9TolyeyJwSJFPrkl3L2a/FYhHlcjm2325xoGXqvNWouOHh4ZjOy/pzfeO6OjMzk/niRdd7XfNDCNHeKfjx+XoyL9NBaUsamUb75nsUflXwZH8xGtAK4BxPzk1NPabtq+juOI7jdC4uxDmO43Q4qQilFDaqgs6OjSgBFgsmKj7liVMpB1B/V4c5JSZpCqU6WxoFopE36uDZaK4QQkxxooPHdCFGNtCR1TLYTxpBwjarqKB9qn2r71PsVEeT7dK0WnUKtWw6dXR4u7u7cfjw4UzUh3X0VaRUoSUlGrFdGh1p06WsOKljqNekBAfrhKt95tkKr7FCrh1bWz/7uhXsUs/QsWFZHAsVYWyZ9ln2Gtt/eg/7lylyesCIphHzWX19fahWq9FmKbhVKpUYkaRzQvucz1ZhiXOLY14oLEQSAcjYO99Tu+eaoWl8bJd9vo6z1tEKYCw31cc2+kv7U/vU2pnaTypyzM4HjRIkOjcppOh9eogFD6ywz7LP0bWv3W7HyDlgYf6rmJWK3pqfn49iq62ztl+FVDt3VDiyAmXKjnUseT3TaovFYqYuqXHiM+fn51Gv1zExMYGZmZl40IWuWxq1q+uc7UMbhamiGkUv9p9GJqf6xj6X7dUoSbZZ5w7FxVarhRdeeGGRGMu/dWzt2uY4juN0Ji7EOY7jdDjW2U29p465OrcaBZQn4qkDZveY0318bBkqgKjTQcfJOiMqhKQccuuM8XmpCB2KGuwXTVvSk/ZsBJlNJ7QiDR0rOoKtVivzno16U8GB9baCld6XEhmZ+lSpVDA+Pp5xpq3QlBLgUpEufIYKKnQc84SrlJiSciatCGZFOB3v1P22jlagsDZj+5JYIc1emxInbF31mSkRJ69MHQP+rfepIAcc2Z/KCg8Uapm2yHQ4pgXqvmv2EAWd51ZwTI2VisUaQWRTOFVwVrFST6tkfSmGaHu1Hip+WWHf/svn6Pqggo+OnbUPzlWd33Zu2C8p+CztY5s+zLWT4psK2RrxpzamtmTniLVXO0babptWb8dX+0PT9m1/0TY0Itbavv18sHtm6gE6Gl1my6IoykMbpqam0NfXlymH6zjXIj2Z1Zapc42CGNuroqi2Q4Vv7W/eQ2FUv6Tge6l20fbr9XqM2ObcYBla19nZ2cz+oY7jOE7n4kKc4zhOh2MdOitupIQHKw7RKUg5s7YsRgUAC2k7er86takoAP5r0430fo3MspEY6ghphIlen3LUAWRSPlUktE6lCpfW6dQ+t06b9p8+346Lttke/qCvMzWL0U9WLNS+znPG2depfmeqIR3Xl7OJeJ6gkyfc5V2bErf0eo1yTAkVeeJYqo68zvaRiiAUhth3ep/W1wojefa3VNvprFOE4p6Fqev4eldXVzycoVwuZ+wUWIjApCihwraNmk0J22yLinAUnAjn+8zMTIwC08NDKJ7oc9Vude3QevNQFd1Hkdfweop1PI1YIwj1eo0wVRtRcZfzU+eNiqQqqNsIYF13QgiZqFq1JztfU8Kz2pGuM1ovK4Ix/VcPyLAHy+Q9Q+1T+0Rfy6ubirB5P1YQtdHSHL+pqSm8+OKLGBoaWlQvK2aqiMt5wrHntgp6aAOFs2azGfue17JPmQKtEYU6Hyneajp+aq2lcN1oNOJ7HBdGDKq9LJX+7jiO43QWLsQ5juN0OOokWWcvT1hT8WEpJ4z3qhBiI0tSokVK7FAnmfXs6emJYhBPwbPpWOpAa+QFnSSehmefZ8UpOmh0sGxUhBURFRWy6GDx+br5Oh1JGwljBSWKl1Yk4Pt0tnt6ejAxMZHZzF7FQI6BPkMFAJtqppEnGjFoI4Zsva0NqABkbSAl/Npx0ahBRQUzvUdTH/U6vcaWofW0Pxw3nTcqiLIOKRtMCRt5jnVe3SiyqkDADePZ1yow9fT0oFKpYNWqVRgcHIwChNq2rQvFZk2htCmoVkCiUEKBQUUrFbZUJOzq6oqb2lMk02gyto3RtKVSKbbf9jHtkhvh83orutRqNdTr9UyUmo4l57gVmVR4yrM9/q5zXNervPXV2lXqiwb7PCsC6nv2fZ0LqfXLCl7aDvu3lpv6wsL2BcvkNUyPbbVacQ80m36pvyshHNnD7fDhw6jX65m1kDZFsUxFZb6v40fbYl80m824Ruueiqn26vo3Pz+fsTUKnfxhmXYNt591tHGNkLRCdN6YO47jOJ2FC3GO4zi/AKQcPSsY2Nc1nc1GG6WcBHUCGblio9e0LikHLs8JtpEWNu3SpkCxfI24sSl0ADIbtusJhXSYNE3VimG2/nTKmZrLPYg0YoliCh3AlNOuIoi2jW1QYQEApqamMDU1lRQJUxE36pDbiCSNyKAzrSIG71GBR/9WsSplVykxOGUb2h+p91J2YsUEK7BQYFBnWcVKtZe8VEaLjpP2oxUabFtSaWd6DfteRVU7bwqFI3uxDQ8Po7+/H9VqFdVqNdqvtkNFAt6n0XHsG54mTIGI801tUOvCua5jxGdSHOOm9nrQg0bI2fRW7U/OewCZwwf0QABu6M/n87nVahWNRiOzGb6KQXlrmhWcuS6lIuX0Cwe2mXPHprdae7LzPWV3akcp0crWn0IVRTC7R5ydX6kvaNSGtb/s/E2J3moXPADHnhCb99mhAuDc3Fxc15jer2uOjiWAuLecilm0jRACqtVqPKWU40W75t8cCxXKOG9UdKO4yDnCfRFt/fgMRnNqJKl+KVMqldDb2xvHip+hR4s8dhzHcVY2LsQ5juN0OCpaqENFUkIBsLBHU0rQICo0qONB50U3J9fnWdTh1qg2RrQwIs46hireWbEg5fhqVIp9T/+mI6YCTSpCzEaZ0JnWyDJ9HiOBdL81PpdOqophFBZs9ATRFEY6jnnRZPZ5KQFT065s2Rwb9oGOJ++1ImVqzFPvWaEpJdalHH/bnjwhT9NuWX8rLmh6mBVr8p6pUYWKjYyz803FHnuN/psaA406rFQqGBoawtDQUExPtmVYgcfWkbapkae8T0U9YEFo5Xjrvlm6D6NGrDESDlgQbnmPClZsV71ej8/lXFDBjnZeLBbjddpmiik88IJpshQdde5bO7Brm46N2rhdL6zwavs8Nfe07619WWHK3qt9of2nApiKOWpzecKn/q1rAccpJUyn5oWmzGsdbB+nhHSuHfPz82g0GpicnES9Xkej0YiCl8I5rYeo6IEj/f390QYnJycxPT0dBV0K3bxeU5vtes0oZ9ZP00ptmjc/M7Vsios6r2ijAKJw3G63YxprSqx3HMdxOgcX4hzHcTqcVGRFipRwpVEDdOLs/fq3RlGp45FycLV+VojgD9PHNOJF77H11ugSW5bep0KI9o8KYFaoUXHGXqsw4ociAp1apt/phuAsW0WMlAOmETp6ne5bpHtrWWc5JQik+krFnlSEnf1d+8TeczTxzYqYeU66tlnH2YpbqXHXZ1khxdaPznu5XI62b/fUUpExJQzavrF9Zvsjda+2B0AmUkbLbLfbMRLORubpOOjehIpGeum+bSpW5qWtcm6q3abmJsUIK2pyLdGxpADD/d0oDLIOFHVsmmAeFORoF7Ozs3HfOjvHtQ1WILPp26loX7VHfZ4V+fRZOneWmgtqJ7zeRgXresm0dRXAtF52HNQGbTqlFZpT4pkVlNvtdhxD7aPUZ49NDdb2zczMYGJiArVaLfNFBOuhtqlrOtdDnQe8VucCU5l1TnNO6NrBeaCnGDMqzn4poyInywIW7/PJuUMxWz/n8tYEx3Ecp7NwIc5xHKfDSTmDwOIoDr6m9/FfK1pZ1LnUzclTZVoH04oi6ozxGhWwtG76bDoyKn6xfDpTwIKDRMcfWHA49T57f94zbdtYd90wnBFCjKQolUqo1WqZDfhZb+vkc487lpVKg6tUKiiVSpiYmMiMVUo0VadVHVArUKrDrmVZEVPHzAouqfHXMjS1NSV82fvznNSlREUVWY4mDrKPtX9Tc0bbkycqWiHTXpOqgxVJ2S8qcmqdqtUqisVifJ4VW9Sm7HixrzUyBziSWm2jT4EFYa67uzum6ZXLZZRKpczYMzVS95IDEMUhm9qpYsz8/Hzs/1arFcU0jbyjEFcsFnPtxNoGhbtisYiZmZlFY5InxNnIRh1TFScp6gDZg1Y0LdPW0c5TK0jlzV8rwhGNSNa98WxfWBFUBSReb8VKi21PSkzTgwyWmkOpstvtIydOT01NZaLhNFKNZenr7HNuKVCv1zE9PQ0AaDQaMVqNh+ewntp+jbxToZSnU/O5FIfZryyLe8gxUo7lWFGaeyCy/q1WK0a15u0b6DiO43QOLsQ5juN0OOok5zlA6vhZ8SElQOl9qbJU1NGIkpT4wX+tMKTOol6rqOhGsU43oefvGp1AEYCOPtPbNIJD0121juq02ogeFfJs36kgx78LhULcx4kOu+1fja7gnkeFQgHNZjM+r1gsYmRkBH19fZicnEyOTUpA1b61gguv1WhEXmMFL/sMG62WEl61LD310qYz23K0P1LtseLfUiKYYgVUFYv4PBXdtC4qJqWEOm2rvq6RYHnCYUrQ0/JpV7R/jchRsYFiUGpPP0b2UOhWUYk2phFzFHtUDOE8515delAJD1jRiDZtv/YNhRBNaaQow3K0T+34p8ac9eT8AZAR43S+qn2qPdsvGrQdmhqrqYscExUgU9FoOq52nU6teXmCMvuaaamp9FOuT9Y2bZvZTjuflqqPXTO4xunprak5mGorBUfu8QcsCMSMNOS/7GvdP1AFOqajsk3Awn6Fmnaq4rTOf9adQi6FYB4Cwb7nXnD280rnkB1z7lnHvea6u4+cVM098hzHcZzOxYU4x3GcDsc6gCkh4mgOnzp1qfusY8ioA43gYDnq9AHIOG0AMhEkVsSh2KAChqZ+0rHSdqvgBGQ3+06lfPIaOnjqpKnox3ZpO+yzenp6ooNFJ5KOOve44r5O3JScbdVN6lnWwMAA2u12PBGyq6sLlUoFlUplkYOtY6EiAcUYoo5/Siiw0WYsz4oL7AMVldQ28oRgG8Wl9eL7djzVNqyApX1gxzUlcmg6nh5OYU/EtFGD1o7zIpBS9SApMSlPoLFzlyIHhQ4KuXrACNuTEl/s/mQU4TRlmgKCbSPHhPttsZ38Gzgyj5vNJprNZmbesG9VjGMZqXml+8uxDjMzM6jX6/FU5dT6ZcehWCxiYGAgjiXLZV+xfrrnmJ0bvFbFR2sHLIsHBTD1UCMFtQ9V3E8J22p/VvTS+us6YiPa1HY4nrQb1iXvixAVJ9VG1YbtfAMWDq2x6a0vV0Dl2POkXdoHo4I1eliFQ4084/6Ac3Nz8YsQlk/BUr+8od1qP/M5tJ9ms4lGo5GxU/1sol3pus9DK9QWNXKc670Kf0ezacdxHGdl40Kc4zhOh2OjPZb6D34q0oJlWIdMr1ORpqurK54Ep5EwVkDT63VPH+tA5v3osykYaJodBRUVNlJOrJahv1OwUhHG9p99jSIb76NDz8g3CiNMlatWqxkRjU66Po9OLKNwdB+tcrkchQl7kEWeHWjbU+KRFUFt3wDZAwPyngcsPt3UpkjafswTifPKTwkTttyUOGeFYL6v4oSKvFYssHXVMdP2WdHClnG0tiw110IIUURQO7Epziqw6TzUelI8oxCmAqxNbV1KhLF2q/t6ad+qeKTzMyVa2hR1Cn60eRVfdO3Q8ee8BBD3itOoMdteG9XJMjXqlaKLttNGUJXL5fhas9nE9PQ0arVaXAdSdmHt52hzms+nKLvUwQq6ruU9MyX6LlVHa89564a2SZ+j2GtV6NeDe/jFC8U3HV8rrGmbU9HVGo3MLzfUBkJYiLpjnVqtVhSYGemmUc8cD5ar6eMAMtF7fBajTjXi2nEcx+lcXIhzHMfpUOgQ1Wq1+O37yyVPkNNy867v7u5GvV7PRJ5peqxN80ulP9pr6GhrxBXr0dXVhYmJCUxMTODQoUPo6urC4cOH8cILLySj1OhkqvOsAgCdqlqthueeew61Wi1GV6TEKC1bI4j4wzarEMJUpFKphJ6ensweWDpWdLIBxFStdrsd9z2amZnB9PQ0JiYmUCgUMD09vUjotKT6W8c1NTYpgUjH0opS2tfqeGukk44r25dKPdTxsc67FUiUlHik5S4lLOvv1uaskGCFPi0jJRKmxAz7/JQYlypnbGwMzz77bKZ/dG873kdxIE8s1OtUDLfRebadForNs7OzqNVqqNVqmRRTnTMqdqbSme346Fg/8sgjcb8uCt9W9NVyCEUURiipjbTbR06s5L5k2lYdY64PurYRvjc9PR1TGTV6UE80zRN1Fe0nAHj00UdRKpUWiZ9MS63X67FtqXm01J6MVsAkqXHQf1Pzh5HJhUJh0ZqWN+9sGSyHkYQpYU338tPx4TqoX37Yea12SWxqK3+KxSIajQZ6e3sxOzuLer2+6NRVXWd0vVe7tGK1ftlj1yluM/BKPrcdx3GclUMh+ArvOI7Tkfz4xz/GGWeccaKr4TiO4zjO/4Fnn30WJ5988omuhuM4jnOM8Yg4x3GcDmVkZAQAcODAAQwNDZ3g2hx/Jicnccopp+DZZ5/F4ODgia7Occfb29l4ezsbb29n82rbG0LA1NQUNm7ceBxq5ziO45xoXIhzHMfpUJjmMjQ09Avh+JDBwUFvbwfj7e1svL2djbf35fOL8AWa4zjOLypdR7/EcRzHcRzHcRzHcRzHcZxXiwtxjuM4juM4juM4juM4jrMMuBDnOI7ToZRKJdx0000olUonuirLgre3s/H2djbe3s7G2+s4juM4C/ipqY7jOI7jOI7jOI7jOI6zDHhEnOM4juM4juM4juM4juMsAy7EOY7jOI7jOI7jOI7jOM4y4EKc4ziO4ziO4ziO4ziO4ywDLsQ5juM4juM4juM4juM4zjLgQpzjOE6HsnPnTrz2ta9FuVzG5s2b8d3vfvdEV+kVc8stt+DXfu3XMDAwgLVr1+L3fu/3MDY2lrnmLW95CwqFQubnfe97X+aaAwcO4LLLLkO1WsXatWtxww03YG5ubjmb8rL42Mc+tqgtZ511Vny/2Wxi+/btWL16Nfr7+3HFFVfgueeey5SxUtoKAK997WsXtbdQKGD79u0AVv7YPvjgg/jd3/1dbNy4EYVCAV/72tcy74cQ8NGPfhQbNmxApVLBli1b8OSTT2aueemll3D11VdjcHAQw8PDuPbaazE9PZ255vHHH8eb3/xmlMtlnHLKKbjtttuOd9OSLNXe2dlZ7NixA+eeey76+vqwceNGvOMd78BPf/rTTBkpm7j11lsz16yE9gLAO9/5zkVtueSSSzLXdMr4AkjO5UKhgNtvvz1es5LG9+V8/hyrNXn37t244IILUCqV8LrXvQ533XXX8W6e4ziOcwJxIc5xHKcD+ed//mdcf/31uOmmm/Doo4/i/PPPx7Zt2/D888+f6Kq9Ih544AFs374d3/nOd7Br1y7Mzs5i69atqNVqmeve85734ODBg/FHHbf5+XlcdtllaLVaeOihh/D5z38ed911Fz760Y8ud3NeFm94wxsybfn2t78d3/uLv/gL/Ou//iu+/OUv44EHHsBPf/pTvO1tb4vvr7S2PvLII5m27tq1CwDwB3/wB/GalTy2tVoN559/Pnbu3Jl8/7bbbsM//MM/4JOf/CQefvhh9PX1Ydu2bWg2m/Gaq6++Gj/4wQ+wa9cu3H333XjwwQfx3ve+N74/OTmJrVu3YtOmTdi7dy9uv/12fOxjH8OnP/3p494+y1LtrdfrePTRR/GRj3wEjz76KL7yla9gbGwMb33rWxdde/PNN2fG/AMf+EB8b6W0l1xyySWZtnzxi1/MvN8p4wsg086DBw/is5/9LAqFAq644orMdStlfF/O58+xWJP379+Pyy67DL/927+Nffv24UMf+hDe/e5341vf+tayttdxHMdZRoLjOI7TcbzpTW8K27dvj3/Pz8+HjRs3hltuueUE1urV8/zzzwcA4YEHHoiv/dZv/Vb44Ac/mHvPN77xjdDV1RUOHToUX7vzzjvD4OBgmJmZOZ7VfcXcdNNN4fzzz0++Nz4+Hnp7e8OXv/zl+NqPfvSjACDs2bMnhLCy2prigx/8YDjjjDNCu90OIXTW2AIIX/3qV+Pf7XY7rF+/Ptx+++3xtfHx8VAqlcIXv/jFEEIIP/zhDwOA8Mgjj8Rr/v3f/z0UCoXwv//7vyGEED7xiU+EVatWZdq7Y8eOcOaZZx7nFi2NbW+K7373uwFAeOaZZ+JrmzZtCnfccUfuPSupvddcc024/PLLc+/p9PG9/PLLw+/8zu9kXlup4xvC4s+fY7Um/9Vf/VV4wxvekHnWlVdeGbZt23a8m+Q4juOcIDwiznEcp8NotVrYu3cvtmzZEl/r6urCli1bsGfPnhNYs1fPxMQEAGBkZCTz+j/90z9hzZo1OOecc3DjjTeiXq/H9/bs2YNzzz0X69ati69t27YNk5OT+MEPfrA8FX8FPPnkk9i4cSNOP/10XH311Thw4AAAYO/evZidnc2M61lnnYVTTz01jutKa6vSarXwhS98AX/yJ3+CQqEQX++ksVX279+PQ4cOZcZzaGgImzdvzozn8PAwfvVXfzVes2XLFnR1deHhhx+O11x00UUoFovxmm3btmFsbAyHDx9eptb835iYmEChUMDw8HDm9VtvvRWrV6/GG9/4Rtx+++2ZNL6V1t7du3dj7dq1OPPMM3HdddfhxRdfjO918vg+99xz+Ld/+zdce+21i95bqeNrP3+O1Zq8Z8+eTBm8ZqV/XjuO4zj59JzoCjiO4zjHlp/97GeYn5/P/McfANatW4f//u//PkG1evW022186EMfwm/8xm/gnHPOia//8R//MTZt2oSNGzfi8ccfx44dOzA2NoavfOUrAIBDhw4l+4Lv/TyxefNm3HXXXTjzzDNx8OBB/O3f/i3e/OY344knnsChQ4dQLBYXiRbr1q2L7VhJbbV87Wtfw/j4ON75znfG1zppbC2sX6r+Op5r167NvN/T04ORkZHMNaeddtqiMvjeqlWrjkv9Xy3NZhM7duzAVVddhcHBwfj6n//5n+OCCy7AyMgIHnroIdx44404ePAgPv7xjwNYWe295JJL8La3vQ2nnXYann76afz1X/81Lr30UuzZswfd3d0dPb6f//znMTAwkEnTBFbu+KY+f47Vmpx3zeTkJBqNBiqVyvFokuM4jnMCcSHOcRzHWRFs374dTzzxRGbPNACZ/ZTOPfdcbNiwARdffDGefvppnHHGGctdzVfFpZdeGn8/77zzsHnzZmzatAn/8i//0vHO2Gc+8xlceuml2LhxY3ytk8bWWWB2dhZ/+Id/iBAC7rzzzsx7119/ffz9vPPOQ7FYxJ/+6Z/illtuQalUWu6qvir+6I/+KP5+7rnn4rzzzsMZZ5yB3bt34+KLLz6BNTv+fPazn8XVV1+NcrmceX2ljm/e54/jOI7j/F/w1FTHcZwOY82aNeju7l50cttzzz2H9evXn6BavTre//734+6778b999+Pk08+eclrN2/eDAB46qmnAADr169P9gXf+3lmeHgYv/RLv4SnnnoK69evR6vVwvj4eOYaHdeV2tZnnnkG99xzD9797ncveV0njS3rt9Q8Xb9+/aIDVubm5vDSSy+t2DGnCPfMM89g165dmWi4FJs3b8bc3Bx+8pOfAFh57VVOP/10rFmzJmO/nTa+APAf//EfGBsbO+p8BlbG+OZ9/hyrNTnvmsHBwY7/AsZxHOcXFRfiHMdxOoxisYgLL7wQ9957b3yt3W7j3nvvxejo6Ams2SsnhID3v//9+OpXv4r77rtvUcpSin379gEANmzYAAAYHR3F97///YzDSwHg7LPPPi71PlZMT0/j6aefxoYNG3DhhReit7c3M65jY2M4cOBAHNeV2tbPfe5zWLt2LS677LIlr+uksT3ttNOwfv36zHhOTk7i4Ycfzozn+Pg49u7dG6+577770G63oyg5OjqKBx98ELOzs/GaXbt24cwzz/y5S1ukCPfkk0/innvuwerVq496z759+9DV1RVTOFdSey3/8z//gxdffDFjv500vuQzn/kMLrzwQpx//vlHvfbneXyP9vlzrNbk0dHRTBm8ZqV9XjuO4zivgBN8WITjOI5zHPjSl74USqVSuOuuu8IPf/jD8N73vjcMDw9nTm5bCVx33XVhaGgo7N69Oxw8eDD+1Ov1EEIITz31VLj55pvD9773vbB///7w9a9/PZx++unhoosuimXMzc2Fc845J2zdujXs27cvfPOb3wwnnXRSuPHGG09Us3L58Ic/HHbv3h32798f/vM//zNs2bIlrFmzJjz//PMhhBDe9773hVNPPTXcd9994Xvf+14YHR0No6Oj8f6V1FYyPz8fTj311LBjx47M650wtlNTU+Gxxx4Ljz32WAAQPv7xj4fHHnssnhJ66623huHh4fD1r389PP744+Hyyy8Pp512Wmg0GrGMSy65JLzxjW8MDz/8cPj2t78dXv/614errroqvj8+Ph7WrVsX3v72t4cnnngifOlLXwrVajV86lOf+rlqb6vVCm9961vDySefHPbt25eZzzw98qGHHgp33HFH2LdvX3j66afDF77whXDSSSeFd7zjqT377AAAAtlJREFUHSuuvVNTU+Ev//Ivw549e8L+/fvDPffcEy644ILw+te/PjSbzVhGp4wvmZiYCNVqNdx5552L7l9p43u0z58Qjs2a/OMf/zhUq9Vwww03hB/96Edh586dobu7O3zzm99c1vY6juM4y4cLcY7jOB3KP/7jP4ZTTz01FIvF8KY3vSl85zvfOdFVesUASP587nOfCyGEcODAgXDRRReFkZGRUCqVwute97pwww03hImJiUw5P/nJT8Kll14aKpVKWLNmTfjwhz8cZmdnT0CLlubKK68MGzZsCMViMbzmNa8JV155ZXjqqafi+41GI/zZn/1ZWLVqVahWq+H3f//3w8GDBzNlrJS2km9961sBQBgbG8u83glje//99yft95prrgkhhNBut8NHPvKRsG7dulAqlcLFF1+8qB9efPHFcNVVV4X+/v4wODgY3vWud4WpqanMNf/1X/8VfvM3fzOUSqXwmte8Jtx6663L1cQMS7V3//79ufP5/vvvDyGEsHfv3rB58+YwNDQUyuVy+OVf/uXw93//9xnhKoSV0d56vR62bt0aTjrppNDb2xs2bdoU3vOe9yz6MqRTxpd86lOfCpVKJYyPjy+6f6WN79E+f0I4dmvy/fffH37lV34lFIvFcPrpp2ee4TiO43QehRBCOE7Bdo7jOI7jOI7jOI7jOI7j/H98jzjHcRzHcRzHcRzHcRzHWQZciHMcx3Ecx3Ecx3Ecx3GcZcCFOMdxHMdxHMdxHMdxHMdZBlyIcxzHcRzHcRzHcRzHcZxlwIU4x3Ecx3Ecx3Ecx3Ecx1kGXIhzHMdxHMdxHMdxHMdxnGXAhTjHcRzHcRzHcRzHcRzHWQZciHMcx3Ecx3Ecx3Ecx3GcZcCFOMdxHMdxHMdxHMdxHMdZBlyIcxzHcRzHcRzHcRzHcZxlwIU4x3Ecx3Ecx3Ecx3Ecx1kGXIhzHMdxHMdxHMdxHMdxnGXg/wG/XpnK5FajNAAAAABJRU5ErkJggg=="},"metadata":{}}],"execution_count":32},{"cell_type":"code","source":"def plot(val_loss,train_loss,typ):\n\n    plt.title(\"{} after epoch: {}\".format(typ,len(train_loss)))\n\n    plt.xlabel(\"Epoch\")\n\n    plt.ylabel(typ)\n\n    plt.plot(list(range(len(train_loss))),train_loss,color=\"r\",label=\"Train \"+typ)\n\n    plt.plot(list(range(len(val_loss))),val_loss,color=\"b\",label=\"Validation \"+typ)\n\n    plt.legend()\n\n    plt.savefig(os.path.join(data_dir,typ+\".png\"))\n\n    plt.close()","metadata":{"id":"wCNW2ZBbwXod","trusted":true,"execution":{"iopub.status.busy":"2024-12-04T22:52:59.475497Z","iopub.execute_input":"2024-12-04T22:52:59.475765Z","iopub.status.idle":"2024-12-04T22:52:59.482437Z","shell.execute_reply.started":"2024-12-04T22:52:59.475739Z","shell.execute_reply":"2024-12-04T22:52:59.481597Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"val_loss_gph=[]\n\ntrain_loss_gph=[]\n\nval_acc_gph=[]\n\ntrain_acc_gph=[]","metadata":{"id":"DZ4sbUwCwXq_","trusted":true,"execution":{"iopub.status.busy":"2024-12-04T22:52:59.483595Z","iopub.execute_input":"2024-12-04T22:52:59.483863Z","iopub.status.idle":"2024-12-04T22:52:59.497861Z","shell.execute_reply.started":"2024-12-04T22:52:59.483837Z","shell.execute_reply":"2024-12-04T22:52:59.497165Z"}},"outputs":[],"execution_count":34},{"cell_type":"markdown","source":"## Model Training Function\n\n\n\nThis function encapsulates the model training logic. It takes a model, criterion for loss calculation, optimizer for backpropagation, and a scheduler for learning rate adjustment as inputs and conducts the training process.","metadata":{"id":"fc576835"}},{"cell_type":"code","source":"!pip install torchsummary","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T22:52:59.499048Z","iopub.execute_input":"2024-12-04T22:52:59.499341Z","iopub.status.idle":"2024-12-04T22:53:07.691680Z","shell.execute_reply.started":"2024-12-04T22:52:59.499316Z","shell.execute_reply":"2024-12-04T22:53:07.690851Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torchsummary in /opt/conda/lib/python3.10/site-packages (1.5.1)\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchsummary import torchsummary\n\nclass SEBlock(nn.Module):\n    def __init__(self, channels, reduction=16):\n        super(SEBlock, self).__init__()\n        self.fc1 = nn.Linear(channels, channels // reduction, bias=False)\n        self.fc2 = nn.Linear(channels // reduction, channels, bias=False)\n\n    def forward(self, x):\n        batch, channels, _, _ = x.size()\n        y = x.view(batch, channels, -1).mean(dim=2)  # Global average pooling\n        y = nn.functional.relu(self.fc1(y))\n        y = torch.sigmoid(self.fc2(y))\n        y = y.view(batch, channels, 1, 1)\n        return x * y\n\nclass ResidualSEBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, stride=1):\n        super(ResidualSEBlock, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3,\n                               stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.conv2 = nn.Conv2d(out_channels, out_channels,\n                               kernel_size=3, padding=1,\n                               bias=False)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        self.se = SEBlock(out_channels)\n\n        self.downsample = None\n        if stride != 1 or in_channels != out_channels:\n            self.downsample = nn.Sequential(\n                nn.Conv2d(in_channels,\n                          out_channels,\n                          kernel_size=1,\n                          stride=stride,\n                          bias=False),\n                nn.BatchNorm2d(out_channels),\n            )\n            \n        self.relu = nn.ReLU(inplace=True)\n\n    def forward(self, x):\n        residual = x\n        \n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        \n        out = self.se(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        \n        return self.relu(out)\n\nclass Network(nn.Module):\n    def __init__(self):\n        super(Network,self).__init__()\n        \n        self.backbone = nn.Sequential(\n            nn.Conv2d(3 ,64 ,kernel_size=7 ,stride=2 ,padding=3 ,bias=False),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3 ,stride=2 ,padding=1),\n            self._make_layer(64 ,64 ,3),\n            self._make_layer(64 ,128 ,4 ,stride=2),\n            self._make_layer(128 ,256 ,6 ,stride=2),\n            self._make_layer(256 ,512 ,3 ,stride=2),\n            nn.AdaptiveAvgPool2d((1 ,1))\n        )\n        \n        # Final classification layer \n        self.cls_layer = nn.Linear(512 ,num_classes)\n\n    def _make_layer(self,in_channels,out_channels,num_blocks,stride=1):\n        downsample=None\n        \n        if stride != 1 or in_channels != out_channels:\n            downsample=nn.Sequential(\n                nn.Conv2d(in_channels,out_channels,kernel_size=1,stride=stride,bias=False),\n                nn.BatchNorm2d(out_channels),\n            )\n        \n        layers=[ResidualSEBlock(in_channels,out_channels,stride=stride)]\n        \n        for _ in range(1,num_blocks):\n            layers.append(ResidualSEBlock(out_channels,out_channels))\n        \n        return nn.Sequential(*layers)\n\n    def forward(self,x):\n        feats=self.backbone(x)\n        \n        feats=feats.view(feats.size(0),-1) \n       \n        out=self.cls_layer(feats) \n        \n        return {\"feats\": feats,\"out\": out}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T23:35:05.838863Z","iopub.execute_input":"2024-12-04T23:35:05.839202Z","iopub.status.idle":"2024-12-04T23:35:05.855120Z","shell.execute_reply.started":"2024-12-04T23:35:05.839174Z","shell.execute_reply":"2024-12-04T23:35:05.854163Z"}},"outputs":[],"execution_count":65},{"cell_type":"code","source":"# import torch\n# import torch.nn as nn\n# import torch.nn.functional as F\n\n# class ChannelAttention(nn.Module):\n#     def __init__(self, num_channels, reduction_ratio=16):\n#         super(ChannelAttention, self).__init__()\n#         self.avg_pool = nn.AdaptiveAvgPool2d(1)\n#         self.max_pool = nn.AdaptiveMaxPool2d(1)\n#         self.fc = nn.Sequential(\n#             nn.Linear(num_channels, num_channels // reduction_ratio, bias=False),\n#             nn.ReLU(),\n#             nn.Linear(num_channels // reduction_ratio, num_channels, bias=False)\n#         )\n#         self.sigmoid = nn.Sigmoid()\n\n#     def forward(self, x):\n#         avg_out = self.fc(self.avg_pool(x).view(x.size(0), -1))\n#         max_out = self.fc(self.max_pool(x).view(x.size(0), -1))\n#         out = avg_out + max_out\n#         return self.sigmoid(out).view(x.size(0), x.size(1), 1, 1)\n\n# class SpatialAttention(nn.Module):\n#     def __init__(self, kernel_size=7):\n#         super(SpatialAttention, self).__init__()\n#         self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=kernel_size//2, bias=False)\n#         self.sigmoid = nn.Sigmoid()\n\n#     def forward(self, x):\n#         avg_out = torch.mean(x, dim=1, keepdim=True)\n#         max_out, _ = torch.max(x, dim=1, keepdim=True)\n#         x = torch.cat([avg_out, max_out], dim=1)\n#         x = self.conv1(x)\n#         return self.sigmoid(x)\n\n# class CBAMBlock(nn.Module):\n#     def __init__(self, num_channels, reduction_ratio=16, kernel_size=7):\n#         super(CBAMBlock, self).__init__()\n#         self.channel_attention = ChannelAttention(num_channels, reduction_ratio)\n#         self.spatial_attention = SpatialAttention(kernel_size)\n\n#     def forward(self, x):\n#         x = x * self.channel_attention(x)\n#         x = x * self.spatial_attention(x)\n#         return x\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T23:35:06.456840Z","iopub.execute_input":"2024-12-04T23:35:06.457171Z","iopub.status.idle":"2024-12-04T23:35:06.462602Z","shell.execute_reply.started":"2024-12-04T23:35:06.457140Z","shell.execute_reply":"2024-12-04T23:35:06.461807Z"}},"outputs":[],"execution_count":66},{"cell_type":"code","source":"# import torch\n# import torch.nn as nn\n# import torch.nn.functional as F\n\n# class ChannelAttention(nn.Module):\n#     def __init__(self, num_channels, reduction_ratio=16):\n#         super(ChannelAttention, self).__init__()\n#         self.avg_pool = nn.AdaptiveAvgPool2d(1)\n#         self.max_pool = nn.AdaptiveMaxPool2d(1)\n#         self.fc1 = nn.Linear(num_channels, num_channels // reduction_ratio, bias=False)\n#         self.relu = nn.ReLU()\n#         self.fc2 = nn.Linear(num_channels // reduction_ratio, num_channels, bias=False)\n#         self.sigmoid = nn.Sigmoid()\n\n#     def forward(self, x):\n#         avg_pooled = self.avg_pool(x).view(x.size(0), -1)\n#         max_pooled = self.max_pool(x).view(x.size(0), -1)\n#         avg_out = self.fc1(avg_pooled)\n#         avg_out = self.relu(avg_out)\n#         avg_out = self.fc2(avg_out)\n#         max_out = self.fc1(max_pooled)\n#         max_out = self.relu(max_out)\n#         max_out = self.fc2(max_out)\n#         out = avg_out + max_out\n#         return self.sigmoid(out).view(x.size(0), x.size(1), 1, 1)\n\n# class SpatialAttention(nn.Module):\n#     def __init__(self, kernel_size=7):\n#         super(SpatialAttention, self).__init__()\n#         self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=kernel_size // 2, bias=False)\n#         self.sigmoid = nn.Sigmoid()\n\n#     def forward(self, x):\n#         avg_out = torch.mean(x, dim=1, keepdim=True)\n#         max_out, _ = torch.max(x, dim=1, keepdim=True)\n#         x = torch.cat([avg_out, max_out], dim=1)\n#         x = self.conv1(x)\n#         return self.sigmoid(x)\n\n# class CBAM(nn.Module):\n#     def __init__(self, num_channels, reduction_ratio=16, kernel_size=7):\n#         super(CBAM, self).__init__()\n#         self.channel_attention = ChannelAttention(num_channels, reduction_ratio)\n#         self.spatial_attention = SpatialAttention(kernel_size)\n\n#     def forward(self, x):\n#         x = x * self.channel_attention(x)\n#         x = x * self.spatial_attention(x)\n#         return x\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T23:35:06.830599Z","iopub.execute_input":"2024-12-04T23:35:06.830864Z","iopub.status.idle":"2024-12-04T23:35:06.836168Z","shell.execute_reply.started":"2024-12-04T23:35:06.830838Z","shell.execute_reply":"2024-12-04T23:35:06.835464Z"}},"outputs":[],"execution_count":67},{"cell_type":"code","source":"# import torch\n# import torch.nn as nn\n# from torchsummary import summary\n\n# # Assuming 'Network' is your custom model class, which you should define or import\n# class Network(nn.Module):\n#     def __init__(self, num_classes=10):  # Set the default number of classes to 10\n#         super(Network, self).__init__()\n#         # Example layers\n#         self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n#         self.bn1 = nn.BatchNorm2d(16)\n#         self.relu = nn.ReLU(inplace=True)\n#         self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n#         self.cbam = CBAM(16)  # Example usage of CBAM with 16 channels\n#         # Continue building your network architecture\n#         self.fc = nn.Linear(16 * 56 * 56, num_classes)  # Adjust size according to your architecture\n\n#     def forward(self, x):\n#         x = self.conv1(x)\n#         x = self.bn1(x)\n#         x = self.relu(x)\n#         x = self.pool(x)\n#         x = self.cbam(x)  # Apply CBAM module after initial layers\n#         x = x.view(x.size(0), -1)  # Flatten the features for the fully connected layer\n#         x = self.fc(x)\n#         return x\n\n# # Initialize the model and transfer it to the appropriate device\n# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# model = Network().to(device)\n\n# # Use torchsummary to print the summary of the model\n# summary(model, (3, 112, 112))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T23:35:07.274458Z","iopub.execute_input":"2024-12-04T23:35:07.275328Z","iopub.status.idle":"2024-12-04T23:35:07.280246Z","shell.execute_reply.started":"2024-12-04T23:35:07.275295Z","shell.execute_reply":"2024-12-04T23:35:07.279363Z"}},"outputs":[],"execution_count":68},{"cell_type":"code","source":"# Initialize the model and print summary \nmodel = Network().to(device)\nfrom torchsummary import summary\n\nsummary(model,(3 ,112 ,112))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T23:35:07.736601Z","iopub.execute_input":"2024-12-04T23:35:07.736923Z","iopub.status.idle":"2024-12-04T23:35:08.046102Z","shell.execute_reply.started":"2024-12-04T23:35:07.736894Z","shell.execute_reply":"2024-12-04T23:35:08.045117Z"}},"outputs":[{"name":"stdout","text":"----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1           [-1, 64, 56, 56]           9,408\n       BatchNorm2d-2           [-1, 64, 56, 56]             128\n              ReLU-3           [-1, 64, 56, 56]               0\n         MaxPool2d-4           [-1, 64, 28, 28]               0\n            Conv2d-5           [-1, 64, 28, 28]          36,864\n       BatchNorm2d-6           [-1, 64, 28, 28]             128\n              ReLU-7           [-1, 64, 28, 28]               0\n            Conv2d-8           [-1, 64, 28, 28]          36,864\n       BatchNorm2d-9           [-1, 64, 28, 28]             128\n           Linear-10                    [-1, 4]             256\n           Linear-11                   [-1, 64]             256\n          SEBlock-12           [-1, 64, 28, 28]               0\n             ReLU-13           [-1, 64, 28, 28]               0\n  ResidualSEBlock-14           [-1, 64, 28, 28]               0\n           Conv2d-15           [-1, 64, 28, 28]          36,864\n      BatchNorm2d-16           [-1, 64, 28, 28]             128\n             ReLU-17           [-1, 64, 28, 28]               0\n           Conv2d-18           [-1, 64, 28, 28]          36,864\n      BatchNorm2d-19           [-1, 64, 28, 28]             128\n           Linear-20                    [-1, 4]             256\n           Linear-21                   [-1, 64]             256\n          SEBlock-22           [-1, 64, 28, 28]               0\n             ReLU-23           [-1, 64, 28, 28]               0\n  ResidualSEBlock-24           [-1, 64, 28, 28]               0\n           Conv2d-25           [-1, 64, 28, 28]          36,864\n      BatchNorm2d-26           [-1, 64, 28, 28]             128\n             ReLU-27           [-1, 64, 28, 28]               0\n           Conv2d-28           [-1, 64, 28, 28]          36,864\n      BatchNorm2d-29           [-1, 64, 28, 28]             128\n           Linear-30                    [-1, 4]             256\n           Linear-31                   [-1, 64]             256\n          SEBlock-32           [-1, 64, 28, 28]               0\n             ReLU-33           [-1, 64, 28, 28]               0\n  ResidualSEBlock-34           [-1, 64, 28, 28]               0\n           Conv2d-35          [-1, 128, 14, 14]          73,728\n      BatchNorm2d-36          [-1, 128, 14, 14]             256\n             ReLU-37          [-1, 128, 14, 14]               0\n           Conv2d-38          [-1, 128, 14, 14]         147,456\n      BatchNorm2d-39          [-1, 128, 14, 14]             256\n           Linear-40                    [-1, 8]           1,024\n           Linear-41                  [-1, 128]           1,024\n          SEBlock-42          [-1, 128, 14, 14]               0\n           Conv2d-43          [-1, 128, 14, 14]           8,192\n      BatchNorm2d-44          [-1, 128, 14, 14]             256\n             ReLU-45          [-1, 128, 14, 14]               0\n  ResidualSEBlock-46          [-1, 128, 14, 14]               0\n           Conv2d-47          [-1, 128, 14, 14]         147,456\n      BatchNorm2d-48          [-1, 128, 14, 14]             256\n             ReLU-49          [-1, 128, 14, 14]               0\n           Conv2d-50          [-1, 128, 14, 14]         147,456\n      BatchNorm2d-51          [-1, 128, 14, 14]             256\n           Linear-52                    [-1, 8]           1,024\n           Linear-53                  [-1, 128]           1,024\n          SEBlock-54          [-1, 128, 14, 14]               0\n             ReLU-55          [-1, 128, 14, 14]               0\n  ResidualSEBlock-56          [-1, 128, 14, 14]               0\n           Conv2d-57          [-1, 128, 14, 14]         147,456\n      BatchNorm2d-58          [-1, 128, 14, 14]             256\n             ReLU-59          [-1, 128, 14, 14]               0\n           Conv2d-60          [-1, 128, 14, 14]         147,456\n      BatchNorm2d-61          [-1, 128, 14, 14]             256\n           Linear-62                    [-1, 8]           1,024\n           Linear-63                  [-1, 128]           1,024\n          SEBlock-64          [-1, 128, 14, 14]               0\n             ReLU-65          [-1, 128, 14, 14]               0\n  ResidualSEBlock-66          [-1, 128, 14, 14]               0\n           Conv2d-67          [-1, 128, 14, 14]         147,456\n      BatchNorm2d-68          [-1, 128, 14, 14]             256\n             ReLU-69          [-1, 128, 14, 14]               0\n           Conv2d-70          [-1, 128, 14, 14]         147,456\n      BatchNorm2d-71          [-1, 128, 14, 14]             256\n           Linear-72                    [-1, 8]           1,024\n           Linear-73                  [-1, 128]           1,024\n          SEBlock-74          [-1, 128, 14, 14]               0\n             ReLU-75          [-1, 128, 14, 14]               0\n  ResidualSEBlock-76          [-1, 128, 14, 14]               0\n           Conv2d-77            [-1, 256, 7, 7]         294,912\n      BatchNorm2d-78            [-1, 256, 7, 7]             512\n             ReLU-79            [-1, 256, 7, 7]               0\n           Conv2d-80            [-1, 256, 7, 7]         589,824\n      BatchNorm2d-81            [-1, 256, 7, 7]             512\n           Linear-82                   [-1, 16]           4,096\n           Linear-83                  [-1, 256]           4,096\n          SEBlock-84            [-1, 256, 7, 7]               0\n           Conv2d-85            [-1, 256, 7, 7]          32,768\n      BatchNorm2d-86            [-1, 256, 7, 7]             512\n             ReLU-87            [-1, 256, 7, 7]               0\n  ResidualSEBlock-88            [-1, 256, 7, 7]               0\n           Conv2d-89            [-1, 256, 7, 7]         589,824\n      BatchNorm2d-90            [-1, 256, 7, 7]             512\n             ReLU-91            [-1, 256, 7, 7]               0\n           Conv2d-92            [-1, 256, 7, 7]         589,824\n      BatchNorm2d-93            [-1, 256, 7, 7]             512\n           Linear-94                   [-1, 16]           4,096\n           Linear-95                  [-1, 256]           4,096\n          SEBlock-96            [-1, 256, 7, 7]               0\n             ReLU-97            [-1, 256, 7, 7]               0\n  ResidualSEBlock-98            [-1, 256, 7, 7]               0\n           Conv2d-99            [-1, 256, 7, 7]         589,824\n     BatchNorm2d-100            [-1, 256, 7, 7]             512\n            ReLU-101            [-1, 256, 7, 7]               0\n          Conv2d-102            [-1, 256, 7, 7]         589,824\n     BatchNorm2d-103            [-1, 256, 7, 7]             512\n          Linear-104                   [-1, 16]           4,096\n          Linear-105                  [-1, 256]           4,096\n         SEBlock-106            [-1, 256, 7, 7]               0\n            ReLU-107            [-1, 256, 7, 7]               0\n ResidualSEBlock-108            [-1, 256, 7, 7]               0\n          Conv2d-109            [-1, 256, 7, 7]         589,824\n     BatchNorm2d-110            [-1, 256, 7, 7]             512\n            ReLU-111            [-1, 256, 7, 7]               0\n          Conv2d-112            [-1, 256, 7, 7]         589,824\n     BatchNorm2d-113            [-1, 256, 7, 7]             512\n          Linear-114                   [-1, 16]           4,096\n          Linear-115                  [-1, 256]           4,096\n         SEBlock-116            [-1, 256, 7, 7]               0\n            ReLU-117            [-1, 256, 7, 7]               0\n ResidualSEBlock-118            [-1, 256, 7, 7]               0\n          Conv2d-119            [-1, 256, 7, 7]         589,824\n     BatchNorm2d-120            [-1, 256, 7, 7]             512\n            ReLU-121            [-1, 256, 7, 7]               0\n          Conv2d-122            [-1, 256, 7, 7]         589,824\n     BatchNorm2d-123            [-1, 256, 7, 7]             512\n          Linear-124                   [-1, 16]           4,096\n          Linear-125                  [-1, 256]           4,096\n         SEBlock-126            [-1, 256, 7, 7]               0\n            ReLU-127            [-1, 256, 7, 7]               0\n ResidualSEBlock-128            [-1, 256, 7, 7]               0\n          Conv2d-129            [-1, 256, 7, 7]         589,824\n     BatchNorm2d-130            [-1, 256, 7, 7]             512\n            ReLU-131            [-1, 256, 7, 7]               0\n          Conv2d-132            [-1, 256, 7, 7]         589,824\n     BatchNorm2d-133            [-1, 256, 7, 7]             512\n          Linear-134                   [-1, 16]           4,096\n          Linear-135                  [-1, 256]           4,096\n         SEBlock-136            [-1, 256, 7, 7]               0\n            ReLU-137            [-1, 256, 7, 7]               0\n ResidualSEBlock-138            [-1, 256, 7, 7]               0\n          Conv2d-139            [-1, 512, 4, 4]       1,179,648\n     BatchNorm2d-140            [-1, 512, 4, 4]           1,024\n            ReLU-141            [-1, 512, 4, 4]               0\n          Conv2d-142            [-1, 512, 4, 4]       2,359,296\n     BatchNorm2d-143            [-1, 512, 4, 4]           1,024\n          Linear-144                   [-1, 32]          16,384\n          Linear-145                  [-1, 512]          16,384\n         SEBlock-146            [-1, 512, 4, 4]               0\n          Conv2d-147            [-1, 512, 4, 4]         131,072\n     BatchNorm2d-148            [-1, 512, 4, 4]           1,024\n            ReLU-149            [-1, 512, 4, 4]               0\n ResidualSEBlock-150            [-1, 512, 4, 4]               0\n          Conv2d-151            [-1, 512, 4, 4]       2,359,296\n     BatchNorm2d-152            [-1, 512, 4, 4]           1,024\n            ReLU-153            [-1, 512, 4, 4]               0\n          Conv2d-154            [-1, 512, 4, 4]       2,359,296\n     BatchNorm2d-155            [-1, 512, 4, 4]           1,024\n          Linear-156                   [-1, 32]          16,384\n          Linear-157                  [-1, 512]          16,384\n         SEBlock-158            [-1, 512, 4, 4]               0\n            ReLU-159            [-1, 512, 4, 4]               0\n ResidualSEBlock-160            [-1, 512, 4, 4]               0\n          Conv2d-161            [-1, 512, 4, 4]       2,359,296\n     BatchNorm2d-162            [-1, 512, 4, 4]           1,024\n            ReLU-163            [-1, 512, 4, 4]               0\n          Conv2d-164            [-1, 512, 4, 4]       2,359,296\n     BatchNorm2d-165            [-1, 512, 4, 4]           1,024\n          Linear-166                   [-1, 32]          16,384\n          Linear-167                  [-1, 512]          16,384\n         SEBlock-168            [-1, 512, 4, 4]               0\n            ReLU-169            [-1, 512, 4, 4]               0\n ResidualSEBlock-170            [-1, 512, 4, 4]               0\nAdaptiveAvgPool2d-171            [-1, 512, 1, 1]               0\n          Linear-172                    [-1, 2]           1,026\n================================================================\nTotal params: 21,442,882\nTrainable params: 21,442,882\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.14\nForward/backward pass size (MB): 27.12\nParams size (MB): 81.80\nEstimated Total Size (MB): 109.06\n----------------------------------------------------------------\n","output_type":"stream"}],"execution_count":69},{"cell_type":"code","source":"import torch.optim as optim\nfrom torch.optim import lr_scheduler\n\n# Criterion with class weights for handling imbalances \nweights=torch.tensor([1.0 ,4.7], device=device) \n# criterion=nn.CrossEntropyLoss(weight=weights) \n\n# # Optimizer \n# optimizer=optim.Adam(model.parameters(), lr=0.0001) \n\n# # Learning rate scheduler \n# scheduler=lr_scheduler.StepLR(optimizer ,step_size=10 ,gamma=0.1)\ncriterion = torch.nn.CrossEntropyLoss()\n\n# --------------------------------------------------- #\n\n# Defining Optimizer\n#optimizer =  # TODO: Feel free to pick a optimizer\n#optimizer = torch.optim.Adam(model.parameters(), lr=config['lr'], weight_decay=1e-4)\n\n# --------------------------------------------------- #\nimport torch.optim as optim\n\n# Define the SGD optimizer\noptimizer = optim.SGD(\n    model.parameters(),      # Model parameters to update\n    lr=0.01,                 # Learning rate, which you can adjust based on experimentation\n    momentum=0.9,            # Momentum for faster convergence\n    weight_decay=1e-4        # Weight decay for regularization\n)\n\n# Optionally, define a learning rate scheduler\n# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10, eta_min=1e-6)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T23:52:53.113713Z","iopub.execute_input":"2024-12-04T23:52:53.114111Z","iopub.status.idle":"2024-12-04T23:52:53.123245Z","shell.execute_reply.started":"2024-12-04T23:52:53.114078Z","shell.execute_reply":"2024-12-04T23:52:53.122455Z"}},"outputs":[],"execution_count":80},{"cell_type":"code","source":"import wandb\nwandb.login(key = '889736f968fd287026464ea18bead25ea75991d4')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T23:52:54.251923Z","iopub.execute_input":"2024-12-04T23:52:54.252225Z","iopub.status.idle":"2024-12-04T23:52:54.261084Z","shell.execute_reply.started":"2024-12-04T23:52:54.252197Z","shell.execute_reply":"2024-12-04T23:52:54.260194Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n","output_type":"stream"},{"execution_count":81,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":81},{"cell_type":"code","source":"\nconfig={\n   \"learning_rate\":0.0001,\n   \"epochs\":10,\n   \"batch_size\":64,\n   \"loss_function\":\"CrossEntropyLoss\",\n   \"architecture\":\"SERESNET\",\n   \"dataset\":\"Your Dataset Name\"\n}\n\n# Create your wandb run \nrun=wandb.init(\n   name=\"SERESNET SGD Second \",\n   reinit=True,\n   project=\"IDL_Project\",\n   config=config \n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T23:53:08.352806Z","iopub.execute_input":"2024-12-04T23:53:08.353153Z","iopub.status.idle":"2024-12-04T23:53:11.326708Z","shell.execute_reply.started":"2024-12-04T23:53:08.353121Z","shell.execute_reply":"2024-12-04T23:53:11.325807Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Finishing last run (ID:fzs6cq0c) before initializing another..."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">SERESNET SGD </strong> at: <a href='https://wandb.ai/aizabayo-carnegie-mellon-university/IDL_Project/runs/fzs6cq0c' target=\"_blank\">https://wandb.ai/aizabayo-carnegie-mellon-university/IDL_Project/runs/fzs6cq0c</a><br/> View project at: <a href='https://wandb.ai/aizabayo-carnegie-mellon-university/IDL_Project' target=\"_blank\">https://wandb.ai/aizabayo-carnegie-mellon-university/IDL_Project</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20241204_234435-fzs6cq0c/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Successfully finished last run (ID:fzs6cq0c). Initializing new run:<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.18.7"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241204_235308-ha2i9nqm</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/aizabayo-carnegie-mellon-university/IDL_Project/runs/ha2i9nqm' target=\"_blank\">SERESNET SGD Second </a></strong> to <a href='https://wandb.ai/aizabayo-carnegie-mellon-university/IDL_Project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/aizabayo-carnegie-mellon-university/IDL_Project' target=\"_blank\">https://wandb.ai/aizabayo-carnegie-mellon-university/IDL_Project</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/aizabayo-carnegie-mellon-university/IDL_Project/runs/ha2i9nqm' target=\"_blank\">https://wandb.ai/aizabayo-carnegie-mellon-university/IDL_Project/runs/ha2i9nqm</a>"},"metadata":{}}],"execution_count":82},{"cell_type":"code","source":"def train_model(model, criterion, optimizer, scheduler, dataloaders, dataset_sizes, device, num_epochs=25):\n    since = time.time()\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n\n    for epoch in range(num_epochs):\n        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n        print('-' * 10)\n\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            for inputs, labels in dataloaders[phase]:\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                optimizer.zero_grad()  # Zero the parameter gradients\n\n                # Forward pass\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    # Access the actual output for loss and accuracy computation\n                    output_tensor = outputs['out']  \n                    _, preds = torch.max(output_tensor, 1)\n                    loss = criterion(output_tensor, labels)\n\n                    # Backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n\n            if phase == 'train':\n                scheduler.step()\n\n            epoch_loss = running_loss / dataset_sizes[phase]\n            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n                phase, epoch_loss, epoch_acc))\n\n            # Deep copy the model if it has the best accuracy on validation set\n            if phase == 'val' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(\n        time_elapsed // 60, time_elapsed % 60))\n    print('Best val Acc: {:4f}'.format(best_acc))\n\n    model.load_state_dict(best_model_wts)\n    return model\n","metadata":{"id":"4MUg_T9FwXty","trusted":true,"execution":{"iopub.status.busy":"2024-12-04T23:53:11.347133Z","iopub.execute_input":"2024-12-04T23:53:11.347373Z","iopub.status.idle":"2024-12-04T23:53:11.356681Z","shell.execute_reply.started":"2024-12-04T23:53:11.347347Z","shell.execute_reply":"2024-12-04T23:53:11.355743Z"}},"outputs":[],"execution_count":83},{"cell_type":"code","source":"trained_model = train_model(\n    model=model,\n    criterion=criterion,\n    optimizer=optimizer,\n    scheduler=scheduler,\n    dataloaders=dataloaders,\n    dataset_sizes=dataset_sizes,\n    device=device,  # Ensure this is defined and passed correctly\n    num_epochs=config['epochs']\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T23:53:17.056306Z","iopub.execute_input":"2024-12-04T23:53:17.057019Z","iopub.status.idle":"2024-12-04T23:59:57.462366Z","shell.execute_reply.started":"2024-12-04T23:53:17.056980Z","shell.execute_reply":"2024-12-04T23:59:57.461235Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10\n----------\ntrain Loss: 0.4123 Acc: 0.8392\nval Loss: 0.4801 Acc: 0.8273\nEpoch 2/10\n----------\ntrain Loss: 0.4067 Acc: 0.8406\nval Loss: 0.5512 Acc: 0.8311\nEpoch 3/10\n----------\ntrain Loss: 0.3873 Acc: 0.8471\nval Loss: 0.3944 Acc: 0.8520\nEpoch 4/10\n----------\ntrain Loss: 0.3702 Acc: 0.8481\nval Loss: 0.3819 Acc: 0.8419\nEpoch 5/10\n----------\ntrain Loss: 0.3476 Acc: 0.8635\nval Loss: 0.3428 Acc: 0.8712\nEpoch 6/10\n----------\ntrain Loss: 0.3156 Acc: 0.8778\nval Loss: 0.3072 Acc: 0.8805\nEpoch 7/10\n----------\ntrain Loss: 0.2990 Acc: 0.8834\nval Loss: 0.2974 Acc: 0.8843\nEpoch 8/10\n----------\ntrain Loss: 0.2769 Acc: 0.8909\nval Loss: 0.2805 Acc: 0.8828\nEpoch 9/10\n----------\ntrain Loss: 0.2577 Acc: 0.8959\nval Loss: 0.2786 Acc: 0.8990\nEpoch 10/10\n----------\ntrain Loss: 0.2400 Acc: 0.9030\nval Loss: 0.2535 Acc: 0.9013\nTraining complete in 6m 40s\nBest val Acc: 0.901311\n","output_type":"stream"}],"execution_count":84},{"cell_type":"code","source":"# Assuming 'num_classes' is defined correctly elsewhere in your code\nimport torch\nimport numpy as np\nimport csv\nfrom torch.utils.data import DataLoader\n\nmodel.eval()  # Ensure the model is in evaluation mode\ndata_dir = \"/kaggle/working/\"\ntrainloader = DataLoader(image_datasets['train'], batch_size=config['batch_size'])\n\nf = open(data_dir + \"seresnet.csv\", 'w+', newline='')\nwriter = csv.writer(f)\n\n# Create a list to save filenames and an array to hold probabilities\nsaving = []\ntemp_array = np.zeros((len(trainloader.dataset), num_classes))  # Adjust array size to dataset size\n\ncorrect = 0\ntotal = 0\n\nwith torch.no_grad():\n    index = 0  # To track where to place results in temp_array\n    for images, labels in trainloader:\n        images = images.to(device)\n        labels = labels.to(device)\n\n        outputs = model(images)['out']\n        _, predicted = torch.max(outputs, 1)\n\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\n        prob = torch.nn.functional.softmax(outputs, dim=1)\n        for j in range(images.size(0)):  # Iterate over each item in the batch\n            saving.append(trainloader.dataset.samples[index][0].split('/')[-1])\n            temp_array[index] = prob[j].cpu().numpy()  # Store probabilities for each class\n            index += 1\n\n# Calculate and print train accuracy\ntrain_accuracy = (100 * correct / total)\nprint(\"Train Accuracy =\", train_accuracy)\n\n# Write to CSV\nfor i in range(len(saving)):\n    k = temp_array[i].tolist()\n    k.append(saving[i])\n    writer.writerow(k)\n\nf.close()\n\n# Optionally log accuracy to Weights & Biases\n# wandb.log({\"train_accuracy\": train_accuracy})\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T00:19:08.455622Z","iopub.execute_input":"2024-12-05T00:19:08.455967Z","iopub.status.idle":"2024-12-05T00:20:01.336726Z","shell.execute_reply.started":"2024-12-05T00:19:08.455938Z","shell.execute_reply":"2024-12-05T00:20:01.335763Z"}},"outputs":[{"name":"stdout","text":"Train Accuracy = 91.03528050896472\n","output_type":"stream"}],"execution_count":87},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport csv\nfrom torch.utils.data import DataLoader\n\n# Assuming the testloader and model are already defined and configured\nmodel.eval()  # Set the model to evaluation mode\n\n# Define the path for the CSV file and open it for writing\ndata_dir = \"/kaggle/working/\"  # Make sure this directory exists\nf = open(data_dir + \"seresnet_test.csv\", 'w+', newline='')\nwriter = csv.writer(f)\n\n# Initialize lists and counters for storing results and calculating accuracy\nsaving = []\ncorrect = 0\ntotal = 0\n\nwith torch.no_grad():\n    num = len(testloader.dataset)\n    temp_array = np.zeros((num, num_classes))  # Ensure dimensions are correct based on your `num_classes`\n\n    index = 0  # Track the index for proper placement in the temp_array\n    for i, (images, labels) in enumerate(testloader):\n        images, labels = images.to(device), labels.to(device)  # Move data to the correct device\n\n        outputs = model(images)['out']\n        _, predicted = torch.max(outputs.data, 1)\n\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\n        prob = torch.nn.functional.softmax(outputs, dim=1)\n        for j in range(images.size(0)):  # Handle batches with more than one image\n            saving.append(testloader.dataset.samples[index][0].split('/')[-1])\n            temp_array[index] = prob[j].cpu().numpy()  # Extract probabilities for each image\n            index += 1\n\n# Calculate and print the test accuracy\ntest_accuracy = (100 * correct / total)\nprint(\"Test Accuracy =\", test_accuracy)\n\n# Write the probabilities and filenames to the CSV file\nfor i in range(num):\n    k = temp_array[i].tolist()\n    k.append(saving[i])\n    writer.writerow(k)\n\n# Close the CSV file\nf.close()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T00:22:56.463183Z","iopub.execute_input":"2024-12-05T00:22:56.463532Z","iopub.status.idle":"2024-12-05T00:23:12.348296Z","shell.execute_reply.started":"2024-12-05T00:22:56.463501Z","shell.execute_reply":"2024-12-05T00:23:12.347336Z"}},"outputs":[{"name":"stdout","text":"Test Accuracy = 90.8754623921085\n","output_type":"stream"}],"execution_count":89},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# ResNet 152","metadata":{"id":"7wZ0_Qfo5f8q"}},{"cell_type":"markdown","source":"## Model Definition and Training\n\n\n\nThis section covers the instantiation of the ResNet152 model and its subsequent training with the dataset.","metadata":{"id":"c9302949"}},{"cell_type":"code","source":"# import torch.optim as optim\n# from torch.optim import lr_scheduler\n\n# # Criterion with class weights for handling imbalances\n# weights = torch.tensor([1.0, 4.7], device=DEVICE)  # Adjust weights as needed for your application\n# criterion = nn.CrossEntropyLoss(weight=weights)\n\n# # Optimizer\n# optimizer = optim.Adam(model.parameters(), lr=0.0001)\n\n# # Learning rate scheduler\n# scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import wandb\n# wandb.login(key = '889736f968fd287026464ea18bead25ea75991d4')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# config = {\n#     \"learning_rate\": 0.0001,\n#     \"epochs\": 10,\n#     \"batch_size\": 64,\n#     \"loss_function\": \"CrossEntropyLoss\",\n#     \"architecture\": \"SERESNET\",\n#     \"dataset\": \"Your Dataset Name\"\n# }\n# # Create your wandb run\n# run = wandb.init(\n#     name = \"SERESNET First\", ## Wandb creates random run names if you skip this field\n#     reinit = True, ### Allows reinitalizing runs when you re-run this cell\n#     # run_id = ### Insert specific run id here if you want to resume a previous run\n#     # resume = \"must\" ### You need this to resume previous runs, but comment out reinit = True when using this\n#     project = \"IDL_Project\", ### Project should be created in your wandb account\n#     config = config ### Wandb Config for your run\n# )","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # model = models.resnet152(pretrained = True)\n\n# #num_ftrs = model.classifier[0].in_features\n# model = Network().to(DEVICE)\n\n# num_ftrs = model.fc.in_features  ##for googlenet, resnet18\n\n# #num_ftrs = model.classifier.in_features  ## for densenet169\n\n# print(\"Number of features: \"+str(num_ftrs))\n\n# #model.classifier = nn.Linear(num_ftrs, num_classes) ## for vgg19\n\n# model.fc = nn.Linear(num_ftrs, num_classes)  ##for googlenet, resnet18\n\n# #model.classifier = nn.Linear(num_ftrs, num_classes) ## for densenet169\n\n# model = model.to(device)\n\n# criterion = nn.CrossEntropyLoss( weight = torch.tensor([1, 4.7]).to(device))\n\n# # Observe that all parameters are being optimized\n\n# optimizer = optim.Adam(model.parameters(), lr=0.0001)\n\n# # StepLR Decays the learning rate of each parameter group by gamma every step_size epochs\n\n# # Decay LR by a factor of 0.1 every 7 epochs\n\n# # Learning rate scheduling should be applied after optimizer’s update\n\n# # e.g., you should write your code this way:\n\n# # for epoch in range(100):\n\n# #     train(...)\n\n# #     validate(...)\n\n# #     scheduler.step()\n\n# step_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size = 10, gamma=0.1)\n\n# model = train_model(model, criterion, optimizer, step_lr_scheduler, num_epochs=10, model_name = \"SeResnet\")","metadata":{"id":"pSghfYK5wXwK","colab":{"base_uri":"https://localhost:8080/"},"outputId":"3a22ec82-afd6-42c3-b3ce-51350c06fbc1","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Getting Proba distribution\n\n# print(\"\\nGetting the Probability Distribution\")\n\n# trainloader=torch.utils.data.DataLoader(image_datasets['train'],batch_size=1)\n\n# testloader=torch.utils.data.DataLoader(image_datasets['test'],batch_size=1)\n\n# model=model.eval()\n\n# import csv\n\n# import numpy as np  # Importing NumPy for numerical operations","metadata":{"id":"vGn8_Nw1wXy6","colab":{"base_uri":"https://localhost:8080/"},"outputId":"379b5c39-ec1b-46f0-a36e-bea1d4af2775","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# def train_model(model, criterion, optimizer, scheduler, num_epochs=25,model_name = \"kaggle\"):\n\n#     since = time.time()\n\n#     best_model_wts = copy.deepcopy(model.state_dict())\n\n#     best_acc = 0.0\n\n#     for epoch in range(num_epochs):\n\n#         print('Epoch {}/{}'.format(epoch+1, num_epochs))\n\n#         print('-' * 10)\n\n#         # Each epoch has a training and validation phase\n\n#         for phase in ['train', 'val']:\n\n#             if phase == 'train':\n\n#                 model.train()  # Set model to training mode\n\n#             else:\n\n#                 model.eval()   # Set model to evaluate mode\n\n#             running_loss = 0.0\n\n#             running_corrects = 0\n\n#             # Iterate over data.\n\n#             for inputs, labels in dataloaders[phase]:\n\n#                 inputs = inputs.to(device)\n\n#                 labels = labels.to(device)\n\n#                 # forward\n\n#                 # track history if only in train\n\n#                 with torch.set_grad_enabled(phase == 'train'):\n\n#                     outputs = model(inputs)\n\n#                     _, preds = torch.max(outputs, 1) #was (outputs,1) for non-inception and (outputs.data,1) for inception\n\n#                     loss = criterion(outputs, labels)\n\n#                     # backward + optimize only if in training phase\n\n#                     if phase == 'train':\n\n#                         optimizer.zero_grad()\n\n#                         loss.backward()\n\n#                         optimizer.step()\n\n#                 # statistics\n\n#                 running_loss += loss.item() * inputs.size(0)\n\n#                 running_corrects += torch.sum(preds == labels.data)\n\n#             if phase == 'train':\n\n#                 scheduler.step()\n\n#             epoch_loss = running_loss / dataset_sizes[phase]\n\n#             epoch_acc = running_corrects.double() / dataset_sizes[phase]\n\n#             if phase == 'train':\n\n#               train_loss_gph.append(epoch_loss)\n\n#               train_acc_gph.append(epoch_acc)\n\n#             if phase == 'val':\n\n#               val_loss_gph.append(epoch_loss)\n\n#               val_acc_gph.append(epoch_acc)\n\n#            # plot(val_loss_gph,train_loss_gph, \"Loss\")\n\n#           #  plot(val_acc_gph,train_acc_gph, \"Accuracy\")\n\n#             print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n\n#                 phase, epoch_loss, epoch_acc))\n\n#             # deep copy the model\n\n#             if phase == 'val' and epoch_acc >= best_acc:\n\n#                 best_acc = epoch_acc\n\n#                 best_model_wts = copy.deepcopy(model.state_dict())\n\n#                 torch.save(model, data_dir+\"/\"+model_name+\".h5\")\n\n#                 print('==>Model Saved')\n\n#         print()\n\n#     time_elapsed = time.time() - since\n\n#     print('Training complete in {:.0f}m {:.0f}s'.format(\n\n#         time_elapsed // 60, time_elapsed % 60))\n\n#     print('Best val Acc: {:4f}'.format(best_acc))\n\n#     # load best model weights\n\n#     model.load_state_dict(best_model_wts)\n\n#     return model","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Train the Model\n# trained_model = train_model(\n#     model=model,\n#     criterion=criterion,\n#     optimizer=optimizer,\n#     scheduler=scheduler,\n#     dataloaders=dataloaders,  # Correctly passed here\n#     dataset_sizes=dataset_sizes,\n#     device=device,  # Correctly passed here\n#     num_epochs=10\n# )","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import torch\n# from torch.utils.data import DataLoader\n# import numpy as np\n# import csv\n\n# # Define data loaders\n# trainloader = DataLoader(image_datasets['train'], batch_size=config['batch_size'])\n# testloader = DataLoader(image_datasets['test'], batch_size=config['batch_size'])\n\n# # Model evaluation\n# model.eval()\n# # Correct directory path for writable access\n# data_dir = \"/kaggle/working/\"\n\n# # Attempt to open a file for writing in a writable directory\n# f = open(data_dir + \"seresnet.csv\", 'w+', newline='')\n# writer = csv.writer(f)\n# saving = []\n# correct = 0\n# total = 0\n\n# # Proceed with your existing code...\n\n\n# with torch.no_grad():\n#     temp_array = np.zeros((len(trainloader), num_classes))\n#     for i, data in enumerate(trainloader):\n#         images, labels = data\n#         labels = labels.to(DEVICE)\n#         outputs = model(images.to(DEVICE))['out']\n#         _, predicted = torch.max(outputs, 1)\n#         # outputs = model(images.to(DEVICE))['out']  # Directly access the 'out' tensor from the dictionary\n#     \t# _, predicted = torch.max(outputs, 1)\n#         total += labels.size(0)\n#         correct += (predicted == labels).sum().item()\n\n#         # Calculate probabilities\n#         prob = torch.nn.functional.softmax(outputs, dim=1)\n#         saving.append(trainloader.dataset.samples[i][0].split('/')[-1])\n#         temp_array[i] = np.asarray(prob[0].tolist()[0:num_classes])\n\n#         # Log batch accuracy to wandb\n#         wandb.log({\"batch_accuracy\": (predicted == labels).float().mean().item()})\n\n# train_accuracy = 100 * correct / total\n# print(\"Train Accuracy =\", train_accuracy)\n\n# # Log overall train accuracy to wandb\n# wandb.log({\"train_accuracy\": train_accuracy})\n\n# for i in range(len(trainloader)):\n#     k = temp_array[i].tolist()\n#     k.append(saving[i])\n#     writer.writerow(k)\n\n# f.close()\n\n# # Log model and close wandb run\n# wandb.watch(model, log=\"all\", log_freq=10)\n# run.finish()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# f = open(data_dir+\"/resnet152_train.csv\",'w+',newline = '')\n\n# writer = csv.writer(f)\n\n# saving = []\n\n# correct = 0\n\n# total = 0\n\n# with torch.no_grad():\n\n#       num = 0\n\n#       temp_array = np.zeros((len(trainloader),num_classes))\n\n#       for i,data in enumerate(trainloader):\n\n#           images, labels = data\n\n#           sample_fname, _ = trainloader.dataset.samples[i]\n\n#           labels=labels.cuda()\n\n#           outputs = model(images.cuda())\n\n#           _, predicted = torch.max(outputs, 1)\n\n#           total += labels.size(0)\n\n#           correct += (predicted == labels.cuda()).sum().item()\n\n#           prob = torch.nn.functional.softmax(outputs, dim=1)\n\n#           saving.append(sample_fname.split('/')[-1])\n\n#           temp_array[num] = np.asarray(prob[0].tolist()[0:num_classes])\n\n#           num+=1\n\n# print(\"Train Accuracy = \",100*correct/total)\n\n# for i in range(len(trainloader)):\n\n#   k = temp_array[i].tolist()\n\n#   k.append(saving[i])\n\n#   writer.writerow(k)\n\n# f.close()\n\n# f = open(data_dir+\"/train_labels.csv\",'w+',newline = '')\n\n# writer = csv.writer(f)\n\n# for i,data in enumerate(trainloader):\n\n#   _, labels = data\n\n#   sample_fname, _ = trainloader.dataset.samples[i]\n\n#   sample = sample_fname.split('/')[-1]\n\n#   lab = labels.tolist()[0]\n\n#   writer.writerow([sample,lab])\n\n# f.close()\n\n\n# ====================\n\n\n# import csv\n\n# import numpy as np\n\n# import torch\n\n\n\n# # Open file for writing predicted probabilities\n\n# f = open(save_dir + \"/resnet152_train.csv\", 'w+', newline='')\n\n# writer = csv.writer(f)\n\n# saving = []  # To store filenames\n\n# correct = 0  # To count correct predictions\n\n# total = 0    # To count total samples\n\n\n\n# with torch.no_grad():\n\n#     num = 0\n\n#     temp_array = np.zeros((len(trainloader), num_classes))  # Array to store probabilities\n\n\n\n#     # Loop through training data\n\n#     for i, data in enumerate(trainloader):\n\n#         images, labels = data\n\n#         sample_fname, _ = trainloader.dataset.samples[i]  # Get filename\n\n#         labels = labels.cuda()  # Move labels to GPU\n\n#         outputs = model(images.cuda())  # Get model predictions\n\n\n\n#         # Calculate predicted class and accumulate accuracy metrics\n\n#         _, predicted = torch.max(outputs, 1)\n\n#         total += labels.size(0)\n\n#         correct += (predicted == labels).sum().item()\n\n\n\n#         # Calculate probabilities using softmax and store filename and probabilities\n\n#         prob = torch.nn.functional.softmax(outputs, dim=1)\n\n#         saving.append(sample_fname.split('/')[-1])\n\n#         temp_array[num] = np.asarray(prob[0].tolist()[:num_classes])  # Store probabilities\n\n#         num += 1\n\n\n\n# # Calculate and print training accuracy\n\n# print(\"Train Accuracy = \", 100 * correct / total)\n\n\n\n# # Write predicted probabilities to CSV\n\n# for i in range(len(trainloader)):\n\n#     row = temp_array[i].tolist()  # Convert probabilities to list\n\n#     row.append(saving[i])         # Append filename\n\n#     writer.writerow(row)           # Write row to CSV\n\n# f.close()  # Close the file\n\n\n\n# # Open file for writing true labels\n\n# f = open(save_dir + \"/train_labels.csv\", 'w+', newline='')\n\n# writer = csv.writer(f)\n\n\n\n# # Loop through training data to get labels\n\n# for i, data in enumerate(trainloader):\n\n#     _, labels = data\n\n#     sample_fname, _ = trainloader.dataset.samples[i]  # Get filename\n\n#     sample = sample_fname.split('/')[-1]  # Extract filename from path\n\n#     lab = labels.tolist()[0]              # Get label as integer\n\n#     writer.writerow([sample, lab])         # Write filename and label to CSV\n\n# f.close()  # Close the file\n","metadata":{"id":"vc-8RBcowX1r","colab":{"base_uri":"https://localhost:8080/"},"outputId":"76e4427c-4082-49fc-8c24-c250bd6ce965","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# #Test Probabilities\n\n# f = open(data_dir+\"/resnet152_test.csv\",'w+',newline = '')\n\n# writer = csv.writer(f)\n\n# saving = []\n\n# correct = 0\n\n# total = 0\n\n# with torch.no_grad():\n\n#       num = 0\n\n#       temp_array = np.zeros((len(testloader),num_classes))\n\n#       for i,data in enumerate(testloader):\n\n#           images, labels = data\n\n#           sample_fname, _ = testloader.dataset.samples[i]\n\n#           labels=labels.cuda()\n\n#           outputs = model(images.cuda())\n\n#           _, predicted = torch.max(outputs, 1)\n\n#           total += labels.size(0)\n\n#           correct += (predicted == labels.cuda()).sum().item()\n\n#           prob = torch.nn.functional.softmax(outputs, dim=1)\n\n#           saving.append(sample_fname.split('/')[-1])\n\n#           temp_array[num] = np.asarray(prob[0].tolist()[0:num_classes])\n\n#           num+=1\n\n# print(\"Test Accuracy = \",100*correct/total)\n\n# for i in range(len(testloader)):\n\n#   k = temp_array[i].tolist()\n\n#   k.append(saving[i])\n\n#   writer.writerow(k)\n\n# f.close()\n\n# f = open(data_dir+\"/test_labels.csv\",'w+',newline = '')\n\n# writer = csv.writer(f)\n\n# for i,data in enumerate(testloader):\n\n#   _, labels = data\n\n#   sample_fname, _ = testloader.dataset.samples[i]\n\n#   sample = sample_fname.split('/')[-1]\n\n#   lab = labels.tolist()[0]\n\n#   writer.writerow([sample,lab])\n\n# f.close()\n\n\n# #=====================\n\n\n# # import csv\n\n# # import numpy as np\n\n# # import torch\n\n\n\n# # # Test Probabilities\n\n# # f = open(save_dir + \"/resnet152_test.csv\", 'w+', newline='')\n\n# # writer = csv.writer(f)\n\n# # saving = []\n\n# # correct = 0\n\n# # total = 0\n\n\n\n# # with torch.no_grad():\n\n# #     num = 0\n\n# #     temp_array = np.zeros((len(testloader), num_classes))\n\n\n\n# #     # Loop through test data\n\n# #     for i, data in enumerate(testloader):\n\n# #         images, labels = data\n\n# #         sample_fname, _ = testloader.dataset.samples[i]  # Get filename\n\n# #         labels = labels.cuda()  # Move labels to GPU\n\n# #         outputs = model(images.cuda())  # Get model predictions\n\n\n\n# #         # Calculate predicted class and accumulate accuracy metrics\n\n# #         _, predicted = torch.max(outputs, 1)\n\n# #         total += labels.size(0)\n\n# #         correct += (predicted == labels).sum().item()\n\n\n\n# #         # Calculate probabilities using softmax and store filename and probabilities\n\n# #         prob = torch.nn.functional.softmax(outputs, dim=1)\n\n# #         saving.append(sample_fname.split('/')[-1])\n\n# #         temp_array[num] = np.asarray(prob[0].tolist()[:num_classes])  # Store probabilities\n\n# #         num += 1\n\n\n\n# # # Calculate and print test accuracy\n\n# # print(\"Test Accuracy = \", 100 * correct / total)\n\n\n\n# # # Write predicted probabilities to CSV\n\n# # for i in range(len(testloader)):\n\n# #     row = temp_array[i].tolist()  # Convert probabilities to list\n\n# #     row.append(saving[i])         # Append filename\n\n# #     writer.writerow(row)           # Write row to CSV\n\n# # f.close()  # Close the file\n\n\n\n# # # Open file for writing true labels\n\n# # f = open(save_dir + \"/test_labels.csv\", 'w+', newline='')\n\n# # writer = csv.writer(f)\n\n\n\n# # # Loop through test data to get labels\n\n# # for i, data in enumerate(testloader):\n\n# #     _, labels = data\n\n# #     sample_fname, _ = testloader.dataset.samples[i]  # Get filename\n\n# #     sample = sample_fname.split('/')[-1]  # Extract filename from path\n\n# #     lab = labels.tolist()[0]              # Get label as integer\n\n# #     writer.writerow([sample, lab])         # Write filename and label to CSV\n\n# # f.close()  # Close the file\n","metadata":{"id":"n1DjIkdPwX4O","colab":{"base_uri":"https://localhost:8080/"},"outputId":"0db763c7-aba7-4ede-9013-4efd36ee294e","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Inception V3","metadata":{"id":"E5Sz8Gm3K7oO"}},{"cell_type":"markdown","source":"## Inception V3 Model\n\n\n\nFollowing the pattern of the previous section, this part focuses on the Inception V3 model, its setup, and training.","metadata":{"id":"fb03cdc6"}},{"cell_type":"code","source":"# # model = models.inception_v3(pretrained = True)\n\n# # model.aux_logits = False\n\n# # # Handle the auxilary net\n\n# # num_ftrs = model.AuxLogits.fc.in_features\n\n# # model.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n\n# # # Handle the primary net\n\n# # num_ftrs = model.fc.in_features\n\n# # model.fc = nn.Linear(num_ftrs,num_classes)\n\n# # print(\"Number of features: \"+str(num_ftrs))\n\n# # #model.classifier = nn.Linear(num_ftrs, num_classes) ## for vgg19\n\n# # model.fc = nn.Linear(num_ftrs, num_classes)  ##for googlenet, resnet18\n\n# # #model.classifier = nn.Linear(num_ftrs, num_classes) ## for densenet169\n\n# # model = model.to(device)\n\n# # criterion = nn.CrossEntropyLoss( weight = torch.tensor([1, 4.7]).to(device))\n\n# # # Observe that all parameters are being optimized\n\n# # optimizer = optim.Adam(model.parameters(), lr=0.0001)\n\n# # # StepLR Decays the learning rate of each parameter group by gamma every step_size epochs\n\n# # # Decay LR by a factor of 0.1 every 7 epochs\n\n# # # Learning rate scheduling should be applied after optimizer’s update\n\n# # # e.g., you should write your code this way:\n\n# # # for epoch in range(100):\n\n# # #     train(...)\n\n# # #     validate(...)\n\n# # #     scheduler.step()\n\n# # step_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size = 10, gamma=0.1)\n\n# # model = train_model(model, criterion, optimizer, step_lr_scheduler, num_epochs=10, model_name = \"inception_v3\")\n\n\n\n# from torchvision import transforms\n\n\n\n# data_transforms = {\n\n#     'train': transforms.Compose([\n\n#         transforms.Resize((299, 299)),  # Resize images to 299x299 for Inception v3\n\n#         transforms.ToTensor(),\n\n#         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n\n#     ]),\n\n#     'val': transforms.Compose([\n\n#         transforms.Resize((299, 299)),  # Resize images to 299x299 for Inception v3\n\n#         transforms.ToTensor(),\n\n#         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n\n#     ]),\n\n#     'test': transforms.Compose([\n\n#         transforms.Resize((299, 299)),  # Resize images to 299x299 for Inception v3\n\n#         transforms.ToTensor(),\n\n#         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n\n#     ]),\n\n# }\n","metadata":{"id":"Qs1MXn4oL4oO","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import csv\n\n# import numpy as np\n\n# # Getting Proba distribution\n\n# print(\"\\nGetting the Probability Distribution\")\n\n# trainloader=torch.utils.data.DataLoader(image_datasets['train'],batch_size=1)\n\n# testloader=torch.utils.data.DataLoader(image_datasets['test'],batch_size=1)\n\n# model=model.eval()","metadata":{"id":"dmh_rbxbMVQy","colab":{"base_uri":"https://localhost:8080/"},"outputId":"9e500838-d7e0-44a8-a840-61612140f165","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# f = open(data_dir+\"/inception_v3_train.csv\",'w+',newline = '')\n\n# writer = csv.writer(f)\n\n# saving = []\n\n# correct = 0\n\n# total = 0\n\n# with torch.no_grad():\n\n#       num = 0\n\n#       temp_array = np.zeros((len(trainloader),num_classes))\n\n#       for i,data in enumerate(trainloader):\n\n#           images, labels = data\n\n#           sample_fname, _ = trainloader.dataset.samples[i]\n\n#           labels=labels.cuda()\n\n#           outputs = model(images.cuda())\n\n#           _, predicted = torch.max(outputs, 1)\n\n#           total += labels.size(0)\n\n#           correct += (predicted == labels.cuda()).sum().item()\n\n#           prob = torch.nn.functional.softmax(outputs, dim=1)\n\n#           saving.append(sample_fname.split('/')[-1])\n\n#           temp_array[num] = np.asarray(prob[0].tolist()[0:num_classes])\n\n#           num+=1\n\n# print(\"Train Accuracy = \",100*correct/total)\n\n# for i in range(len(trainloader)):\n\n#   k = temp_array[i].tolist()\n\n#   k.append(saving[i])\n\n#   writer.writerow(k)\n\n# f.close()\n\n# f = open(data_dir+\"/train_labels.csv\",'w+',newline = '')\n\n# writer = csv.writer(f)\n\n# for i,data in enumerate(trainloader):\n\n#   _, labels = data\n\n#   sample_fname, _ = trainloader.dataset.samples[i]\n\n#   sample = sample_fname.split('/')[-1]\n\n#   lab = labels.tolist()[0]\n\n#   writer.writerow([sample,lab])\n\n# f.close()\n\n\n\n# # ===============\n\n# # import csv\n\n# # import numpy as np\n\n# # import torch\n\n\n\n# # # Inception_v3 Train Probabilities\n\n# # f = open(save_dir + \"/inception_v3_train.csv\", 'w+', newline='')\n\n# # writer = csv.writer(f)\n\n# # saving = []\n\n# # correct = 0\n\n# # total = 0\n\n\n\n# # with torch.no_grad():\n\n# #     num = 0\n\n# #     temp_array = np.zeros((len(trainloader), num_classes))\n\n\n\n# #     # Loop through training data\n\n# #     for i, data in enumerate(trainloader):\n\n# #         images, labels = data\n\n# #         sample_fname, _ = trainloader.dataset.samples[i]  # Get filename\n\n# #         labels = labels.cuda()  # Move labels to GPU\n\n# #         outputs = model(images.cuda())  # Get model predictions\n\n\n\n# #         # Calculate predicted class and accumulate accuracy metrics\n\n# #         _, predicted = torch.max(outputs, 1)\n\n# #         total += labels.size(0)\n\n# #         correct += (predicted == labels).sum().item()\n\n\n\n# #         # Calculate probabilities using softmax and store filename and probabilities\n\n# #         prob = torch.nn.functional.softmax(outputs, dim=1)\n\n# #         saving.append(sample_fname.split('/')[-1])\n\n# #         temp_array[num] = np.asarray(prob[0].tolist()[:num_classes])  # Store probabilities\n\n# #         num += 1\n\n\n\n# # # Calculate and print train accuracy\n\n# # print(\"Train Accuracy = \", 100 * correct / total)\n\n\n\n# # # Write predicted probabilities to CSV\n\n# # for i in range(len(trainloader)):\n\n# #     row = temp_array[i].tolist()  # Convert probabilities to list\n\n# #     row.append(saving[i])         # Append filename\n\n# #     writer.writerow(row)           # Write row to CSV\n\n# # f.close()  # Close the file\n\n\n\n# # # Open file for writing true labels\n\n# # f = open(save_dir + \"/train_labels.csv\", 'w+', newline='')\n\n# # writer = csv.writer(f)\n\n\n\n# # # Loop through training data to get labels\n\n# # for i, data in enumerate(trainloader):\n\n# #     _, labels = data\n\n# #     sample_fname, _ = trainloader.dataset.samples[i]  # Get filename\n\n# #     sample = sample_fname.split('/')[-1]  # Extract filename from path\n\n# #     lab = labels.tolist()[0]              # Get label as integer\n\n# #     writer.writerow([sample, lab])         # Write filename and label to CSV\n\n# # f.close()  # Close the file\n","metadata":{"id":"PyQeUPZyMYY0","colab":{"base_uri":"https://localhost:8080/"},"outputId":"8ad8564a-53b5-469d-9375-29bd3a6a9d90","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# #Test Probabilities\n\n# f = open(data_dir+\"/inception_v3_test.csv\",'w+',newline = '')\n\n# writer = csv.writer(f)\n\n# saving = []\n\n# correct = 0\n\n# total = 0\n\n# with torch.no_grad():\n\n#       num = 0\n\n#       temp_array = np.zeros((len(testloader),num_classes))\n\n#       for i,data in enumerate(testloader):\n\n#           images, labels = data\n\n#           sample_fname, _ = testloader.dataset.samples[i]\n\n#           labels=labels.cuda()\n\n#           outputs = model(images.cuda())\n\n#           _, predicted = torch.max(outputs, 1)\n\n#           total += labels.size(0)\n\n#           correct += (predicted == labels.cuda()).sum().item()\n\n#           prob = torch.nn.functional.softmax(outputs, dim=1)\n\n#           saving.append(sample_fname.split('/')[-1])\n\n#           temp_array[num] = np.asarray(prob[0].tolist()[0:num_classes])\n\n#           num+=1\n\n# print(\"Test Accuracy = \",100*correct/total)\n\n# for i in range(len(testloader)):\n\n#   k = temp_array[i].tolist()\n\n#   k.append(saving[i])\n\n#   writer.writerow(k)\n\n# f.close()\n\n# f = open(data_dir+\"/test_labels.csv\",'w+',newline = '')\n\n# writer = csv.writer(f)\n\n# for i,data in enumerate(testloader):\n\n#   _, labels = data\n\n#   sample_fname, _ = testloader.dataset.samples[i]\n\n#   sample = sample_fname.split('/')[-1]\n\n#   lab = labels.tolist()[0]\n\n#   writer.writerow([sample,lab])\n\n# f.close()\n\n\n# # ====================\n\n\n\n\n\n# # import csv\n\n# # import numpy as np\n\n# # import torch\n\n\n\n# # # Inception_v3 Test Probabilities\n\n# # f = open(save_dir + \"/inception_v3_test.csv\", 'w+', newline='')\n\n# # writer = csv.writer(f)\n\n# # saving = []\n\n# # correct = 0\n\n# # total = 0\n\n\n\n# # with torch.no_grad():\n\n# #     num = 0\n\n# #     temp_array = np.zeros((len(testloader), num_classes))\n\n\n\n# #     # Loop through test data\n\n# #     for i, data in enumerate(testloader):\n\n# #         images, labels = data\n\n# #         sample_fname, _ = testloader.dataset.samples[i]  # Get filename\n\n# #         labels = labels.cuda()  # Move labels to GPU\n\n# #         outputs = model(images.cuda())  # Get model predictions\n\n\n\n# #         # Calculate predicted class and accumulate accuracy metrics\n\n# #         _, predicted = torch.max(outputs, 1)\n\n# #         total += labels.size(0)\n\n# #         correct += (predicted == labels).sum().item()\n\n\n\n# #         # Calculate probabilities using softmax and store filename and probabilities\n\n# #         prob = torch.nn.functional.softmax(outputs, dim=1)\n\n# #         saving.append(sample_fname.split('/')[-1])\n\n# #         temp_array[num] = np.asarray(prob[0].tolist()[:num_classes])  # Store probabilities\n\n# #         num += 1\n\n\n\n# # # Calculate and print test accuracy\n\n# # print(\"Test Accuracy = \", 100 * correct / total)\n\n\n\n# # # Write predicted probabilities to CSV\n\n# # for i in range(len(testloader)):\n\n# #     row = temp_array[i].tolist()  # Convert probabilities to list\n\n# #     row.append(saving[i])         # Append filename\n\n# #     writer.writerow(row)           # Write row to CSV\n\n# # f.close()  # Close the file\n\n\n\n# # # Open file for writing true labels\n\n# # f = open(save_dir + \"/test_labels.csv\", 'w+', newline='')\n\n# # writer = csv.writer(f)\n\n\n\n# # # Loop through test data to get labels\n\n# # for i, data in enumerate(testloader):\n\n# #     _, labels = data\n\n# #     sample_fname, _ = testloader.dataset.samples[i]  # Get filename\n\n# #     sample = sample_fname.split('/')[-1]  # Extract filename from path\n\n# #     lab = labels.tolist()[0]              # Get label as integer\n\n# #     writer.writerow([sample, lab])         # Write filename and label to CSV\n\n# # f.close()  # Close the file\n","metadata":{"id":"JV1bWRWrMZRD","colab":{"base_uri":"https://localhost:8080/"},"outputId":"90464e65-a538-4a43-92c4-9c72c2e56738","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Densenet 169","metadata":{"id":"xpFGud4Y5mz3"}},{"cell_type":"markdown","source":"\n\n\n\n## Densenet 169  Model\n\n\n\nFollowing the pattern of the previous section, this part focuses on the Densenet 169 model, its setup, and training.","metadata":{"id":"IeHrwVuZTZ4c"}},{"cell_type":"code","source":"# model = models.densenet169(pretrained = True)\n\n# #num_ftrs = model.classifier[0].in_features\n\n# #num_ftrs = model.fc.in_features  ##for googlenet, resnet18\n\n# num_ftrs = model.classifier.in_features  ## for densenet169\n\n# print(\"Number of features: \"+str(num_ftrs))\n\n# #model.classifier = nn.Linear(num_ftrs, num_classes) ## for vgg19\n\n# #model.fc = nn.Linear(num_ftrs, num_classes)  ##for googlenet, resnet18\n\n# model.classifier = nn.Linear(num_ftrs, num_classes) ## for densenet169\n\n# model = model.to(device)\n\n# criterion = nn.CrossEntropyLoss( weight = torch.tensor([1, 4.7]).to(device))\n\n# # Observe that all parameters are being optimized\n\n# optimizer = optim.Adam(model.parameters(), lr=0.0001)\n\n# # StepLR Decays the learning rate of each parameter group by gamma every step_size epochs\n\n# # Decay LR by a factor of 0.1 every 7 epochs\n\n# # Learning rate scheduling should be applied after optimizer’s update\n\n# # e.g., you should write your code this way:\n\n# # for epoch in range(100):\n\n# #     train(...)\n\n# #     validate(...)\n\n# #     scheduler.step()\n\n# step_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size = 10, gamma=0.1)\n\n# model = train_model(model, criterion, optimizer, step_lr_scheduler, num_epochs=10, model_name = \"densenet169\")","metadata":{"id":"0xgJj2xGTarw","colab":{"base_uri":"https://localhost:8080/"},"outputId":"41a2b62b-b0ce-4139-eb11-148add281fac","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import csv\n\n# import numpy as np\n\n\n\n# # Getting Proba distribution\n\n# print(\"\\nGetting the Probability Distribution\")\n\n# trainloader=torch.utils.data.DataLoader(image_datasets['train'],batch_size=1)\n\n# testloader=torch.utils.data.DataLoader(image_datasets['test'],batch_size=1)\n\n# model=model.eval()\n","metadata":{"id":"Pqimg_IxUQjm","colab":{"base_uri":"https://localhost:8080/"},"outputId":"3e72704a-2b94-4fa1-8f9f-ddcbb19873a8","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# f = open(data_dir+\"/densenet169_train.csv\",'w+',newline = '')\n\n# writer = csv.writer(f)\n\n# saving = []\n\n# correct = 0\n\n# total = 0\n\n# with torch.no_grad():\n\n#       num = 0\n\n#       temp_array = np.zeros((len(trainloader),num_classes))\n\n#       for i,data in enumerate(trainloader):\n\n#           images, labels = data\n\n#           sample_fname, _ = trainloader.dataset.samples[i]\n\n#           labels=labels.cuda()\n\n#           outputs = model(images.cuda())\n\n#           _, predicted = torch.max(outputs, 1)\n\n#           total += labels.size(0)\n\n#           correct += (predicted == labels.cuda()).sum().item()\n\n#           prob = torch.nn.functional.softmax(outputs, dim=1)\n\n#           saving.append(sample_fname.split('/')[-1])\n\n#           temp_array[num] = np.asarray(prob[0].tolist()[0:num_classes])\n\n#           num+=1\n\n# print(\"Train Accuracy = \",100*correct/total)\n\n# for i in range(len(trainloader)):\n\n#   k = temp_array[i].tolist()\n\n#   k.append(saving[i])\n\n#   writer.writerow(k)\n\n# f.close()\n\n# f = open(data_dir+\"/train_labels.csv\",'w+',newline = '')\n\n# writer = csv.writer(f)\n\n# for i,data in enumerate(trainloader):\n\n#   _, labels = data\n\n#   sample_fname, _ = trainloader.dataset.samples[i]\n\n#   sample = sample_fname.split('/')[-1]\n\n#   lab = labels.tolist()[0]\n\n#   writer.writerow([sample,lab])\n\n# f.close()\n\n\n# # ================\n\n\n# # import csv\n\n# # import numpy as np\n\n# # import torch\n\n\n\n# # # DenseNet169 Train Probabilities\n\n# # f = open(save_dir + \"/densenet169_train.csv\", 'w+', newline='')\n\n# # writer = csv.writer(f)\n\n# # saving = []\n\n# # correct = 0\n\n# # total = 0\n\n\n\n# # with torch.no_grad():\n\n# #     num = 0\n\n# #     temp_array = np.zeros((len(trainloader), num_classes))\n\n\n\n# #     # Loop through training data\n\n# #     for i, data in enumerate(trainloader):\n\n# #         images, labels = data\n\n# #         sample_fname, _ = trainloader.dataset.samples[i]  # Get filename\n\n# #         labels = labels.cuda()  # Move labels to GPU\n\n# #         outputs = model(images.cuda())  # Get model predictions\n\n\n\n# #         # Calculate predicted class and accumulate accuracy metrics\n\n# #         _, predicted = torch.max(outputs, 1)\n\n# #         total += labels.size(0)\n\n# #         correct += (predicted == labels).sum().item()\n\n\n\n# #         # Calculate probabilities using softmax and store filename and probabilities\n\n# #         prob = torch.nn.functional.softmax(outputs, dim=1)\n\n# #         saving.append(sample_fname.split('/')[-1])\n\n# #         temp_array[num] = np.asarray(prob[0].tolist()[:num_classes])  # Store probabilities\n\n# #         num += 1\n\n\n\n# # # Calculate and print train accuracy\n\n# # print(\"Train Accuracy = \", 100 * correct / total)\n\n\n\n# # # Write predicted probabilities to CSV\n\n# # for i in range(len(trainloader)):\n\n# #     row = temp_array[i].tolist()  # Convert probabilities to list\n\n# #     row.append(saving[i])         # Append filename\n\n# #     writer.writerow(row)           # Write row to CSV\n\n# # f.close()  # Close the file\n\n\n\n# # # Open file for writing true labels\n\n# # f = open(save_dir + \"/train_labels.csv\", 'w+', newline='')\n\n# # writer = csv.writer(f)\n\n\n\n# # # Loop through training data to get labels\n\n# # for i, data in enumerate(trainloader):\n\n# #     _, labels = data\n\n# #     sample_fname, _ = trainloader.dataset.samples[i]  # Get filename\n\n# #     sample = sample_fname.split('/')[-1]  # Extract filename from path\n\n# #     lab = labels.tolist()[0]              # Get label as integer\n\n# #     writer.writerow([sample, lab])         # Write filename and label to CSV\n\n# # f.close()  # Close the file\n","metadata":{"id":"D79oEFEVUM5j","colab":{"base_uri":"https://localhost:8080/"},"outputId":"910fa914-4bc1-4b7e-edfd-34b2b5049ae7","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# #Test Probabilities\n\n# f = open(data_dir+\"/densenet169_test.csv\",'w+',newline = '')\n\n# writer = csv.writer(f)\n\n# saving = []\n\n# correct = 0\n\n# total = 0\n\n# with torch.no_grad():\n\n#       num = 0\n\n#       temp_array = np.zeros((len(testloader),num_classes))\n\n#       for i,data in enumerate(testloader):\n\n#           images, labels = data\n\n#           sample_fname, _ = testloader.dataset.samples[i]\n\n#           labels=labels.cuda()\n\n#           outputs = model(images.cuda())\n\n#           _, predicted = torch.max(outputs, 1)\n\n#           total += labels.size(0)\n\n#           correct += (predicted == labels.cuda()).sum().item()\n\n#           prob = torch.nn.functional.softmax(outputs, dim=1)\n\n#           saving.append(sample_fname.split('/')[-1])\n\n#           temp_array[num] = np.asarray(prob[0].tolist()[0:num_classes])\n\n#           num+=1\n\n# print(\"Test Accuracy = \",100*correct/total)\n\n# for i in range(len(testloader)):\n\n#   k = temp_array[i].tolist()\n\n#   k.append(saving[i])\n\n#   writer.writerow(k)\n\n# f.close()\n\n# f = open(data_dir+\"/test_labels.csv\",'w+',newline = '')\n\n# writer = csv.writer(f)\n\n# for i,data in enumerate(testloader):\n\n#   _, labels = data\n\n#   sample_fname, _ = testloader.dataset.samples[i]\n\n#   sample = sample_fname.split('/')[-1]\n\n#   lab = labels.tolist()[0]\n\n#   writer.writerow([sample,lab])\n\n# f.close()\n\n\n# # ==================\n\n\n# # import csv\n\n# # import numpy as np\n\n# # import torch\n\n\n\n# # # DenseNet169 Test Probabilities\n\n# # f = open(save_dir + \"/densenet169_test.csv\", 'w+', newline='')\n\n# # writer = csv.writer(f)\n\n# # saving = []\n\n# # correct = 0\n\n# # total = 0\n\n\n\n# # with torch.no_grad():\n\n# #     num = 0\n\n# #     temp_array = np.zeros((len(testloader), num_classes))\n\n\n\n# #     # Loop through test data\n\n# #     for i, data in enumerate(testloader):\n\n# #         images, labels = data\n\n# #         sample_fname, _ = testloader.dataset.samples[i]  # Get filename\n\n# #         labels = labels.cuda()  # Move labels to GPU\n\n# #         outputs = model(images.cuda())  # Get model predictions\n\n\n\n# #         # Calculate predicted class and accumulate accuracy metrics\n\n# #         _, predicted = torch.max(outputs, 1)\n\n# #         total += labels.size(0)\n\n# #         correct += (predicted == labels).sum().item()\n\n\n\n# #         # Calculate probabilities using softmax and store filename and probabilities\n\n# #         prob = torch.nn.functional.softmax(outputs, dim=1)\n\n# #         saving.append(sample_fname.split('/')[-1])\n\n# #         temp_array[num] = np.asarray(prob[0].tolist()[:num_classes])  # Store probabilities\n\n# #         num += 1\n\n\n\n# # # Calculate and print test accuracy\n\n# # print(\"Test Accuracy = \", 100 * correct / total)\n\n\n\n# # # Write predicted probabilities to CSV\n\n# # for i in range(len(testloader)):\n\n# #     row = temp_array[i].tolist()  # Convert probabilities to list\n\n# #     row.append(saving[i])         # Append filename\n\n# #     writer.writerow(row)           # Write row to CSV\n\n# # f.close()  # Close the file\n\n\n\n# # # Open file for writing true labels\n\n# # f = open(save_dir + \"/test_labels.csv\", 'w+', newline='')\n\n# # writer = csv.writer(f)\n\n\n\n# # # Loop through test data to get labels\n\n# # for i, data in enumerate(testloader):\n\n# #     _, labels = data\n\n# #     sample_fname, _ = testloader.dataset.samples[i]  # Get filename\n\n# #     sample = sample_fname.split('/')[-1]  # Extract filename from path\n\n# #     lab = labels.tolist()[0]              # Get label as integer\n\n# #     writer.writerow([sample, lab])         # Write filename and label to CSV\n\n# # f.close()  # Close the file\n","metadata":{"id":"hIkkc94UUNog","colab":{"base_uri":"https://localhost:8080/"},"outputId":"2da44606-6d16-4437-eba2-007871eaa190","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Efficientnet B7 Model","metadata":{"id":"w2BmxFk25qt_"}},{"cell_type":"markdown","source":"## Efficientnet B7 Model\n\n\n\nFollowing the pattern of the previous section, this part focuses on the Efficientnet B7 model, its setup, and training.","metadata":{"id":"i-_BIBsS-Qcw"}},{"cell_type":"code","source":"# model = models.efficientnet_b7(pretrained = True)\n\n# #num_ftrs = model.classifier[0].in_features\n\n# #num_ftrs = model.fc.in_features  ##for googlenet, resnet18\n\n# #num_ftrs = model.classifier.in_features  ## for densenet169\n\n# num_ftrs = model.classifier[1].in_features   ## for efficientnet_b7\n\n# print(\"Number of features: \"+str(num_ftrs))\n\n# #model.classifier = nn.Linear(num_ftrs, num_classes) ## for vgg19\n\n# #model.fc = nn.Linear(num_ftrs, num_classes)  ##for googlenet, resnet18\n\n# model.classifier = nn.Linear(num_ftrs, num_classes) ## for densenet169, efficientnet_b7\n\n# model = model.to(device)\n\n# criterion = nn.CrossEntropyLoss( weight = torch.tensor([1, 4.7]).to(device))\n\n# # Observe that all parameters are being optimized\n\n# optimizer = optim.Adam(model.parameters(), lr=0.0001)\n\n# # StepLR Decays the learning rate of each parameter group by gamma every step_size epochs\n\n# # Decay LR by a factor of 0.1 every 7 epochs\n\n# # Learning rate scheduling should be applied after optimizer’s update\n\n# # e.g., you should write your code this way:\n\n# # for epoch in range(100):\n\n# #     train(...)\n\n# #     validate(...)\n\n# #     scheduler.step()\n\n# step_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size = 10, gamma=0.1)\n\n# model = train_model(model, criterion, optimizer, step_lr_scheduler, num_epochs=10, model_name = \"efficientnet_b7\")","metadata":{"id":"VjFMd7jC-Q4W","colab":{"base_uri":"https://localhost:8080/"},"outputId":"46f937b6-b6ff-4996-c448-ee8c1c7a9820","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import csv\n\n# import numpy as np\n\n# # Getting Proba distribution\n\n# print(\"\\nGetting the Probability Distribution\")\n\n# trainloader=torch.utils.data.DataLoader(image_datasets['train'],batch_size=1)\n\n# testloader=torch.utils.data.DataLoader(image_datasets['test'],batch_size=1)\n\n# model=model.eval()","metadata":{"id":"nhT4agZ7-Q7n","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ae0598d0-9c60-445e-bfe7-1366a4173d62","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# f = open(data_dir+\"/efficientnetb7_train.csv\",'w+',newline = '')\n\n# writer = csv.writer(f)\n\n# saving = []\n\n# correct = 0\n\n# total = 0\n\n# with torch.no_grad():\n\n#       num = 0\n\n#       temp_array = np.zeros((len(trainloader),num_classes))\n\n#       for i,data in enumerate(trainloader):\n\n#           images, labels = data\n\n#           sample_fname, _ = trainloader.dataset.samples[i]\n\n#           labels=labels.cuda()\n\n#           outputs = model(images.cuda())\n\n#           _, predicted = torch.max(outputs, 1)\n\n#           total += labels.size(0)\n\n#           correct += (predicted == labels.cuda()).sum().item()\n\n#           prob = torch.nn.functional.softmax(outputs, dim=1)\n\n#           saving.append(sample_fname.split('/')[-1])\n\n#           temp_array[num] = np.asarray(prob[0].tolist()[0:num_classes])\n\n#           num+=1\n\n# print(\"Train Accuracy = \",100*correct/total)\n\n# for i in range(len(trainloader)):\n\n#   k = temp_array[i].tolist()\n\n#   k.append(saving[i])\n\n#   writer.writerow(k)\n\n# f.close()\n\n# f = open(data_dir+\"/train_labels.csv\",'w+',newline = '')\n\n# writer = csv.writer(f)\n\n# for i,data in enumerate(trainloader):\n\n#   _, labels = data\n\n#   sample_fname, _ = trainloader.dataset.samples[i]\n\n#   sample = sample_fname.split('/')[-1]\n\n#   lab = labels.tolist()[0]\n\n#   writer.writerow([sample,lab])\n\n# f.close()\n\n\n# # ======================\n\n\n# # import csv\n\n# # import numpy as np\n\n# # import torch\n\n\n\n# # # EfficientNetB7 Train Probabilities\n\n# # f = open(save_dir + \"/efficientnetb7_train.csv\", 'w+', newline='')\n\n# # writer = csv.writer(f)\n\n# # saving = []\n\n# # correct = 0\n\n# # total = 0\n\n\n\n# # with torch.no_grad():\n\n# #     num = 0\n\n# #     temp_array = np.zeros((len(trainloader), num_classes))\n\n\n\n# #     # Loop through training data\n\n# #     for i, data in enumerate(trainloader):\n\n# #         images, labels = data\n\n# #         sample_fname, _ = trainloader.dataset.samples[i]  # Get filename\n\n# #         labels = labels.cuda()  # Move labels to GPU\n\n# #         outputs = model(images.cuda())  # Get model predictions\n\n\n\n# #         # Calculate predicted class and accumulate accuracy metrics\n\n# #         _, predicted = torch.max(outputs, 1)\n\n# #         total += labels.size(0)\n\n# #         correct += (predicted == labels).sum().item()\n\n\n\n# #         # Calculate probabilities using softmax and store filename and probabilities\n\n# #         prob = torch.nn.functional.softmax(outputs, dim=1)\n\n# #         saving.append(sample_fname.split('/')[-1])\n\n# #         temp_array[num] = np.asarray(prob[0].tolist()[:num_classes])  # Store probabilities\n\n# #         num += 1\n\n\n\n# # # Calculate and print train accuracy\n\n# # print(\"Train Accuracy = \", 100 * correct / total)\n\n\n\n# # # Write predicted probabilities to CSV\n\n# # for i in range(len(trainloader)):\n\n# #     row = temp_array[i].tolist()  # Convert probabilities to list\n\n# #     row.append(saving[i])         # Append filename\n\n# #     writer.writerow(row)           # Write row to CSV\n\n# # f.close()  # Close the file\n\n\n\n# # # Open file for writing true labels\n\n# # f = open(save_dir + \"/train_labels.csv\", 'w+', newline='')\n\n# # writer = csv.writer(f)\n\n\n\n# # # Loop through training data to get labels\n\n# # for i, data in enumerate(trainloader):\n\n# #     _, labels = data\n\n# #     sample_fname, _ = trainloader.dataset.samples[i]  # Get filename\n\n# #     sample = sample_fname.split('/')[-1]  # Extract filename from path\n\n# #     lab = labels.tolist()[0]              # Get label as integer\n\n# #     writer.writerow([sample, lab])         # Write filename and label to CSV\n\n# # f.close()  # Close the file\n","metadata":{"id":"_x6tAo7e_tWB","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b015e33f-764f-4b6e-b91c-49bd267576e4","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# #Test Probabilities\n\n# f = open(data_dir+\"/efficientnetb7_test.csv\",'w+',newline = '')\n\n# writer = csv.writer(f)\n\n# saving = []\n\n# correct = 0\n\n# total = 0\n\n# with torch.no_grad():\n\n#       num = 0\n\n#       temp_array = np.zeros((len(testloader),num_classes))\n\n#       for i,data in enumerate(testloader):\n\n#           images, labels = data\n\n#           sample_fname, _ = testloader.dataset.samples[i]\n\n#           labels=labels.cuda()\n\n#           outputs = model(images.cuda())\n\n#           _, predicted = torch.max(outputs, 1)\n\n#           total += labels.size(0)\n\n#           correct += (predicted == labels.cuda()).sum().item()\n\n#           prob = torch.nn.functional.softmax(outputs, dim=1)\n\n#           saving.append(sample_fname.split('/')[-1])\n\n#           temp_array[num] = np.asarray(prob[0].tolist()[0:num_classes])\n\n#           num+=1\n\n# print(\"Test Accuracy = \",100*correct/total)\n\n# for i in range(len(testloader)):\n\n#   k = temp_array[i].tolist()\n\n#   k.append(saving[i])\n\n#   writer.writerow(k)\n\n# f.close()\n\n# f = open(data_dir+\"/test_labels.csv\",'w+',newline = '')\n\n# writer = csv.writer(f)\n\n# for i,data in enumerate(testloader):\n\n#   _, labels = data\n\n#   sample_fname, _ = testloader.dataset.samples[i]\n\n#   sample = sample_fname.split('/')[-1]\n\n#   lab = labels.tolist()[0]\n\n#   writer.writerow([sample,lab])\n\n# f.close()\n\n\n# # ====================\n\n# # import csv\n\n# # import numpy as np\n\n# # import torch\n\n\n\n# # # EfficientNetB7 Test Probabilities\n\n# # f = open(save_dir + \"/efficientnetb7_test.csv\", 'w+', newline='')\n\n# # writer = csv.writer(f)\n\n# # saving = []\n\n# # correct = 0\n\n# # total = 0\n\n\n\n# # with torch.no_grad():\n\n# #     num = 0\n\n# #     temp_array = np.zeros((len(testloader), num_classes))\n\n\n\n# #     # Loop through test data\n\n# #     for i, data in enumerate(testloader):\n\n# #         images, labels = data\n\n# #         sample_fname, _ = testloader.dataset.samples[i]  # Get filename\n\n# #         labels = labels.cuda()  # Move labels to GPU\n\n# #         outputs = model(images.cuda())  # Get model predictions\n\n\n\n# #         # Calculate predicted class and accumulate accuracy metrics\n\n# #         _, predicted = torch.max(outputs, 1)\n\n# #         total += labels.size(0)\n\n# #         correct += (predicted == labels).sum().item()\n\n\n\n# #         # Calculate probabilities using softmax and store filename and probabilities\n\n# #         prob = torch.nn.functional.softmax(outputs, dim=1)\n\n# #         saving.append(sample_fname.split('/')[-1])\n\n# #         temp_array[num] = np.asarray(prob[0].tolist()[:num_classes])  # Store probabilities\n\n# #         num += 1\n\n\n\n# # # Calculate and print test accuracy\n\n# # print(\"Test Accuracy = \", 100 * correct / total)\n\n\n\n# # # Write predicted probabilities to CSV\n\n# # for i in range(len(testloader)):\n\n# #     row = temp_array[i].tolist()  # Convert probabilities to list\n\n# #     row.append(saving[i])         # Append filename\n\n# #     writer.writerow(row)           # Write row to CSV\n\n# # f.close()  # Close the file\n\n\n\n# # # Open file for writing true labels\n\n# # f = open(save_dir + \"/test_labels.csv\", 'w+', newline='')\n\n# # writer = csv.writer(f)\n\n\n\n# # # Loop through test data to get labels\n\n# # for i, data in enumerate(testloader):\n\n# #     _, labels = data\n\n# #     sample_fname, _ = testloader.dataset.samples[i]  # Get filename\n\n# #     sample = sample_fname.split('/')[-1]  # Extract filename from path\n\n# #     lab = labels.tolist()[0]              # Get label as integer\n\n# #     writer.writerow([sample, lab])         # Write filename and label to CSV\n\n# # f.close()  # Close the file\n","metadata":{"id":"411CiJvX_tYo","colab":{"base_uri":"https://localhost:8080/"},"outputId":"7c14f00f-1b82-4088-b776-6af7d61d8bc7","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Ensemble Learning Analysis","metadata":{"id":"T_wzB7pcMV7F"}},{"cell_type":"markdown","source":"## Imports","metadata":{"id":"F60vUT2KM9mh"}},{"cell_type":"code","source":"# !pip install scikit-plot","metadata":{"id":"xZAkFyiqq8Eb","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# !pip uninstall scipy -y","metadata":{"id":"ul3MAh6csWlV","colab":{"base_uri":"https://localhost:8080/"},"outputId":"70e5d4b6-f557-4ff3-fe36-da768cd02105","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# !pip install numpy==1.22.4 pandas==1.5.3 scipy==1.8.1","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"RlHr5ln6YwvD","outputId":"8d173398-ce98-49d3-9225-45a332894a6f","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# !pip uninstall scikit-plot -y\n\n# !pip install scikit-plot","metadata":{"id":"sVrkFN5lsXxW","colab":{"base_uri":"https://localhost:8080/"},"outputId":"174d425d-7ebb-4f5d-c1dd-007ecf76e509","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# !pip cache purge","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mB0O4DAyZ9PK","outputId":"580ddcb6-240e-464b-abea-c1021e09835e","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# !pip install --force-reinstall numpy==1.22.4 scipy==1.8.1","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":981},"id":"gI9cCar2asrQ","outputId":"71e22c01-3d97-4d90-bde9-e77a8d5032dd","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import pandas as pd\n\n# import numpy as np\n\n# from sklearn.metrics import *\n\n# import matplotlib.pyplot as plt\n\n# import math,os,argparse\n\n# from scikitplot.estimators import plot_feature_importances\n\n# from scikitplot.metrics import plot_confusion_matrix, plot_roc\n\n# from sklearn.metrics import roc_curve,auc\n\n# import matplotlib.pyplot as plt\n\n# from sklearn.preprocessing import label_binarize","metadata":{"id":"1yFTPabIM6cW","colab":{"base_uri":"https://localhost:8080/","height":106},"outputId":"e839e499-34a5-4bd3-ec8b-861258a9f744","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Data Loading","metadata":{"id":"_WIM3Au8NBPM"}},{"cell_type":"code","source":"parser.add_argument('--root_train', type=str, required = True, help='Directory where train csv files are stored')\n\nparser.add_argument('--train_labels', type=str, required = True, help='File path for train labels')\n\nparser.add_argument('--root_test', type=str, required = True, help='Directory where test csv files are stored')\n\nparser.add_argument('--test_labels', type=str, required = True, help='File path for test labels')\n\n    df = pd.read_csv(file,header=None)\n\n    df = pd.read_csv(file,header=None)","metadata":{"id":"lgJezXwONBi2","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Helper Functions","metadata":{"id":"CxHDVc1qNFtP"}},{"cell_type":"code","source":"def predicting(ensemble_prob):\n\n    prediction = np.zeros((ensemble_prob.shape[0],))\n\n    for i in range(ensemble_prob.shape[0]):\n\n        temp = ensemble_prob[i]\n\n        t = np.where(temp == np.max(temp))[0][0]\n\n        prediction[i] = t\n\n    return prediction\n\n\n\ndef getfile(filename):\n\n    root=\"./\"\n\n    file = root+filename\n\n    if '.csv' not in file:\n\n        file+='.csv'\n\n    df = pd.read_csv(file,header=None)\n\n    df = np.asarray(df)[:,:-1] #Since last column has image names\n\n    return df\n\n\n\ndef metrics(labels,predictions,classes):\n\n    print(\"Classification Report:\")\n\n    print(classification_report(labels, predictions, target_names = classes,digits = 4))\n\n    matrix = confusion_matrix(labels, predictions)\n\n    accuracy = accuracy_score(labels,predictions)\n\n    pre = precision_score(labels,predictions)\n\n    rec = recall_score(labels,predictions)\n\n    f1 = f1_score(labels,predictions)\n\n    auc = roc_auc_score(labels,predictions)\n\n    print(\"Accuracy\", accuracy)\n\n    print(\"Precision Score\", pre)\n\n    print(\"Recall Score\", rec)\n\n    print(\"F1 Score\", f1)\n\n    print(\"Roc_Auc Score\", auc)\n\n    print(\"Confusion matrix:\")\n\n    print(matrix)\n\n    print(\"\\nClasswise Accuracy :{}\".format(matrix.diagonal()/matrix.sum(axis = 1)))","metadata":{"id":"Vviab_TxNDuG","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Plot ROC Curve Function","metadata":{"id":"E7QrH7bjNMIX"}},{"cell_type":"code","source":"#ROC-AUC\n\nfrom sklearn.metrics import roc_curve,auc\n\nimport matplotlib.pyplot as plt\n\nfrom sklearn.preprocessing import label_binarize\n\n\n\ndef plot_roc(val_label,decision_val, caption='ROC Curve'):\n\n    num_classes=np.unique(val_label).shape[0]\n\n    classes = []\n\n    for i in range(num_classes):\n\n        classes.append(i)\n\n    plt.figure()\n\n    decision_val = label_binarize(decision_val, classes=classes)\n\n\n\n    if num_classes!=2:\n\n        # Compute ROC curve and ROC area for each class\n\n        fpr = dict()\n\n        tpr = dict()\n\n        roc_auc = dict()\n\n        for i in range(num_classes):\n\n            y_val = label_binarize(val_label, classes=classes)\n\n            fpr[i], tpr[i], _ = roc_curve(y_val[:, i], decision_val[:, i])\n\n            roc_auc[i] = auc(fpr[i], tpr[i])\n\n        for i in range(num_classes):\n\n            plt.plot(fpr[i], tpr[i], label='ROC curve of class {0} (area = {1:0.2f})'\n\n                                           ''.format(i+1, roc_auc[i]))\n\n    else:\n\n        fpr,tpr,_ = roc_curve(val_label,decision_val, pos_label=1)\n\n        roc_auc = auc(fpr,tpr)*100\n\n        plt.plot(fpr,tpr,label='ROC curve (AUC=%0.2f)'%roc_auc)\n\n\n\n    plt.plot([0, 1], [0, 1], 'k--')\n\n    plt.xlim([0.0, 1.0])\n\n    plt.ylim([0.0, 1.05])\n\n    plt.xlabel('False Positive Rate')\n\n    plt.ylabel('True Positive Rate')\n\n    plt.title(caption)\n\n    plt.legend(loc=\"lower right\")\n\n    plt.savefig(str(len(classes))+'RE_NAME.png',dpi=300)\n\n\n\n\n\n#plot_roc(test_labels,preds_Adjusted)\n\nplot_roc(test_labels,preds_original)","metadata":{"id":"7jQLF1IaNSKt","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Analysis\n","metadata":{"id":"zUooQ98FNsVP"}},{"cell_type":"code","source":"# Function to calculate scores for each model\n\ndef get_scores(labels, *models_predictions):\n\n    \"\"\"\n\n    Calculates precision, recall, f1-score, and AUC for each model's predictions.\n\n\n\n    :param labels: The ground truth labels.\n\n    :param models_predictions: Variable number of arrays with model predictions.\n\n    :return: A list of weights for each set of model predictions.\n\n    \"\"\"\n\n    num_models = len(models_predictions)\n\n    # Initialize metrics array\n\n    metrics = np.zeros((2, num_models))\n\n    num_classes = len(np.unique(labels))\n\n\n\n    for i, model_preds in enumerate(models_predictions):\n\n        # Simulate a predicting function for model predictions\n\n        preds = predicting(model_preds)\n\n\n\n        # Calculate different metrics depending on the number of classes\n\n        if num_classes == 2:  # Binary classification\n\n            pre = precision_score(labels, preds)\n\n            rec = recall_score(labels, preds)\n\n            f1 = f1_score(labels, preds)\n\n            auc = roc_auc_score(labels, preds)\n\n        else:  # Multiclass classification\n\n            pre = precision_score(labels, preds, average='macro')\n\n            rec = recall_score(labels, preds, average='macro')\n\n            f1 = f1_score(labels, preds, average='macro')\n\n            auc = roc_auc_score(labels, model_preds, average='macro', multi_class='ovo')\n\n\n\n        # Update metrics array with the calculated metrics\n\n        metrics[:, i] = np.array([f1, auc])\n\n\n\n    # Output the f1 and auc scores for each model\n\n    print(\"F1 Score\", metrics[0] * 100)\n\n    print(\"ROC_AUC Score\", metrics[1] * 100)\n\n\n\n    # Calculate weights based on the metrics\n\n    weights = get_weights(np.transpose(metrics))\n\n    return weights\n\n\n\ndef get_weights(matrix):\n\n    \"\"\"\n\n    Calculates weights for each model using the tanh function on the metrics.\n\n\n\n    :param matrix: A matrix of shape (number of models, number of metrics).\n\n    :return: A list of weights for each model.\n\n    \"\"\"\n\n    weights = []\n\n    for model_metrics in matrix:\n\n        # Use tanh to compute a weighted sum of metrics for each model\n\n        weight = np.sum(np.tanh(model_metrics))\n\n        weights.append(weight)\n\n    return weights\n\n\n\n# Ensure the training root path ends with a slash\n\nroot_train = args.root_train\n\nif root_train[-1] != '/':\n\n    root_train += '/'\n\n\n\n# Ensure the testing root path ends with a slash\n\nroot_test = args.root_test\n\nif root_test[-1] != '/':\n\n    root_test += '/'\n\n\n\n# Define the filenames for the training predictions from different models\n\ntrain1 = \"densenet169_train_adam\"\n\ntrain2 = \"efficientnetb7_train_adam\"\n\ntrain3 = \"resnet152_train_adam\"\n\n\n\n# Retrieve the predictions from files for training data\n\np1_train = getfile(root_train + train1)  # Get predictions for the first model\n\np2_train = getfile(root_train + train2)  # Get predictions for the second model\n\np3_train = getfile(root_train + train3)  # Get predictions for the third model\n\n\n\n# Load the labels for the training data\n\ntrain_labels = getlabels(args.train_labels)\n\n\n\n# Define the filenames for the testing predictions from different models\n\ntest1 = \"densenet169_test_adam\"\n\ntest2 = \"efficientnetb7_test_adam\"\n\ntest3 = \"resnet152_test_adam\"\n\n\n\n# Retrieve the predictions from files for testing data\n\np1_test = getfile(root_test + test1)  # Get predictions for the first model\n\np2_test = getfile(root_test + test2)  # Get predictions for the second model\n\np3_test = getfile(root_test + test3)  # Get predictions for the third model\n\n\n\n# Load the labels for the testing data\n\ntest_labels = getlabels(args.test_labels)\n\n\n\n# Print the order of CSV files\n\nprint(\"Train CSV's Order\", train1 + \", \" + train2 + \", \" + train3)\n\nprint(\"\\n\")\n\nprint(\"Test CSV's Order\", test1 + \", \" + test2 + \", \" + test3)\n\nprint(\"\\n\")\n\n\n\n# Display header for training data metrics\n\nprint(\"Training Data Metrics\")\n\nprint(\"--------------------------------------------------------------------------------------\")\n\nprint(train1 + \" \" + train2 + \" \" + train3)\n\nprint(\"--------------------------------------------------------------------------------------\")\n\n\n\n# Get weights based on training labels and predictions\n\nweights = get_scores(train_labels, p1_train, p2_train, p3_train)\n\nprint(\"\\n\")\n\n\n\n# Display header for testing data metrics\n\nprint(\"Testing Data Metrics\")\n\nprint(\"--------------------------------------------------------------------------------------\")\n\nprint(test1 + \" \" + test2 + \" \" + test3)\n\nprint(\"--------------------------------------------------------------------------------------\")\n\nweight = get_scores(test_labels, p1_test, p2_test, p3_test)\n\nprint(\"\\n\")\n\n\n\n# Display original weights\n\nprint(\"Original Weights\")\n\nprint(\"--------------------------------------------------------------------------------------\")\n\nprint(train1, weights[0])\n\nprint(train2, weights[1])\n\nprint(train3, weights[2])\n\nprint(\"\\n\")\n\n\n\n# Calculate ensemble probabilities using the original weights\n\nensemble_prob_original = weights[0] * p1_test + weights[1] * p2_test + weights[2] * p3_test\n\n\n\n# Display ensemble probabilities with original weights\n\nprint(\"Ensemble Probabilities with Original Weights\", ensemble_prob_original)\n\nprint(\"--------------------------------------------------------------------------------------\")\n\nprint(\"\\n\")\n\n\n\n# Generate predictions using the original ensemble probabilities\n\npreds_original = predicting(ensemble_prob_original)\n\n\n\n# Display predictions with original weights\n\nprint(\"Predictions with Original Weights\", preds_original)\n\nprint(\"--------------------------------------------------------------------------------------\")\n\nprint(\"\\n\")\n\n\n\n# Normalize the weights so they sum up to 1\n\nw0, w1, w2 = weights\n\nw0_norm = w0 / (w0 + w1 + w2)\n\nw1_norm = w1 / (w0 + w1 + w2)\n\nw2_norm = w2 / (w0 + w1 + w2)\n\n\n\n# Display normalized weights\n\nprint(\"Normalised Weights\")\n\nprint(\"--------------------------------------------------------------------------------------\")\n\nprint(train1, w0_norm)\n\nprint(train2, w1_norm)\n\nprint(train3, w2_norm)\n\nprint(\"\\n\")\n\n\n\n# Calculate ensemble probabilities using the normalized weights\n\nensemble_prob_Normal = w0_norm * p1_test + w1_norm * p2_test + w2_norm * p3_test\n\n\n\n# Display ensemble probabilities with normalized weights\n\nprint(\"Ensemble Probabilities with Normal Weights\", ensemble_prob_Normal)\n\nprint(\"--------------------------------------------------------------------------------------\")\n\nprint(\"\\n\")\n\n\n\n# Generate predictions using the normalized ensemble probabilities\n\npreds_Normal = predicting(ensemble_prob_Normal)\n\n\n\n# Display predictions with normalized weights\n\nprint(\"Predictions with Normal Weights\", preds_Normal)\n\nprint(\"--------------------------------------------------------------------------------------\")\n\nprint(\"\\n\")\n\n\n\n# Manually adjusted weights based on empirical findings\n\nw0_adj = 0.3585864 # Best Weights for some criterion\n\nw1_adj = 0.3441670 # Best Weights for some criterion\n\nw2_adj = 0.2972466 # Best Weights for some criterion\n\n\n\n# Display adjusted weights\n\nprint(\"Adjusted Weights\")\n\nprint(\"--------------------------------------------------------------------------------------\")\n\nprint(train1, w0_adj)\n\nprint(train2, w1_adj)\n\nprint(train3, w2_adj)\n\nprint(\"\\n\")\n\n\n\n# Calculate ensemble probabilities using the adjusted weights\n\nensemble_prob_Adjusted = w0_adj * p1_test + w1_adj * p2_test + w2_adj * p3_test\n\n\n\n# Display ensemble probabilities after updating weights\n\nprint(\"Ensemble Probabilities After Updating Weights\", ensemble_prob_Adjusted)\n\nprint(\"--------------------------------------------------------------------------------------\")\n\nprint(\"\\n\")\n\n\n\n# Generate predictions using the adjusted ensemble probabilities\n\npreds_Adjusted = predicting(ensemble_prob_Adjusted)\n\n\n\n# Display predictions after updating weights\n\nprint(\"Predictions After Updating Weights\", preds_Adjusted)\n\nprint(\"--------------------------------------------------------------------------------------\")\n\nprint(\"\\n\")\n\n\n\n# Calculate the number of correct predictions with original weights and print accuracy\n\ncorrect_original = np.where(preds_original == test_labels)[0].shape[0]\n\ntotal = test_labels.shape[0]\n\nprint(\"\\n\")\n\nprint(\"Accuracy (Original) = \", (correct_original / total) * 100)\n\nprint(\"\\n\")\n\n\n\n# Print classification metrics for the predictions made with original weights\n\nclasses = ['Benign', 'Malignant']\n\nmetrics(test_labels, preds_original, classes)\n\n\n\n# Calculate the number of correct predictions with normalized weights and print accuracy\n\ncorrect_Normal = np.where(preds_Normal == test_labels)[0].shape[0]\n\nprint(\"\\n\")\n\nprint(\"Accuracy (Normal) = \", (correct_Normal / total) * 100)\n\nprint(\"\\n\")\n\n\n\n# Print classification metrics for the predictions made with normalized weights\n\nmetrics(test_labels, preds_Normal, classes)","metadata":{"id":"jlgPiVbaNu63","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"LqKGFzBREROr","trusted":true},"outputs":[],"execution_count":null}]}